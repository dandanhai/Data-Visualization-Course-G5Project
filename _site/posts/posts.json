[
  {
    "path": "posts/2021-03-23-decision-tree/",
    "title": "Predictive Modeling of H1N1 Vaccination",
    "description": "The predictive modeling component of the Shiny application allows the user to customize and use different modeling techniques to build a predictive model to predict whether an individual would take the H1N1 vaccine.",
    "author": [
      {
        "name": "Desmond LIM Pek Loong",
        "url": {}
      }
    ],
    "date": "2021-03-23",
    "categories": [],
    "contents": "\r\n\r\nContents\r\n1. Introduction\r\n1.1 Purpose\r\n\r\n2. Data Preparation\r\n2.1 Data Source\r\n2.2 Date Wrangling and Cleaning\r\n\r\n3 Modeling\r\n3.1 Literature Review: Choosing the right Modeling Package\r\n3.2 Data Splitting\r\n3.3 Model Tuning\r\n\r\n4. Plotting Variable Importance\r\n5. Model Comparision by ROC/AUC and Visualisations\r\n5.1 Comparing ROC Packages\r\n5.1.1 Using ROCR Package\r\n5.1.2 Using pROC Package\r\n5.1.3 Using plotROC Package\r\n5.1.4 ROC Package Comparison\r\n\r\n5.2 Obtaining the AUC Table\r\n5.3 Comparing Model Performance via Resampling\r\n\r\n6. Proposed Visualisation from Shiny Module\r\n7. Conclusion/Reflections\r\nReferences\r\n\r\n1. Introduction\r\nWith the ongoing COVID-19 pandemic, the world is experiencing first-hand on how a virus could affect economy, society and the deaths that it could cause. The importance of having a vaccine and having the general population taking the vaccine is key to curbing the spread of the virus and saving lives.\r\nA similar situation was the H1N1 virus pandemic which occurred in 2009, where an estimated amount of 151,700-575,400 people worldwide had died during the first year of the virus. Being able to predict which individuals are likely to receive their H1N1 vaccinations, it will guide governments, health officials to know what are the important predictors that lead them to take the H1N1 vaccine. This understanding would be useful in future efforts to promote vaccination to the public, especially when a vaccine for the current pandemic is made.\r\n1.1 Purpose\r\nThe purpose of the study is to develop various predictive models on the individuals who are likely to take the H1N1 vaccine based on the flu survey data , to be able to assess the models for the optimal model and visualize the assessment.\r\n2. Data Preparation\r\nThe data used was obtained from the United States Centre of Disease Control and Prevention (CDC)’s website https://www.cdc.gov/nchs/nis/data_files_h1n1.htm on the National 2009 H1N1 flu survey conducted in the US.\r\n2.1 Data Source\r\nThe dataset in excel format was imported by read_csv into the RStudio environment. The following code was used to launch the mentioned packages in R.\r\n\r\n\r\n#R packages used to modelling and visualization\r\n\r\npackages = c('tidyverse','readr','caret','caTools','ggpubr','ROCR','pROC','plotROC','plotly')\r\nfor (p in packages){\r\n  if(!require(p, character.only = T)){\r\n  install.packages(p)\r\n  }\r\n  library(p,character.only= T ) \r\n} \r\n\r\n\r\n\r\n\r\n\r\nH1N1 <- read_csv('data/H1N1_Final_dan_edit.csv')\r\n\r\nglimpse(H1N1)\r\n\r\n\r\n\r\nCheck for missing data i.e NA is conducted on the data. Variables with missing data were noted down.\r\n\r\n\r\ncolMeans(is.na(H1N1))\r\n\r\n\r\n       VACC_H1N1_F        VACC_SEAS_F       B_H1N1_ANTIV \r\n       0.005694632        0.005652346        0.203865020 \r\n      B_H1N1_AVOID       B_H1N1_FMASK       B_H1N1_HANDS \r\n       0.207910465        0.201976207        0.202765562 \r\n      B_H1N1_LARGE       B_H1N1_RCONT       B_H1N1_TOUCH \r\n       0.203794542        0.203963690        0.205373252 \r\n     CONCERN LEVEL               HQ23               HQ24 \r\n       0.000000000        0.854434484        0.962717073 \r\n            HQ24_B           INT_H1N1           INT_NEXT \r\n       0.994587280        0.000000000        0.000000000 \r\n          INT_SEAS          KNOW_H1N1                Q23 \r\n       0.000000000        0.000000000        0.960165765 \r\n               Q24              Q24_B             DOCREC \r\n       0.977136897        0.996447903        0.000000000 \r\n   ILI_DIAG_H1N1_F    ILI_DIAG_SEAS_F              ILI_F \r\n       0.961913622        0.961913622        0.020889716 \r\n       ILI_OTHER_F        ILI_TREAT_F              PSL_1 \r\n       0.017083897        0.922488160        1.000000000 \r\n             PSL_2                 Q9             Q9_NUM \r\n       1.000000000        1.000000000        1.000000000 \r\n     CHRONIC_MED_F   CLOSE_UNDER6MO_F    HEALTH_WORKER_F \r\n       0.031799729        0.226291159        0.225713239 \r\n PATIENT_CONTACT_F             AGEGRP     EDUCATION_COMP \r\n       0.265195083        0.000000000        0.244009359 \r\n        HH_CHILD_R             HISP_I           INC_CAT1 \r\n       0.007132386        0.000000000        0.214436739 \r\n            INSURE            MARITAL          N_ADULT_R \r\n       1.000000000        0.244544993        0.007132386 \r\n        N_PEOPLE_R                Q95         Q95_INDSTR \r\n       0.003157420        0.994432228        0.595554240 \r\n         Q95_OCCPN         RACEETH4_I         RENT_OWN_R \r\n       0.595554240        0.000000000        0.983451737 \r\n             SEX_I              STATE REAS_NOH1N1_AHAD_F \r\n       0.000000000        0.000000000        0.399484100 \r\nREAS_NOH1N1_ALLG_F REAS_NOH1N1_CANT_F REAS_NOH1N1_COST_F \r\n       0.399484100        0.399484100        0.399484100 \r\nREAS_NOH1N1_DKNW_F REAS_NOH1N1_DWRK_F REAS_NOH1N1_GOTO_F \r\n       0.399484100        0.399484100        0.399484100 \r\nREAS_NOH1N1_NDOC_F REAS_NOH1N1_NEVR_F REAS_NOH1N1_NNDD_F \r\n       0.399484100        0.399484100        0.399484100 \r\nREAS_NOH1N1_NOTA_F REAS_NOH1N1_OTHR_F REAS_NOH1N1_REFD_F \r\n       0.399484100        0.399484100        0.399484100 \r\nREAS_NOH1N1_SAVE_F REAS_NOH1N1_SEFF_F REAS_NOH1N1_TIME_F \r\n       0.399484100        0.399484100        0.399484100 \r\n\r\n2.2 Date Wrangling and Cleaning\r\nBefore the dataset can be used for modelling, the missing data would need to processed.\r\nThe following section focused on wrangling the data set and cleaning up missing variables. The code below is used to remove the missing data from the target variable, VACC_H1N1_F.\r\n\r\n\r\n#exclude the NA column in the target variable\r\nH1N1 <- H1N1 %>%\r\n  filter(!is.na(VACC_H1N1_F))\r\n\r\n\r\n\r\n\r\n\r\nnames(H1N1)[names(H1N1) == 'CONCERN LEVEL'] <- \"CONCERN_LEVEL\" #Renaming of variable \"Concern Level\"\r\n\r\n\r\n\r\n\r\n\r\nH1N1[H1N1 == '#N/A'] <- NA # Changing all the value with \"#N/A\" to actual missing value.\r\n\r\n\r\n\r\n\r\n\r\ncolMeans(is.na(H1N1)) #Check for missing values again.\r\n\r\n\r\n       VACC_H1N1_F        VACC_SEAS_F       B_H1N1_ANTIV \r\n       0.000000000        0.003997732        0.203132974 \r\n      B_H1N1_AVOID       B_H1N1_FMASK       B_H1N1_HANDS \r\n       0.207201588        0.201360930        0.202098100 \r\n      B_H1N1_LARGE       B_H1N1_RCONT       B_H1N1_TOUCH \r\n       0.203189680        0.203274738        0.204678197 \r\n     CONCERN_LEVEL               HQ23               HQ24 \r\n       0.203473207        0.854834137        0.963198185 \r\n            HQ24_B           INT_H1N1           INT_NEXT \r\n       0.994740573        0.255146016        0.692755883 \r\n          INT_SEAS          KNOW_H1N1                Q23 \r\n       0.459625744        0.204479728        0.960518855 \r\n               Q24              Q24_B             DOCREC \r\n       0.977417068        0.996597675        0.044031755 \r\n   ILI_DIAG_H1N1_F    ILI_DIAG_SEAS_F              ILI_F \r\n       0.961993195        0.961993195        0.020484831 \r\n       ILI_OTHER_F        ILI_TREAT_F              PSL_1 \r\n       0.016869861        0.922497874        1.000000000 \r\n             PSL_2                 Q9             Q9_NUM \r\n       1.000000000        1.000000000        1.000000000 \r\n     CHRONIC_MED_F   CLOSE_UNDER6MO_F    HEALTH_WORKER_F \r\n       0.031216331        0.225333144        0.224766090 \r\n PATIENT_CONTACT_F             AGEGRP     EDUCATION_COMP \r\n       0.264346470        0.000000000        0.242968528 \r\n        HH_CHILD_R             HISP_I           INC_CAT1 \r\n       0.007074001        0.000000000        0.213198185 \r\n            INSURE            MARITAL          N_ADULT_R \r\n       1.000000000        0.243592288        0.007074001 \r\n        N_PEOPLE_R                Q95         Q95_INDSTR \r\n       0.003118798        0.994527927        0.594074284 \r\n         Q95_OCCPN         RACEETH4_I         RENT_OWN_R \r\n       0.594074284        0.000000000        0.983612135 \r\n             SEX_I              STATE REAS_NOH1N1_AHAD_F \r\n       0.000000000        0.000000000        0.401020697 \r\nREAS_NOH1N1_ALLG_F REAS_NOH1N1_CANT_F REAS_NOH1N1_COST_F \r\n       0.401020697        0.401020697        0.401020697 \r\nREAS_NOH1N1_DKNW_F REAS_NOH1N1_DWRK_F REAS_NOH1N1_GOTO_F \r\n       0.401020697        0.401020697        0.401020697 \r\nREAS_NOH1N1_NDOC_F REAS_NOH1N1_NEVR_F REAS_NOH1N1_NNDD_F \r\n       0.401020697        0.401020697        0.401020697 \r\nREAS_NOH1N1_NOTA_F REAS_NOH1N1_OTHR_F REAS_NOH1N1_REFD_F \r\n       0.401020697        0.401020697        0.401020697 \r\nREAS_NOH1N1_SAVE_F REAS_NOH1N1_SEFF_F REAS_NOH1N1_TIME_F \r\n       0.401020697        0.401020697        0.401020697 \r\n\r\nData will more than 50% of missing values are removed. 27 variables are wrangled into a new data set h1n1data.\r\n\r\n\r\nh1n1data <-H1N1 %>%\r\n  select(VACC_H1N1_F,\r\n                   VACC_SEAS_F,\r\n                   B_H1N1_ANTIV,\r\n                   B_H1N1_AVOID,\r\n                   B_H1N1_FMASK,\r\n                   B_H1N1_HANDS,\r\n                   B_H1N1_LARGE,\r\n                   B_H1N1_RCONT,\r\n                   B_H1N1_TOUCH,\r\n                   CONCERN_LEVEL,\r\n                   INT_H1N1,\r\n                   KNOW_H1N1,\r\n                   INT_SEAS,  \r\n                   DOCREC,\r\n                   CHRONIC_MED_F,\r\n                   CLOSE_UNDER6MO_F,         \r\n                   HEALTH_WORKER_F,\r\n                   PATIENT_CONTACT_F,\r\n                   AGEGRP,\r\n                   EDUCATION_COMP,\r\n                   HH_CHILD_R,\r\n                   INC_CAT1,\r\n                   MARITAL,\r\n                   RACEETH4_I,\r\n                   N_ADULT_R,\r\n                   SEX_I,\r\n                   STATE)\r\n\r\n\r\n\r\nThe column variables are transformed in factor(categorical) variables.\r\n\r\n\r\nh1n1data <- transform(h1n1data,\r\n                   VACC_H1N1_F= as.factor(VACC_H1N1_F),\r\n                   VACC_SEAS_F= as.factor(VACC_SEAS_F),\r\n                   B_H1N1_ANTIV= as.factor(B_H1N1_ANTIV),\r\n                   B_H1N1_AVOID= as.factor(B_H1N1_AVOID),\r\n                   B_H1N1_FMASK= as.factor(B_H1N1_FMASK),\r\n                   B_H1N1_HANDS= as.factor(B_H1N1_HANDS),\r\n                   B_H1N1_LARGE= as.factor(B_H1N1_LARGE),\r\n                   B_H1N1_RCONT= as.factor(B_H1N1_RCONT),\r\n                   B_H1N1_TOUCH= as.factor(B_H1N1_TOUCH),\r\n                   CONCERN_LEVEL= as.factor(CONCERN_LEVEL),\r\n                   INT_H1N1= as.factor(INT_H1N1),\r\n                   KNOW_H1N1= as.factor(KNOW_H1N1),\r\n                   DOCREC= as.factor(DOCREC),\r\n                   CHRONIC_MED_F= as.factor(CHRONIC_MED_F),\r\n                   CLOSE_UNDER6MO_F= as.factor(CLOSE_UNDER6MO_F),\r\n                   HEALTH_WORKER_F= as.factor(HEALTH_WORKER_F),\r\n                   AGEGRP= as.factor(AGEGRP),\r\n                   EDUCATION_COMP= as.factor(EDUCATION_COMP),\r\n                   HH_CHILD_R= as.factor(HH_CHILD_R),\r\n                   INC_CAT1= as.factor(INC_CAT1),\r\n                   MARITAL= as.factor(MARITAL),\r\n                   RACEETH4_I= as.factor(RACEETH4_I),\r\n                   N_ADULT_R= as.factor(N_ADULT_R),\r\n                   SEX_I= as.factor(SEX_I),\r\n                   STATE= as.factor(STATE),\r\n                   PATIENT_CONTACT_F = as.factor(PATIENT_CONTACT_F),\r\n                   INT_SEAS = as.factor(INT_SEAS)\r\n                   )\r\n\r\n\r\n\r\nThe code below added a column which recoded the various states into regions.\r\n\r\n\r\nregion <- read_csv(\"data/state_region.csv\")\r\n\r\n\r\n\r\n\r\n\r\nh1n1data$state_recoded <- str_to_title(h1n1data$STATE)\r\nh1n1data <- left_join(h1n1data, region,\r\n                      by=c(\"state_recoded\" = \"State\"))\r\n\r\n\r\n\r\n\r\n\r\nsummary(h1n1data)\r\n\r\n\r\n VACC_H1N1_F VACC_SEAS_F  B_H1N1_ANTIV B_H1N1_AVOID B_H1N1_FMASK\r\n No :53471   No  :38210   No  :53438   No  :15263   No  :52444  \r\n Yes:17069   Yes :32048   Yes : 2773   Yes :40661   Yes : 3892  \r\n             NA's:  282   NA's:14329   NA's:14616   NA's:14204  \r\n                                                                \r\n                                                                \r\n                                                                \r\n                                                                \r\n B_H1N1_HANDS B_H1N1_LARGE B_H1N1_RCONT B_H1N1_TOUCH CONCERN_LEVEL\r\n No  : 9813   No  :36252   No  :37220   No  :17939   0   : 6861   \r\n Yes :46471   Yes :19955   Yes :18981   Yes :38163   1   :17218   \r\n NA's:14256   NA's:14333   NA's:14339   NA's:14438   2   :22490   \r\n                                                     3   : 9618   \r\n                                                     NA's:14353   \r\n                                                                  \r\n                                                                  \r\n INT_H1N1     KNOW_H1N1    INT_SEAS      DOCREC      CHRONIC_MED_F\r\n 0   :17731   0   :30895   0   :15490   0   : 1948   No  :51265   \r\n 1   :19663   1   : 5251   1   :13543   1   :40462   Yes :17073   \r\n 2   : 9961   2   :19970   2   : 5670   2   : 8687   NA's: 2202   \r\n 3   : 5187   NA's:14424   3   : 3415   3   : 2534                \r\n NA's:17998                NA's:32422   4   :13803                \r\n                                        NA's: 3106                \r\n                                                                  \r\n CLOSE_UNDER6MO_F HEALTH_WORKER_F PATIENT_CONTACT_F\r\n No  :50032       No  :48599      No  :46951       \r\n Yes : 4613       Yes : 6086      Yes : 4942       \r\n NA's:15895       NA's:15855      NA's:18647       \r\n                                                   \r\n                                                   \r\n                                                   \r\n                                                   \r\n                AGEGRP               EDUCATION_COMP  HH_CHILD_R  \r\n 10 - 17 Years     : 6833   < 12 Years      : 4995   0   :39356  \r\n 18 - 34 Years     :11037   12 Years        :12158   1   :12383  \r\n 35 - 44 Years     : 8243   College Graduate:21376   2   :11333  \r\n 45 - 54 Years     :11071   Some College    :14872   3   : 6969  \r\n 55 - 64 Years     :11685   NA's            :17139   NA's:  499  \r\n 6 Months - 9 Years: 7332                                        \r\n 65+ Years         :14339                                        \r\n               INC_CAT1            MARITAL     \r\n $75,001 - $100,000:19781   Married    :28539  \r\n $50,001 - $75,000 : 9985   Not Married:24818  \r\n $35,001 - $50,000 : 7976   NA's       :17183  \r\n $15,001 - $25,000 : 5805                      \r\n $25,001 - $35,000 : 5134                      \r\n (Other)           : 6820                      \r\n NA's              :15039                      \r\n                                 RACEETH4_I    N_ADULT_R   \r\n Hispanic                             : 5469   1   :18654  \r\n Non-Hispanic, Black Only             : 5776   2   :40293  \r\n Non-Hispanic, Other or Multiple Races: 4626   3   : 7996  \r\n Non-Hispanic, White Only             :54669   4   : 3098  \r\n                                               NA's:  499  \r\n                                                           \r\n                                                           \r\n    SEX_I                        STATE       state_recoded     \r\n Female:40314   TEXAS               : 1720   Length:70540      \r\n Male  :30226   NEW MEXICO          : 1678   Class :character  \r\n                CALIFORNIA          : 1637   Mode  :character  \r\n                GEORGIA             : 1605                     \r\n                MARYLAND            : 1584                     \r\n                DISTRICT OF COLUMBIA: 1581                     \r\n                (Other)             :60735                     \r\n    Region         \r\n Length:70540      \r\n Class :character  \r\n Mode  :character  \r\n                   \r\n                   \r\n                   \r\n                   \r\n\r\nThe predictors are plotted against the target variable to check for complete or quasi-complete separation.\r\n\r\n\r\n\r\n\r\n\r\nPlots I\r\n\r\n\r\n\r\n\r\n\r\nPlots II\r\n\r\n\r\n\r\n\r\nPlots III\r\n\r\n\r\n\r\n\r\n\r\nThe new dataframe h1n1model is created. 3 variables with complete/quasi-complete separation were removed.\r\n\r\n\r\nh1n1model <- h1n1data #new dataframe for predictive modeling\r\n              \r\n\r\nh1n1model <-select(h1n1model,-c(INT_H1N1,B_H1N1_ANTIV,INT_SEAS, state_recoded, Region)) #Remove variable with complete separation from dataset.\r\n\r\n\r\nh1n1model <- h1n1model %>% #Omitting na in order as some models unable to process with missing values. \r\n             na.omit\r\n\r\nsummary(h1n1model) #To check the data again.\r\n\r\n\r\n VACC_H1N1_F VACC_SEAS_F B_H1N1_AVOID B_H1N1_FMASK B_H1N1_HANDS\r\n No :30432   No :20780   No :10338    No :36863    No : 6618   \r\n Yes: 9075   Yes:18727   Yes:29169    Yes: 2644    Yes:32889   \r\n                                                               \r\n                                                               \r\n                                                               \r\n                                                               \r\n                                                               \r\n B_H1N1_LARGE B_H1N1_RCONT B_H1N1_TOUCH CONCERN_LEVEL KNOW_H1N1\r\n No :25744    No :26430    No :12467    0: 4486       0:21859  \r\n Yes:13763    Yes:13077    Yes:27040    1:12541       1: 2903  \r\n                                        2:16183       2:14745  \r\n                                        3: 6297                \r\n                                                               \r\n                                                               \r\n                                                               \r\n DOCREC    CHRONIC_MED_F CLOSE_UNDER6MO_F HEALTH_WORKER_F\r\n 0:  917   No :28467     No :36077        No :34785      \r\n 1:24438   Yes:11040     Yes: 3430        Yes: 4722      \r\n 2: 5363                                                 \r\n 3: 1271                                                 \r\n 4: 7518                                                 \r\n                                                         \r\n                                                         \r\n PATIENT_CONTACT_F                AGEGRP              EDUCATION_COMP \r\n No :35658         10 - 17 Years     :   0   < 12 Years      : 3300  \r\n Yes: 3849         18 - 34 Years     :8122   12 Years        : 8593  \r\n                   35 - 44 Years     :6220   College Graduate:16515  \r\n                   45 - 54 Years     :8283   Some College    :11099  \r\n                   55 - 64 Years     :8367                           \r\n                   6 Months - 9 Years:   0                           \r\n                   65+ Years         :8515                           \r\n HH_CHILD_R               INC_CAT1            MARITAL     \r\n 0:27196    $10,001 - $15,000 : 1979   Married    :21477  \r\n 1: 4939    $15,001 - $25,000 : 4335   Not Married:18030  \r\n 2: 4570    $25,001 - $35,000 : 3826                      \r\n 3: 2802    $35,001 - $50,000 : 5879                      \r\n            $50,001 - $75,000 : 7082                      \r\n            $75,001 - $100,000:13303                      \r\n            <= $10,000        : 3103                      \r\n                                 RACEETH4_I    N_ADULT_R\r\n Hispanic                             : 2581   1:11389  \r\n Non-Hispanic, Black Only             : 3083   2:22005  \r\n Non-Hispanic, Other or Multiple Races: 2274   3: 4399  \r\n Non-Hispanic, White Only             :31569   4: 1714  \r\n                                                        \r\n                                                        \r\n                                                        \r\n    SEX_I                        STATE      \r\n Female:23154   NEW MEXICO          :  964  \r\n Male  :16353   DISTRICT OF COLUMBIA:  926  \r\n                TEXAS               :  926  \r\n                CALIFORNIA          :  896  \r\n                ARIZONA             :  878  \r\n                VIRGINIA            :  863  \r\n                (Other)             :34054  \r\n\r\n3 Modeling\r\n3.1 Literature Review: Choosing the right Modeling Package\r\nThe R caret package is a set of functions that streamlines the process for predictive model building. It’s current release consist 238 models.As different modeling functions has different syntax for modeling training and prediction, it will be difficult to keep track of which algorithms are in which package. For example, a random forest model will be using randomforest() syntax to run the model and a neural network model requires the neuralnet() syntax. Moreover, each of the algorithm will have their own arguments, making it difficult and time-consuming if different models are required to be used in the same code.\r\nThere is no need to call for the library for the different modeling packages using caret. caret will assist to load the required packages when used and if the package is missing, there will be a prompt for installation.\r\nThe train() function in caret has multiple functions:\r\nBuilding a model using a specific algorithm\r\nCross validating the model\r\nTune the parameters for optimal model performance\r\nChoose the optimal model based on a given evaluation metric\r\nPreprocessing\r\nThe caret package made it easier by combining the data pre-processing, model hyperparameter tuning within the same package. It allows quick change of model with minor syntax change, allowing it the most suitable model to be found.\r\n3.2 Data Splitting\r\nAs the H1N1 vaccination (VACC_H1N1_F) is the target variable is important for analysis, a balance of the target variable across the training/test sets, the function createDataPartition was used to create training/testing sets using stratified random sampling.\r\nData is split with 80% as training data and 20% are testing data.In place of partitioning a validation dataset, the traincontrol function is used for the cross-validation of the training data set.\r\nThe below code shows the spliting of the dataset.\r\n\r\n\r\nset.seed(123)\r\n\r\n# define an 80%/20% train/test split of the h1n1model data set\r\nsplit=0.80 \r\ntrainIndex <- createDataPartition(h1n1model$VACC_H1N1_F, p=split, list=FALSE)\r\ndata_train <- h1n1model[ trainIndex,]\r\ndata_test <- h1n1model[-trainIndex,]\r\n\r\n\r\n\r\n3.3 Model Tuning\r\nThe function trainControl generates parameters that further control how models are created, with different resampling methods like bootstrap re-sampling, k-fold cross validation. In the code below, the k-fold cross validation method with number = referring to the number of folds being used. The repeated k-fold cross validation method involves splitting the dataset into k-subsets and repeating in a number of time. For each subset is held out while the model is trained on all other subsets. This process is completed until accuracy is determine for each instance in the dataset, and an overall accuracy estimate is provided.\r\n\r\n\r\nfitControl <- trainControl(\r\n  method = \"cv\",\r\n  number = 5,\r\n  classProbs = TRUE,\r\n  summaryFunction = twoClassSummary, #twoClassSummary computes the sensitivity, specificity and aread under the ROC curve. \r\n  savePredictions = TRUE)\r\n\r\n\r\n\r\nThere are two main ways of tuning the model within the caret package, using tuneLength or tuneGrid.\r\nThe tuneLength parameter allows the user to enter a value which will determine the number of default values being used as the main parameter for a specific model. The number used can be applicable throughout all the models. The tuneGrid function create a dataframe to store the tuning parameter grid specified by the user. It allows the user to determine which are the values a model will take as it’s main parameter. The parameters in the tuneGrid is model specific. Using tuneGrid will be more applicable as it provides the user more model customizability and fine tuning.\r\nFor random forest using the ranger method in caret, three options are available for tuning the model. Firstly, mtry which refers to the number of variables randomly sampled as candidates at each split. Split rule defines which splitting method is used. The default used is Gini where the split minimizes the the Gini impurtity for classification. The minimum node size refers to the minimum number of observations in a terminal node.\r\nAccording the research (Probst et al.,2019), mtry has the most influence over the model performance and the best value of mtry depends on the number of variables that are related to the outcome.\r\n\r\n\r\n# Random Forest:\r\nset.seed(123)\r\n\r\nm=4\r\nns=10\r\n\r\nrf_grid <- expand.grid(\r\n                mtry = 2:m,\r\n                splitrule =\"gini\",\r\n                min.node.size = 10\r\n                      )\r\n\r\nmodel_rf <- train(VACC_H1N1_F~., \r\n                  data=data_train, \r\n                  trControl = fitControl, \r\n                  method = \"ranger\",\r\n                  metric = \"ROC\",\r\n                  importance = \"impurity\",\r\n                  tuneGrid = rf_grid)\r\n\r\nmodel_rf\r\n\r\n\r\nRandom Forest \r\n\r\n31606 samples\r\n   23 predictor\r\n    2 classes: 'No', 'Yes' \r\n\r\nNo pre-processing\r\nResampling: Cross-Validated (5 fold) \r\nSummary of sample sizes: 25285, 25285, 25284, 25285, 25285 \r\nResampling results across tuning parameters:\r\n\r\n  mtry  ROC        Sens       Spec     \r\n  2     0.8335559  0.9952764  0.0738292\r\n  3     0.8390148  0.9692352  0.2856749\r\n  4     0.8417187  0.9558860  0.3809917\r\n\r\nTuning parameter 'splitrule' was held constant at a value of\r\n gini\r\nTuning parameter 'min.node.size' was held constant at a\r\n value of 10\r\nROC was used to select the optimal model using the largest value.\r\nThe final values used for the model were mtry = 4, splitrule =\r\n gini and min.node.size = 10.\r\n\r\nThe rpart2 method within the caret package allows for the tuning for the maximum depth of the tree. This tuning variable can help to limit the decsion tree model from growing too deep which might cause over-fitting.\r\n\r\n\r\n#Decision Tree\r\nset.seed(123)\r\n\r\ndepth = 5 #User-defined maximum depth of decision tree\r\n\r\ndt_grid<- expand.grid(maxdepth = depth)\r\n\r\nmodel_dt <- train(VACC_H1N1_F~., \r\n                  data=data_train, \r\n                  trControl = fitControl, \r\n                  method = \"rpart2\",\r\n                  metric = \"ROC\",\r\n                  tuneGrid = dt_grid\r\n                  )\r\n\r\nmodel_dt\r\n\r\n\r\nCART \r\n\r\n31606 samples\r\n   23 predictor\r\n    2 classes: 'No', 'Yes' \r\n\r\nNo pre-processing\r\nResampling: Cross-Validated (5 fold) \r\nSummary of sample sizes: 25285, 25285, 25284, 25285, 25285 \r\nResampling results:\r\n\r\n  ROC        Sens       Spec     \r\n  0.7841742  0.9484104  0.4137741\r\n\r\nTuning parameter 'maxdepth' was held constant at a value of 5\r\n\r\nThe principle behind K-Nearest Neighbor(KNN) algorithm is to find K predefined number of training samples that are closest in the distance to a new point & predict a label for our new point using these samples. For classification the KNN method starts by identifying the k most similar training observations (i.e. neighbors) to the new observation, and then assigns the observation to the class containing the majority of its neighbors.\r\nThe choice of k considerably impacts the output of KNN model. k = 1 corresponds to a highly flexible method resulting to a training error rate of 0 (over-fitting), but the test error rate may be quite high. The value of optimal k is usually the square root of N, where N is the total number of samples.\r\n\r\n\r\n#K-Nearest Neighbors\r\nset.seed(123)\r\n\r\nkv=10  #User-defined k value\r\n\r\nknn_grid <- expand.grid(k= kv)\r\n\r\nmodel_knn <- train(VACC_H1N1_F~., \r\n                  data=data_train, \r\n                  trControl = fitControl, \r\n                  method = \"knn\",\r\n                  metric = \"ROC\",\r\n                  tuneGrid = knn_grid\r\n                  )\r\n\r\nmodel_knn\r\n\r\n\r\nk-Nearest Neighbors \r\n\r\n31606 samples\r\n   23 predictor\r\n    2 classes: 'No', 'Yes' \r\n\r\nNo pre-processing\r\nResampling: Cross-Validated (5 fold) \r\nSummary of sample sizes: 25285, 25285, 25284, 25285, 25285 \r\nResampling results:\r\n\r\n  ROC        Sens       Spec     \r\n  0.8048322  0.9500945  0.3513774\r\n\r\nTuning parameter 'k' was held constant at a value of 10\r\n\r\nFor the neural network(nnet) model,there are two tuning parameters, which need to be set. First is the number of nodes in the hidden layer and second, it is the value of the “weight decay” parameter.\r\nThe hidden layer of the neural network is the intermediate layer between the input and output layer of a neuron network (Panchal & Panchal, 2014, p. 460). The hidden nodes might cause overfitting when too many neurons(hidden nodes) are present in the network. The purpose of the weight decay factor is to prevent overfitting.\r\n\r\n\r\n#Neural Network  \r\nset.seed(123)\r\n\r\nsz = 1 #User-defined number of hidden nodes\r\ndc = 0 #USer-defined decay rate\r\n\r\nnnet_grid <- expand.grid( size = sz,\r\n                          decay = dc)\r\n\r\n\r\nmodel_nnet <- train(VACC_H1N1_F~., \r\n                  data=data_train, \r\n                  trControl = fitControl, \r\n                  method = \"nnet\",\r\n                  metric = \"ROC\",\r\n                  tuneGrid = nnet_grid\r\n                  )\r\n\r\n\r\n# weights:  99\r\ninitial  value 26589.627274 \r\niter  10 value 13626.461983\r\niter  20 value 13376.340522\r\niter  30 value 12915.052594\r\niter  40 value 12606.753114\r\niter  50 value 12331.349382\r\niter  60 value 11946.723445\r\niter  70 value 11776.270369\r\niter  80 value 11732.724596\r\niter  90 value 11718.627201\r\niter 100 value 11717.572046\r\nfinal  value 11717.572046 \r\nstopped after 100 iterations\r\n# weights:  99\r\ninitial  value 17171.750195 \r\niter  10 value 11380.634022\r\niter  20 value 11309.563841\r\niter  30 value 11278.590198\r\niter  40 value 11264.527582\r\niter  50 value 11259.782750\r\niter  60 value 11256.844758\r\niter  70 value 11253.710980\r\niter  80 value 11241.607724\r\niter  90 value 11232.658714\r\niter 100 value 11232.389316\r\nfinal  value 11232.389316 \r\nstopped after 100 iterations\r\n# weights:  99\r\ninitial  value 19684.645375 \r\niter  10 value 10712.335323\r\niter  20 value 10503.529519\r\niter  30 value 10471.490428\r\niter  40 value 10447.308989\r\niter  50 value 10426.685950\r\niter  60 value 10414.830002\r\niter  70 value 10410.289543\r\niter  80 value 10409.708839\r\nfinal  value 10409.698890 \r\nconverged\r\n# weights:  99\r\ninitial  value 17241.041006 \r\niter  10 value 13626.329956\r\niter  20 value 12536.157114\r\niter  30 value 11488.105019\r\niter  40 value 11293.383176\r\niter  50 value 11148.360692\r\niter  60 value 11045.260594\r\niter  70 value 10976.829467\r\niter  80 value 10943.918263\r\niter  90 value 10928.649520\r\niter 100 value 10914.121349\r\nfinal  value 10914.121349 \r\nstopped after 100 iterations\r\n# weights:  99\r\ninitial  value 16605.060349 \r\niter  10 value 12063.508758\r\niter  20 value 11550.729798\r\niter  30 value 11528.194364\r\niter  40 value 11510.989549\r\niter  50 value 11503.611516\r\niter  60 value 11493.210692\r\niter  70 value 11487.004214\r\niter  80 value 11481.522394\r\niter  90 value 11473.852666\r\niter 100 value 11468.934232\r\nfinal  value 11468.934232 \r\nstopped after 100 iterations\r\n# weights:  99\r\ninitial  value 18646.728694 \r\niter  10 value 14221.978222\r\niter  20 value 14022.646547\r\niter  30 value 13911.598167\r\niter  40 value 13319.594765\r\niter  50 value 12953.457998\r\niter  60 value 12841.826303\r\niter  70 value 12639.090264\r\niter  80 value 12554.912863\r\niter  90 value 12535.639135\r\niter 100 value 12531.439084\r\nfinal  value 12531.439084 \r\nstopped after 100 iterations\r\n\r\nmodel_nnet\r\n\r\n\r\nNeural Network \r\n\r\n31606 samples\r\n   23 predictor\r\n    2 classes: 'No', 'Yes' \r\n\r\nNo pre-processing\r\nResampling: Cross-Validated (5 fold) \r\nSummary of sample sizes: 25285, 25285, 25284, 25285, 25285 \r\nResampling results:\r\n\r\n  ROC        Sens       Spec     \r\n  0.7411793  0.9238097  0.3256198\r\n\r\nTuning parameter 'size' was held constant at a value of 1\r\n\r\nTuning parameter 'decay' was held constant at a value of 0\r\n\r\n4. Plotting Variable Importance\r\nVariable importance helps to identify most important variables that contribute most significantly to the target variable.Being able to select the most important predictor variables that explains the major part of variance of a target variable can help to identify and build high performing models.\r\nThe variable importance of each trained model is plotted.(Note:kNN does not have variable importance)\r\n\r\n\r\nVariable Importance of Random Forest\r\n\r\n\r\nrfImp <- varImp(model_rf)\r\ndtImp <- varImp(model_dt)\r\nnnetImp <- varImp(model_nnet)\r\n\r\nNo_Var=5 #No.of variable importance to be shown can be user-defined.\r\n\r\ng1 <- rfImp$importance %>% \r\n  as.data.frame() %>%\r\n  rownames_to_column() %>%\r\n  arrange(Overall) %>%\r\n  mutate(rowname = forcats::fct_inorder(rowname )) %>%\r\n  top_n(No_Var,Overall) %>%  #top 5 Importance\r\n  ggplot(aes(x = rowname, y = Overall))+\r\n    geom_col(color=\"black\",fill = \"light blue\")+\r\n    coord_flip()+\r\n    xlab(\"Variable\")+\r\n    ggtitle(\"Variable Importance of Random Forest Model\") + \r\n    theme_minimal() +\r\n    theme(panel.background = element_rect(fill = \"gray80\", color = \"gray80\", size =0.5, linetype = \"solid\"),\r\n       panel.grid.major = element_line(size =0.5, linetype = \"solid\", color = \"white\"), #major refers to grid line at values\r\n       panel.grid.minor = element_line(size =0.25, linetype = \"solid\", color = \"white\")) # minor refers line in between grid values\r\n\r\nggplotly(g1, tooltip = c(\"rowname\", \"Overall\"))\r\n\r\n\r\n\r\n{\"x\":{\"data\":[{\"orientation\":\"h\",\"width\":[0.9,0.9,0.9,0.9,0.9],\"base\":[0,0,0,0,0],\"x\":[18.2359585268045,24.8869169214332,30.709481313405,69.2805079158989,100],\"y\":[1,2,3,4,5],\"text\":[\"rowname: HEALTH_WORKER_FYes<br />Overall:  18.23596\",\"rowname: DOCREC2<br />Overall:  24.88692\",\"rowname: DOCREC1<br />Overall:  30.70948\",\"rowname: DOCREC4<br />Overall:  69.28051\",\"rowname: VACC_SEAS_FYes<br />Overall: 100.00000\"],\"type\":\"bar\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(173,216,230,1)\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(0,0,0,1)\"}},\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":45.4063926940639,\"r\":7.30593607305936,\"b\":41.8264840182648,\"l\":130.776255707763},\"plot_bgcolor\":\"rgba(204,204,204,1)\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187},\"title\":{\"text\":\"Variable Importance of Random Forest Model\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":17.5342465753425},\"x\":0,\"xref\":\"paper\"},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[-5,105],\"tickmode\":\"array\",\"ticktext\":[\"0\",\"25\",\"50\",\"75\",\"100\"],\"tickvals\":[0,25,50,75,100],\"categoryorder\":\"array\",\"categoryarray\":[\"0\",\"25\",\"50\",\"75\",\"100\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(255,255,255,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"Overall\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[0.4,5.6],\"tickmode\":\"array\",\"ticktext\":[\"HEALTH_WORKER_FYes\",\"DOCREC2\",\"DOCREC1\",\"DOCREC4\",\"VACC_SEAS_FYes\"],\"tickvals\":[1,2,3,4,5],\"categoryorder\":\"array\",\"categoryarray\":[\"HEALTH_WORKER_FYes\",\"DOCREC2\",\"DOCREC1\",\"DOCREC4\",\"VACC_SEAS_FYes\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(255,255,255,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\"Variable\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":null,\"line\":{\"color\":null,\"width\":0,\"linetype\":[]},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false,\"legend\":{\"bgcolor\":null,\"bordercolor\":null,\"borderwidth\":0,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.689497716895}},\"hovermode\":\"closest\",\"barmode\":\"relative\"},\"config\":{\"doubleClick\":\"reset\",\"showSendToCloud\":false},\"source\":\"A\",\"attrs\":{\"dd02b796299\":{\"x\":{},\"y\":{},\"type\":\"bar\"}},\"cur_data\":\"dd02b796299\",\"visdat\":{\"dd02b796299\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\nVariable Importance of Decision Tree\r\n\r\n\r\ng2 <- dtImp$importance %>% \r\n  as.data.frame() %>%\r\n  rownames_to_column() %>%\r\n  arrange(Overall) %>%\r\n  mutate(rowname = forcats::fct_inorder(rowname )) %>%\r\n  top_n(No_Var,Overall) %>%  #top 5 Importance\r\n  ggplot(aes(x = rowname, y = Overall))+\r\n    geom_col(color=\"black\",fill = \"light blue\")+\r\n    coord_flip()+\r\n    xlab(\"Variable\")+\r\n    ggtitle(\"Variable Importance of Decision Tree Model\") + \r\n    theme_minimal() +\r\n    theme(panel.background = element_rect(fill = \"gray80\", color = \"gray80\", size =0.5, linetype = \"solid\"),\r\n       panel.grid.major = element_line(size =0.5, linetype = \"solid\", color = \"white\"), #major refers to grid line at values\r\n       panel.grid.minor = element_line(size =0.25, linetype = \"solid\", color = \"white\")) # minor refers line in between grid values\r\n\r\nggplotly(g2, tooltip = c(\"rowname\", \"Overall\"))\r\n\r\n\r\n\r\n{\"x\":{\"data\":[{\"orientation\":\"h\",\"width\":[0.9,0.9,0.9,0.9,0.9],\"base\":[0,0,0,0,0],\"x\":[24.9272016160619,25.258635091715,27.4749244977431,65.8105301166099,100],\"y\":[1,2,3,4,5],\"text\":[\"rowname: HEALTH_WORKER_FYes<br />Overall:  24.92720\",\"rowname: DOCREC1<br />Overall:  25.25864\",\"rowname: DOCREC2<br />Overall:  27.47492\",\"rowname: VACC_SEAS_FYes<br />Overall:  65.81053\",\"rowname: DOCREC4<br />Overall: 100.00000\"],\"type\":\"bar\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(173,216,230,1)\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(0,0,0,1)\"}},\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":45.4063926940639,\"r\":7.30593607305936,\"b\":41.8264840182648,\"l\":130.776255707763},\"plot_bgcolor\":\"rgba(204,204,204,1)\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187},\"title\":{\"text\":\"Variable Importance of Decision Tree Model\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":17.5342465753425},\"x\":0,\"xref\":\"paper\"},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[-5,105],\"tickmode\":\"array\",\"ticktext\":[\"0\",\"25\",\"50\",\"75\",\"100\"],\"tickvals\":[0,25,50,75,100],\"categoryorder\":\"array\",\"categoryarray\":[\"0\",\"25\",\"50\",\"75\",\"100\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(255,255,255,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"Overall\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[0.4,5.6],\"tickmode\":\"array\",\"ticktext\":[\"HEALTH_WORKER_FYes\",\"DOCREC1\",\"DOCREC2\",\"VACC_SEAS_FYes\",\"DOCREC4\"],\"tickvals\":[1,2,3,4,5],\"categoryorder\":\"array\",\"categoryarray\":[\"HEALTH_WORKER_FYes\",\"DOCREC1\",\"DOCREC2\",\"VACC_SEAS_FYes\",\"DOCREC4\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(255,255,255,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\"Variable\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":null,\"line\":{\"color\":null,\"width\":0,\"linetype\":[]},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false,\"legend\":{\"bgcolor\":null,\"bordercolor\":null,\"borderwidth\":0,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.689497716895}},\"hovermode\":\"closest\",\"barmode\":\"relative\"},\"config\":{\"doubleClick\":\"reset\",\"showSendToCloud\":false},\"source\":\"A\",\"attrs\":{\"dd0701f6c20\":{\"x\":{},\"y\":{},\"type\":\"bar\"}},\"cur_data\":\"dd0701f6c20\",\"visdat\":{\"dd0701f6c20\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\nVariable Importance of Neural Network\r\n\r\n\r\ng3 <- nnetImp$importance %>% \r\n  as.data.frame() %>%\r\n  rownames_to_column() %>%\r\n  arrange(Overall) %>%\r\n  mutate(rowname = forcats::fct_inorder(rowname )) %>%\r\n  top_n(No_Var,Overall) %>%  #top 5 Importance\r\n  ggplot(aes(x = rowname, y = Overall))+\r\n    geom_col(color=\"black\",fill = \"light blue\")+\r\n    coord_flip()+\r\n    xlab(\"Variable\")+\r\n    ggtitle(\"Variable Importance of Neural Network Model\") + \r\n    theme_minimal() +\r\n    theme(panel.background = element_rect(fill = \"gray80\", color = \"gray80\", size =0.5, linetype = \"solid\"),\r\n       panel.grid.major = element_line(size =0.5, linetype = \"solid\", color = \"white\"), #major refers to grid line at values\r\n       panel.grid.minor = element_line(size =0.25, linetype = \"solid\", color = \"white\")) # minor refers line in between grid values\r\n\r\nggplotly(g3, tooltip = c(\"rowname\", \"Overall\"))\r\n\r\n\r\n\r\n{\"x\":{\"data\":[{\"orientation\":\"h\",\"width\":[0.9,0.9,0.9,0.9,0.9],\"base\":[0,0,0,0,0],\"x\":[31.8277313713564,32.7172301979378,50.6010822123337,99.5454136385648,100],\"y\":[1,2,3,4,5],\"text\":[\"rowname: DOCREC4<br />Overall:  31.82773\",\"rowname: PATIENT_CONTACT_FYes<br />Overall:  32.71723\",\"rowname: DOCREC2<br />Overall:  50.60108\",\"rowname: VACC_SEAS_FYes<br />Overall:  99.54541\",\"rowname: DOCREC3<br />Overall: 100.00000\"],\"type\":\"bar\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(173,216,230,1)\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(0,0,0,1)\"}},\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":45.4063926940639,\"r\":7.30593607305936,\"b\":41.8264840182648,\"l\":142.465753424658},\"plot_bgcolor\":\"rgba(204,204,204,1)\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187},\"title\":{\"text\":\"Variable Importance of Neural Network Model\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":17.5342465753425},\"x\":0,\"xref\":\"paper\"},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[-5,105],\"tickmode\":\"array\",\"ticktext\":[\"0\",\"25\",\"50\",\"75\",\"100\"],\"tickvals\":[0,25,50,75,100],\"categoryorder\":\"array\",\"categoryarray\":[\"0\",\"25\",\"50\",\"75\",\"100\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(255,255,255,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"Overall\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[0.4,5.6],\"tickmode\":\"array\",\"ticktext\":[\"DOCREC4\",\"PATIENT_CONTACT_FYes\",\"DOCREC2\",\"VACC_SEAS_FYes\",\"DOCREC3\"],\"tickvals\":[1,2,3,4,5],\"categoryorder\":\"array\",\"categoryarray\":[\"DOCREC4\",\"PATIENT_CONTACT_FYes\",\"DOCREC2\",\"VACC_SEAS_FYes\",\"DOCREC3\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(255,255,255,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\"Variable\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":null,\"line\":{\"color\":null,\"width\":0,\"linetype\":[]},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false,\"legend\":{\"bgcolor\":null,\"bordercolor\":null,\"borderwidth\":0,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.689497716895}},\"hovermode\":\"closest\",\"barmode\":\"relative\"},\"config\":{\"doubleClick\":\"reset\",\"showSendToCloud\":false},\"source\":\"A\",\"attrs\":{\"dd02a2451d\":{\"x\":{},\"y\":{},\"type\":\"bar\"}},\"cur_data\":\"dd02a2451d\",\"visdat\":{\"dd02a2451d\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\n5. Model Comparision by ROC/AUC and Visualisations\r\nNote: Compare the model, note the predicted results.\r\nThe ROC (Receiver Operating Characteristic) curve is used to evaluate the strength of a classification model and also to compare between classification models.The ROC curve shows the trade-off between the true positive rate and the false positive rate. To compare between models, the AUC (area under the curve) is used. AUC provides an aggregate measure of performance of a model across the classification thresholds. It is a representation of the model’s capability to distinguish between the classes.\r\n5.1 Comparing ROC Packages\r\nThe following R packages ROCR, pROC and plotROC are used to plot the ROC curves of the predictive models. The packages are later compared on usability, comprehensiveness and visualization of ROC curves.\r\n5.1.1 Using ROCR Package\r\n\r\n\r\n#using ROCR package \r\n\r\n#ROC Curve for Random Forest\r\nrf_pred <- prediction(model_rf$pred$Yes,model_rf$pred$obs)\r\nrf_perf <- performance(rf_pred,\"tpr\",\"fpr\")\r\nplot(rf_perf, main = \"ROC Curves of Models\")\r\n\r\n\r\n#ROC Curve for Decision Tree\r\ndt_pred <-prediction(model_dt$pred$Yes,model_dt$pred$obs)\r\ndt_perf <- performance(dt_pred,\"tpr\",\"fpr\")\r\nplot(dt_perf, add = TRUE, col = \"blue\")\r\n\r\n#ROC Curve for KNN\r\nknn_pred <-prediction(model_knn$pred$Yes,model_knn$pred$obs)\r\nknn_perf <- performance(knn_pred,\"tpr\",\"fpr\")\r\nplot(knn_perf, add = TRUE, col = \"red\")\r\n\r\n#ROC Curve for Neural Network\r\nnnet_pred <-prediction(model_nnet$pred$Yes,model_nnet$pred$obs)\r\nnnet_perf <- performance(nnet_pred,\"tpr\",\"fpr\")\r\nplot(nnet_perf, add = TRUE, col = \"green\")\r\n\r\nlegend(\"right\", legend = c(\"Random Forest\",\"Decision Tree\",\"KNN\",\"Neural Network\"),bty= 'n',cex = 1, lty =1, \r\n       col= c(\"black\",\"blue\",\"red\",\"green\"))\r\n\r\n\r\n\r\n\r\n5.1.2 Using pROC Package\r\n\r\n\r\n#using pROC package\r\n\r\n#ROC Curve for Random Forest\r\nrf_pROC <- roc(model_rf$pred$obs,model_rf$pred$Yes )\r\nplot(rf_pROC, print.auc = TRUE, grid = TRUE, col = \"red\")\r\n\r\n#ROC Curve for Decision Tree\r\ndt_pROC <- roc(model_dt$pred$obs,model_dt$pred$Yes )\r\nplot(dt_pROC, print.auc = TRUE, col = \"blue\", add = TRUE, print.auc.y = .4)\r\n\r\n#ROC Curve for KNN\r\nknn_pROC <- roc(model_knn$pred$obs,model_knn$pred$Yes )\r\nplot(knn_pROC, print.auc = TRUE, col = \"green\", add = TRUE, print.auc.y = .3)\r\n\r\n#ROC Curve for Neural Network\r\nnnet_pROC <- roc(model_nnet$pred$obs,model_nnet$pred$Yes )\r\nplot(nnet_pROC, print.auc = TRUE, col = \"black\", add = TRUE, print.auc.y = .2)\r\n\r\n\r\n\r\n\r\n5.1.3 Using plotROC Package\r\n\r\n\r\n#USing plotROC package\r\n              ggplot() + \r\n              geom_roc(aes(d = obs, m = Yes, color=\"Random Forest\"), model_rf$pred,n.cuts = 0) + #ROC Curve for Random Forest\r\n              geom_roc(aes(d = obs, m = Yes, color=\"Decision Tree\"), model_dt$pred,n.cuts = 0) + #ROC Curve for Decision Tree\r\n              geom_roc(aes(d = obs, m = Yes, color=\"KNN\"), model_knn$pred,n.cuts = 0) + #ROC Curve for KNN \r\n              geom_roc(aes(d = obs, m = Yes, color=\"Neural Network\"), model_nnet$pred,n.cuts = 0) +  #ROC Curve for Neural Network\r\n              scale_color_manual(values=c(\"Random Forest\"=\"red\", \"Decision Tree\"=\"blue\",\"KNN\"=\"green\",\"Neural Network\"=\"black\"), \r\n              name=\"Models\", guide=\"legend\") + \r\n              coord_equal()+\r\n              style_roc(theme = theme_grey,xlab = \"1-Specificity\", ylab =\"Sensitivity\")+\r\n              theme(legend.position = \"bottom\")+\r\n              labs(title=\"ROC Plots Comparison\")\r\n\r\n\r\n\r\n\r\n5.1.4 ROC Package Comparison\r\nBased on report (Robin et al., 2011, p. 12), the pROC is a report dedicated to ROC analysis compared to ROCR. Both pROC and ROCR use simple commands to for plotting the ROC curve. ROCR requiring only 3 commands and pROC* requiring 2 commands for a basic plot. One key difference between the plotROC package and the other two, plotROC allows the use of ggplot’s geoms to plot the ROC curve, enabling usage of the extensive ggplot package. where the other two packages use the base plot function in R.\r\nThus, for the purpose of a ROC visualisation for shiny,plotROC is deemed to be the more appropriate package for it’s usability for plotting via ggplot.\r\n5.2 Obtaining the AUC Table\r\n\r\n\r\nCombineAUC <- calc_auc(ggplot() + \r\n              geom_roc(aes(d = obs, m = Yes,), model_rf$pred))\r\n\r\nAUCdt <- calc_auc(ggplot() + \r\n              geom_roc(aes(d = obs, m = Yes), model_dt$pred)) \r\n\r\nAUCknn <- calc_auc(ggplot() + \r\n              geom_roc(aes(d = obs, m = Yes), model_knn$pred)) \r\n\r\nAUCnnet <- calc_auc(ggplot() + \r\n              geom_roc(aes(d = obs, m = Yes), model_nnet$pred)) \r\n           \r\n\r\nCombineAUC <- bind_rows(CombineAUC,AUCdt,AUCknn,AUCnnet) #Combining AUC values of each model into one dataframe\r\n\r\nModel <-c(\"Random Forest\", \"Decision Tree\",\"kNN\",\"Neural Network\")\r\nAUC <- CombineAUC$AUC\r\nFinalAUC <- data.frame(Model,AUC)\r\n\r\nggplot(FinalAUC, aes( x=Model, y= AUC))+\r\n                  geom_bar(stat = \"Identity\", fill= \"#E7B800\", color =\"black\")+\r\n                  geom_text(aes(y=AUC, ymax= AUC, label = round(AUC, 3)))+\r\n                  coord_flip()+\r\n                  geom_hline(yintercept = AUC[AUC == max(AUC)],color = \"red\",linetype =2)+\r\n                  theme_grey()\r\n\r\n\r\n\r\n\r\nAs seen from both the AUC table and the ROC curve, it is shown the Random Forest model has performed the best with the highest AUC at 0.837 and highest ROC curve.\r\n5.3 Comparing Model Performance via Resampling\r\nThe caret’s resamples() function assist to resampling performance on the final model produced during the model training.It creates summary statistics (mean, min, max, etc.) for each performance metric for the list of models.\r\n\r\n\r\nrvalues <-resamples(list('Random Forest'=model_rf,'Decision Tree'=model_dt,kNN=model_knn, 'Neural Network'=model_nnet))\r\nsummary(rvalues)\r\n\r\n\r\n\r\nCall:\r\nsummary.resamples(object = rvalues)\r\n\r\nModels: Random Forest, Decision Tree, kNN, Neural Network \r\nNumber of resamples: 5 \r\n\r\nROC \r\n                    Min.   1st Qu.    Median      Mean   3rd Qu.\r\nRandom Forest  0.8325592 0.8366193 0.8424705 0.8417187 0.8480867\r\nDecision Tree  0.7774597 0.7819551 0.7825665 0.7841742 0.7869916\r\nkNN            0.7918626 0.7983920 0.8044332 0.8048322 0.8136617\r\nNeural Network 0.6875573 0.7225108 0.7347946 0.7411793 0.7355749\r\n                    Max. NA's\r\nRandom Forest  0.8488579    0\r\nDecision Tree  0.7918983    0\r\nkNN            0.8158115    0\r\nNeural Network 0.8254590    0\r\n\r\nSens \r\n                    Min.   1st Qu.    Median      Mean   3rd Qu.\r\nRandom Forest  0.9515301 0.9533785 0.9548255 0.9558860 0.9574861\r\nDecision Tree  0.9439310 0.9463956 0.9486548 0.9484104 0.9492813\r\nkNN            0.9474225 0.9480386 0.9498870 0.9500945 0.9501027\r\nNeural Network 0.8264531 0.8540041 0.9385911 0.9238097 1.0000000\r\n                    Max. NA's\r\nRandom Forest  0.9622099    0\r\nDecision Tree  0.9537893    0\r\nkNN            0.9550216    0\r\nNeural Network 1.0000000    0\r\n\r\nSpec \r\n                    Min.   1st Qu.    Median      Mean   3rd Qu.\r\nRandom Forest  0.3719008 0.3739669 0.3760331 0.3809917 0.3856749\r\nDecision Tree  0.4001377 0.4008264 0.4166667 0.4137741 0.4228650\r\nkNN            0.3312672 0.3326446 0.3615702 0.3513774 0.3629477\r\nNeural Network 0.0000000 0.0000000 0.4366391 0.3256198 0.5488981\r\n                    Max. NA's\r\nRandom Forest  0.3973829    0\r\nDecision Tree  0.4283747    0\r\nkNN            0.3684573    0\r\nNeural Network 0.6425620    0\r\n\r\nA box-whiskers plot is used to visualized the re-sampling distributions of the models.The best performing model on resamples based on mean ROC score was Random Forest model.Neural network model has the highest sensitivity.\r\n\r\n\r\ntrellis.par.set()\r\nbwplot(rvalues,layout= c(3,1))\r\n\r\n\r\n\r\n\r\n6. Proposed Visualisation from Shiny Module\r\n\r\n7. Conclusion/Reflections\r\nThe purpose of this post was to review the packages available for predictive modeling, how to compare the results of those modes and how to incorporate into a Shiny App. As highlighted in section 3, the caret package was found to be a “wholesome” package when it comes to model building, providing most of the functions required to predictive modeling.\r\nUser of the shiny app would be able to tune and explore the four different models made available. Various visualizations to assess the models were provided for users to assess the parameters and models used.\r\nReferences\r\nProbst, P., Wright, M., & Boulesteix, A.-L. (2019). Hyperparameters and Tuning Strategies for Random Forest. https://arxiv.org/pdf/1804.03515.pdf\r\nBand, A. (2020b, May 23). How to find the optimal value of K in KNN? - Towards Data Science. Medium. https://towardsdatascience.com/how-to-find-the-optimal-value-of-k-in-knn-35d936e554eb#:%7E:text=The%20optimal%20K%20value%20usually,be%20aware%20of%20the%20outliers. 3.Robin, X., Turck, N., Hainard, A., Tiberti, N., Lisacek, F., Sanchez, J. C., & Müller, M. (2011). pROC: an open-source package for R and S+ to analyze and compare ROC curves. BMC Bioinformatics, 12(1), 12. https://doi.org/10.1186/1471-2105-12-77 4.Panchal, F. S., & Panchal, M. (2014). Review on Methods of Selecting Number of Hidden Nodes in Artificial Neural Network. International Journal of Computer Science and Mobile Computing, 3(11), 455–464. https://www.ijcsmc.com/docs/papers/November2014/V3I11201499a19.pdf\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-03-23-decision-tree/decision-tree_files/figure-html5/unnamed-chunk-13-1.png",
    "last_modified": "2021-04-11T18:14:22+08:00",
    "input_file": "decision-tree.utf8.md"
  },
  {
    "path": "posts/2021-02-23-proposal/",
    "title": "Group 5 Proposal",
    "description": "Below is our project proposal detail.",
    "author": [
      {
        "name": "Desmond LIM Pek Loong, HAI Dan, TAY Kai lin",
        "url": "https://example.com/norajones"
      }
    ],
    "date": "2021-02-23",
    "categories": [],
    "contents": "\nMotivation of the project\nWith the outbreak of Covid-19 and recent advancements in vaccination, an important task that public health authorities are looking into is increasing vaccination rates. This would entail looking into the factors that result in an individual undergoing vaccination and how to predict whether an individual would go for the vaccine.\nOur team is interested in drawing a parallel to another 21st century pandemic, the H1N1 virus, which is also known as the swine flu, that broke out in 2009. An extensive study had been conducted by the USA known as the National 2009 H1N1 Flu Survey (NHFS) into the demographics, attitudes towards H1N1 virus or the vaccine, and whether an individual had taken the H1N1 vaccine. This extensive dataset would not just allow us to perform descriptive analytics on how H1N1 vaccination rates vary in USA, but also allows us to do predictions on whether an individual would go for the vaccine.\nData Source\nThe source for our data is provided at the following link: https://www.cdc.gov/nchs/nis/data_files_h1n1.htm\nProblems or issues that the project will address\nThis project will address the following problems:\nDescriptive Analytics: How do vaccination rates vary across states in the USA?\nPredictive Analytics: How do we predict whether an individual would go for the H1N1 vaccine?\nProject Objectives\nThe project aims to use NFHS data to:\nVisualize vaccination receptivity in across states in US\nVisualize the relationships between vaccination and other variables.\nCreate predictive model of vaccination through Logistic regression, Decision tree and random forest\nProposed Scope and Methodology\nData Preparation\nData cleaning will be done using Excel and R. Excel is used as the first preliminary data cleaning to remove columns that will not be used and to combine binary columns into a single column. As for R, we will be using it to remove rows that have blanks for our target variables and to remove columns that have a proportion of blanks above a certain percentage.\nVisualization\nThe first page of the visualization would be our Map. In the Map, we would show how the survey responses and vaccination rates differ across various states in the USA.\nThe second page of the visualization would be our Exploratory Data Analysis (EDA). In our EDA, we will explore the factors that affect H1N1 vaccination. We will have visualizations for both a density plot and a multiplot. The density plot will help users visualize how every factor affects whether an individual would go for vaccination. Users can select the factors to be displayed on the correlation plot. The multiplot will help us to visualize the distribution of our target binary variable according to the factors in the survey. Users can select the factor that they wish to display on the visualization.\nThe third page of the visualization is our logistic regression. The fourth page will showcase the decision tree and random forest model.\nThe last page of the visualization is our Model Comparison.\nEarly prototypes or storyboards\nPage 1: Map\n\n\n\nPage 2: Exploratory Data Analysis (EDA) - Density Plot & Multiplot\n\n\n\nPage 3: Predictive Analytics\n\n\n\nPage 4: Decision Tree/Random Forest\nPage 5: Model Comparison\nR Packages to be used\nPackage Name\nDescription\nShiny and shinydashboard\nFor building interactive web applications with R\ndplyr\nFor effective data manipulation\nreadr\nFor reading excel files in R\nggplot2\nFor plotting various visualizations and EDA\ndlookr\nFor plotting various visualizations and EDA\nrpart\nTo perform recursive partitioning I.e. Decision Tree modelling\nrandomForest\nTo perform random forest modelling\nProject Timeline\n\n\n\nReferences\nComparison of the Logistic Regression, Decision Tree, and Random Forest Models to Predict Red Wine Quality in R: https://towardsdatascience.com/comparison-of-the-logistic-regression-decision-tree-and-random-forest-models-to-predict-red-wine-313d012d6953\nA COMPLETE GUIDE TO RANDOM FOREST IN R: https://www.listendata.com/2014/11/random-forest-with-r.html\nIntroduction to Random Forest in R: https://www.simplilearn.com/tutorials/data-science-tutorial/random-forest-in-r\nLogistic Regression in R: A Classification Technique to Predict Credit Card Default: https://blog.datasciencedojo.com/logistic-regression-in-r-tutorial/\n\n\n\n",
    "preview": "posts/2021-02-23-proposal/picture/1.jpg",
    "last_modified": "2021-03-01T20:45:31+08:00",
    "input_file": "proposal.utf8.md"
  },
  {
    "path": "posts/welcome/",
    "title": "Welcome to G5Project_ISSS602",
    "description": "Welcome to our new blog, G5Project_ISSS602. We hope you enjoy \nreading what we have to say!",
    "author": [
      {
        "name": "Nora Jones",
        "url": "https://example.com/norajones"
      }
    ],
    "date": "2021-02-23",
    "categories": [],
    "contents": "\n\n\n\n",
    "preview": {},
    "last_modified": "2021-02-23T09:26:31+08:00",
    "input_file": {}
  }
]
