[
  {
    "path": "posts/2021-04-25-userguide/",
    "title": "User_Guide",
    "description": "Welcome to the ISSS608 G5 User Guide. This user guide is designed to provide documentation for people who will use our shiny application",
    "author": [
      {
        "name": "Desmond LIM Pek Loong, HAI Dan, TAY Kai Lin",
        "url": {}
      }
    ],
    "date": "2021-04-25",
    "categories": [],
    "contents": "\nUser Guide – Vaccination Survey Analysis and Prediction with Shiny\n2. Agree on Vaccine Distribution and Data Info\nUse this tab to do exploratory data analysis.\n\n\n\nUsers select the factor of interest\nObserve how the graphs are plotted:\nMosaic plot: the intensity of color shading, range of Pearson residuals\nBar chart: count and proportions of values\n\n3.Distribution of Survey\n\n\n\nSelect a demographic of interest\nObserve how the proportions on the graph change\n4. Explanatory Model\nForm the analysis on building the model.There are also two sub tabs, Model Insight and Model Visualization. The data set is also inserted to display by the control button\n\n\n\n4.1 Model Insight\nClick Side bar above to select the variable you want to view\n\n\n\nThen the coordinate bar chart will show like\n\n\n\nAnd the left side, variable explanation will also change.\n\n\n\n4.2 Model Visualization\nFirst is to choose the panel that you want to see\n\n\n\nThen in the first panel, we have odd ratio plot and chiq plot.\nAlso, if you want to see the data set that we use to build the model, you can click the Show data table button.\n\nThen in the second panel, we have side bar to visual more graphs, you can choose diagnose ill fitting plot or KS Chart observation. And we add the defination of each graph in the middle.\n\n\n\n5. Predictive Model\nThe user can choose the data partition for the training and test data. The options available are :\n50% training /50% test,\n60% training /40% test\n70% training /30% test\n80% training /20% test\n\n\n\n2.Next, the user can select the number of k. The parameter called k that refers to the number of groups that a given data sample is to be split into. Of the k subsamples, a single subsample is retained as the validation data for testing the model, and the remaining k − 1 subsamples are used as training data. The cross-validation process is then repeated k times, with each of the k subsamples used exactly once as the validation data.\nThe user will choose the first machine learning model to be used. The user can scroll through the list or type in the key words in the list.\n\n\n\nOnce the first model is chosen, the user can click on update to plot the ROC curve for the model.\n\n\n\nNext, the user can click on the “Confusion Matrix” button to plot the confusion matrix for the first model.\n\n\n\nRepeat step 4 and 5 for the second machine learning model.\n6. Variable Important Tab\nSimilar to the prediction tab, the user can choose the data partition for the training and test data. The options available are :\n50% training /50% test,\n60% training /40% test\n70% training /30% test\n80% training /20% test\nNext, the user can select the number of k.\nThe parameter called k that refers to the number of groups that a given data sample is to be split into. Of the k subsamples, a single subsample is retained as the validation data for testing the model, and the remaining k − 1 subsamples are used as training data. The cross-validation process is then repeated k times, with each of the k subsamples used exactly once as the validation data.\nThe user will choose the first machine learning model to be used. The user can scroll through the list or type in the key words in the list.\nOnce the first model is chosen, the user can click on “Submit” to plot the Variable Importance chart for the model.\n\n\n\nRepeat the step 3 and 4 for the second machine learning model.\n\n\n\n",
    "preview": "posts/2021-04-25-userguide/picture/user_guide_0.PNG",
    "last_modified": "2021-04-25T02:48:07+08:00",
    "input_file": "userguide.utf8.md"
  },
  {
    "path": "posts/2021-03-23-decision-tree/",
    "title": "Predictive Modeling of H1N1 Vaccination",
    "description": "The predictive modeling component of the Shiny application allows the user to customize and use different modeling techniques to build a predictive model to predict whether an individual would take the H1N1 vaccine.",
    "author": [
      {
        "name": "Desmond LIM Pek Loong",
        "url": {}
      }
    ],
    "date": "2021-04-10",
    "categories": [],
    "contents": "\n\nContents\n1. Introduction\n1.1 Purpose\n1.2 Literature Review\n\n2. Data Preparation\n2.1 Data Source\n2.2 Date Wrangling and Cleaning\n\n3 Modeling\n3.1 Choosing the right Modeling Package\n3.2 Data Splitting\n3.3 Model Tuning\n\n4. Plotting Variable Importance\n5. Model Comparision by ROC/AUC and Visualisations\n5.1 Comparing ROC Packages\n5.1.1 Using ROCR Package\n5.1.2 Using pROC Package\n5.1.3 Using plotROC Package\n5.1.4 ROC Package Comparison\n\n5.2 Obtaining the AUC Table\n5.3 Comparing Model Performance via Resampling\n\n6. Proposed Visualisation from Shiny Module\n7. Conclusion/Reflections\nReferences\n\n1. Introduction\nWith the ongoing COVID-19 pandemic, the world is experiencing first-hand on how a virus could affect economy, society and the deaths that it could cause. The importance of having a vaccine and having the general population taking the vaccine is key to curbing the spread of the virus and saving lives.\nA similar situation was the H1N1 virus pandemic which occurred in 2009, where an estimated amount of 151,700-575,400 people worldwide had died during the first year of the virus. Being able to predict which individuals are likely to receive their H1N1 vaccinations, it will guide governments, health officials to know what are the important predictors that lead them to take the H1N1 vaccine. This understanding would be useful in future efforts to promote vaccination to the public, especially when a vaccine for the current pandemic is made.\n1.1 Purpose\nThe purpose of the study is to develop various predictive models on the individuals who are likely to take the H1N1 vaccine based on the flu survey data , to be able to assess the models for the optimal model and visualize the assessment.\n1.2 Literature Review\nWe looked at two shiny featuring model predictions to gain insight on what functions and features our predictive model app should include.\nThe first application was created by Vladislav Fridkin (Fridkin, n.d.) on interactive mushroom edibility predictions with XGboost model. The application uses XGBoost algorithm to predict if a mushroom is edible or poisonous. The user was given the flexibility to adjust 8 different parameters to obtain the best model. It showed visualizations on model accuracy and feature importance. The application was good with the customizabilty of the model parameters, however it seemed limited with by focusing only on one algorithm for modeling.\nThe second application predict payments on individual insurance claims using machine learning built by (Merlino, 2018). The application uses logistic regression and XGboost model to fit different parts of their models. The application does not allow any flexibility to their predictive model as there are no user inputs for the model.The user can only vary the confidence interval of the results.The visualization shown is the simulation results of claims.\nThus, after looking into the two applications, we find that to enhance the user experience and usefulness for predictive modeling application, the application must provide the user the flexibility to compare between different prediction algorithms and ability to tune those models. Visualization of the modeling results will be shown to allow the user to relate the parameters he had used to the model performance.\n2. Data Preparation\nThe data used was obtained from the United States Centre of Disease Control and Prevention (CDC)’s website https://www.cdc.gov/nchs/nis/data_files_h1n1.htm on the National 2009 H1N1 flu survey conducted in the US.\n2.1 Data Source\nThe dataset in excel format was imported by read_csv into the RStudio environment. The following code was used to launch the mentioned packages in R.\n\n\n#R packages used to modelling and visualization\n\npackages = c('tidyverse','readr','caret','caTools','ggpubr','ROCR','pROC','plotROC','plotly')\nfor (p in packages){\n  if(!require(p, character.only = T)){\n  install.packages(p)\n  }\n  library(p,character.only= T ) \n} \n\n\n\n\n\nH1N1 <- read_csv('data/H1N1_Final_dan_edit.csv')\n\nglimpse(H1N1)\n\n\n\nCheck for missing data i.e NA is conducted on the data. Variables with missing data were noted down.\n\n\ncolMeans(is.na(H1N1))\n\n\n       VACC_H1N1_F        VACC_SEAS_F       B_H1N1_ANTIV \n       0.005694632        0.005652346        0.203865020 \n      B_H1N1_AVOID       B_H1N1_FMASK       B_H1N1_HANDS \n       0.207910465        0.201976207        0.202765562 \n      B_H1N1_LARGE       B_H1N1_RCONT       B_H1N1_TOUCH \n       0.203794542        0.203963690        0.205373252 \n     CONCERN LEVEL               HQ23               HQ24 \n       0.000000000        0.854434484        0.962717073 \n            HQ24_B           INT_H1N1           INT_NEXT \n       0.994587280        0.000000000        0.000000000 \n          INT_SEAS          KNOW_H1N1                Q23 \n       0.000000000        0.000000000        0.960165765 \n               Q24              Q24_B             DOCREC \n       0.977136897        0.996447903        0.000000000 \n   ILI_DIAG_H1N1_F    ILI_DIAG_SEAS_F              ILI_F \n       0.961913622        0.961913622        0.020889716 \n       ILI_OTHER_F        ILI_TREAT_F              PSL_1 \n       0.017083897        0.922488160        1.000000000 \n             PSL_2                 Q9             Q9_NUM \n       1.000000000        1.000000000        1.000000000 \n     CHRONIC_MED_F   CLOSE_UNDER6MO_F    HEALTH_WORKER_F \n       0.031799729        0.226291159        0.225713239 \n PATIENT_CONTACT_F             AGEGRP     EDUCATION_COMP \n       0.265195083        0.000000000        0.244009359 \n        HH_CHILD_R             HISP_I           INC_CAT1 \n       0.007132386        0.000000000        0.214436739 \n            INSURE            MARITAL          N_ADULT_R \n       1.000000000        0.244544993        0.007132386 \n        N_PEOPLE_R                Q95         Q95_INDSTR \n       0.003157420        0.994432228        0.595554240 \n         Q95_OCCPN         RACEETH4_I         RENT_OWN_R \n       0.595554240        0.000000000        0.983451737 \n             SEX_I              STATE REAS_NOH1N1_AHAD_F \n       0.000000000        0.000000000        0.399484100 \nREAS_NOH1N1_ALLG_F REAS_NOH1N1_CANT_F REAS_NOH1N1_COST_F \n       0.399484100        0.399484100        0.399484100 \nREAS_NOH1N1_DKNW_F REAS_NOH1N1_DWRK_F REAS_NOH1N1_GOTO_F \n       0.399484100        0.399484100        0.399484100 \nREAS_NOH1N1_NDOC_F REAS_NOH1N1_NEVR_F REAS_NOH1N1_NNDD_F \n       0.399484100        0.399484100        0.399484100 \nREAS_NOH1N1_NOTA_F REAS_NOH1N1_OTHR_F REAS_NOH1N1_REFD_F \n       0.399484100        0.399484100        0.399484100 \nREAS_NOH1N1_SAVE_F REAS_NOH1N1_SEFF_F REAS_NOH1N1_TIME_F \n       0.399484100        0.399484100        0.399484100 \n\n2.2 Date Wrangling and Cleaning\nBefore the dataset can be used for modelling, the missing data would need to processed.\nThe following section focused on wrangling the data set and cleaning up missing variables. The code below is used to remove the missing data from the target variable, VACC_H1N1_F.\n\n\n#exclude the NA column in the target variable\nH1N1 <- H1N1 %>%\n  filter(!is.na(VACC_H1N1_F))\n\n\n\n\n\nnames(H1N1)[names(H1N1) == 'CONCERN LEVEL'] <- \"CONCERN_LEVEL\" #Renaming of variable \"Concern Level\"\n\n\n\n\n\nH1N1[H1N1 == '#N/A'] <- NA # Changing all the value with \"#N/A\" to actual missing value.\n\n\n\n\n\ncolMeans(is.na(H1N1)) #Check for missing values again.\n\n\n       VACC_H1N1_F        VACC_SEAS_F       B_H1N1_ANTIV \n       0.000000000        0.003997732        0.203132974 \n      B_H1N1_AVOID       B_H1N1_FMASK       B_H1N1_HANDS \n       0.207201588        0.201360930        0.202098100 \n      B_H1N1_LARGE       B_H1N1_RCONT       B_H1N1_TOUCH \n       0.203189680        0.203274738        0.204678197 \n     CONCERN_LEVEL               HQ23               HQ24 \n       0.203473207        0.854834137        0.963198185 \n            HQ24_B           INT_H1N1           INT_NEXT \n       0.994740573        0.255146016        0.692755883 \n          INT_SEAS          KNOW_H1N1                Q23 \n       0.459625744        0.204479728        0.960518855 \n               Q24              Q24_B             DOCREC \n       0.977417068        0.996597675        0.044031755 \n   ILI_DIAG_H1N1_F    ILI_DIAG_SEAS_F              ILI_F \n       0.961993195        0.961993195        0.020484831 \n       ILI_OTHER_F        ILI_TREAT_F              PSL_1 \n       0.016869861        0.922497874        1.000000000 \n             PSL_2                 Q9             Q9_NUM \n       1.000000000        1.000000000        1.000000000 \n     CHRONIC_MED_F   CLOSE_UNDER6MO_F    HEALTH_WORKER_F \n       0.031216331        0.225333144        0.224766090 \n PATIENT_CONTACT_F             AGEGRP     EDUCATION_COMP \n       0.264346470        0.000000000        0.242968528 \n        HH_CHILD_R             HISP_I           INC_CAT1 \n       0.007074001        0.000000000        0.213198185 \n            INSURE            MARITAL          N_ADULT_R \n       1.000000000        0.243592288        0.007074001 \n        N_PEOPLE_R                Q95         Q95_INDSTR \n       0.003118798        0.994527927        0.594074284 \n         Q95_OCCPN         RACEETH4_I         RENT_OWN_R \n       0.594074284        0.000000000        0.983612135 \n             SEX_I              STATE REAS_NOH1N1_AHAD_F \n       0.000000000        0.000000000        0.401020697 \nREAS_NOH1N1_ALLG_F REAS_NOH1N1_CANT_F REAS_NOH1N1_COST_F \n       0.401020697        0.401020697        0.401020697 \nREAS_NOH1N1_DKNW_F REAS_NOH1N1_DWRK_F REAS_NOH1N1_GOTO_F \n       0.401020697        0.401020697        0.401020697 \nREAS_NOH1N1_NDOC_F REAS_NOH1N1_NEVR_F REAS_NOH1N1_NNDD_F \n       0.401020697        0.401020697        0.401020697 \nREAS_NOH1N1_NOTA_F REAS_NOH1N1_OTHR_F REAS_NOH1N1_REFD_F \n       0.401020697        0.401020697        0.401020697 \nREAS_NOH1N1_SAVE_F REAS_NOH1N1_SEFF_F REAS_NOH1N1_TIME_F \n       0.401020697        0.401020697        0.401020697 \n\nData will more than 50% of missing values are removed. 27 variables are wrangled into a new data set h1n1data.\n\n\nh1n1data <-H1N1 %>%\n  select(VACC_H1N1_F,\n                   VACC_SEAS_F,\n                   B_H1N1_ANTIV,\n                   B_H1N1_AVOID,\n                   B_H1N1_FMASK,\n                   B_H1N1_HANDS,\n                   B_H1N1_LARGE,\n                   B_H1N1_RCONT,\n                   B_H1N1_TOUCH,\n                   CONCERN_LEVEL,\n                   INT_H1N1,\n                   KNOW_H1N1,\n                   INT_SEAS,  \n                   DOCREC,\n                   CHRONIC_MED_F,\n                   CLOSE_UNDER6MO_F,         \n                   HEALTH_WORKER_F,\n                   PATIENT_CONTACT_F,\n                   AGEGRP,\n                   EDUCATION_COMP,\n                   HH_CHILD_R,\n                   INC_CAT1,\n                   MARITAL,\n                   RACEETH4_I,\n                   N_ADULT_R,\n                   SEX_I,\n                   STATE)\n\n\n\nThe column variables are transformed in factor(categorical) variables.\n\n\nh1n1data <- transform(h1n1data,\n                   VACC_H1N1_F= as.factor(VACC_H1N1_F),\n                   VACC_SEAS_F= as.factor(VACC_SEAS_F),\n                   B_H1N1_ANTIV= as.factor(B_H1N1_ANTIV),\n                   B_H1N1_AVOID= as.factor(B_H1N1_AVOID),\n                   B_H1N1_FMASK= as.factor(B_H1N1_FMASK),\n                   B_H1N1_HANDS= as.factor(B_H1N1_HANDS),\n                   B_H1N1_LARGE= as.factor(B_H1N1_LARGE),\n                   B_H1N1_RCONT= as.factor(B_H1N1_RCONT),\n                   B_H1N1_TOUCH= as.factor(B_H1N1_TOUCH),\n                   CONCERN_LEVEL= as.factor(CONCERN_LEVEL),\n                   INT_H1N1= as.factor(INT_H1N1),\n                   KNOW_H1N1= as.factor(KNOW_H1N1),\n                   DOCREC= as.factor(DOCREC),\n                   CHRONIC_MED_F= as.factor(CHRONIC_MED_F),\n                   CLOSE_UNDER6MO_F= as.factor(CLOSE_UNDER6MO_F),\n                   HEALTH_WORKER_F= as.factor(HEALTH_WORKER_F),\n                   AGEGRP= as.factor(AGEGRP),\n                   EDUCATION_COMP= as.factor(EDUCATION_COMP),\n                   HH_CHILD_R= as.factor(HH_CHILD_R),\n                   INC_CAT1= as.factor(INC_CAT1),\n                   MARITAL= as.factor(MARITAL),\n                   RACEETH4_I= as.factor(RACEETH4_I),\n                   N_ADULT_R= as.factor(N_ADULT_R),\n                   SEX_I= as.factor(SEX_I),\n                   STATE= as.factor(STATE),\n                   PATIENT_CONTACT_F = as.factor(PATIENT_CONTACT_F),\n                   INT_SEAS = as.factor(INT_SEAS)\n                   )\n\n\n\nThe code below added a column which recoded the various states into regions.\n\n\nregion <- read_csv(\"data/state_region.csv\")\n\n\n\n\n\nh1n1data$state_recoded <- str_to_title(h1n1data$STATE)\nh1n1data <- left_join(h1n1data, region,\n                      by=c(\"state_recoded\" = \"State\"))\n\n\n\n\n\nsummary(h1n1data)\n\n\n VACC_H1N1_F VACC_SEAS_F  B_H1N1_ANTIV B_H1N1_AVOID B_H1N1_FMASK\n No :53471   No  :38210   No  :53438   No  :15263   No  :52444  \n Yes:17069   Yes :32048   Yes : 2773   Yes :40661   Yes : 3892  \n             NA's:  282   NA's:14329   NA's:14616   NA's:14204  \n                                                                \n                                                                \n                                                                \n                                                                \n B_H1N1_HANDS B_H1N1_LARGE B_H1N1_RCONT B_H1N1_TOUCH CONCERN_LEVEL\n No  : 9813   No  :36252   No  :37220   No  :17939   0   : 6861   \n Yes :46471   Yes :19955   Yes :18981   Yes :38163   1   :17218   \n NA's:14256   NA's:14333   NA's:14339   NA's:14438   2   :22490   \n                                                     3   : 9618   \n                                                     NA's:14353   \n                                                                  \n                                                                  \n INT_H1N1     KNOW_H1N1    INT_SEAS      DOCREC      CHRONIC_MED_F\n 0   :17731   0   :30895   0   :15490   0   : 1948   No  :51265   \n 1   :19663   1   : 5251   1   :13543   1   :40462   Yes :17073   \n 2   : 9961   2   :19970   2   : 5670   2   : 8687   NA's: 2202   \n 3   : 5187   NA's:14424   3   : 3415   3   : 2534                \n NA's:17998                NA's:32422   4   :13803                \n                                        NA's: 3106                \n                                                                  \n CLOSE_UNDER6MO_F HEALTH_WORKER_F PATIENT_CONTACT_F\n No  :50032       No  :48599      No  :46951       \n Yes : 4613       Yes : 6086      Yes : 4942       \n NA's:15895       NA's:15855      NA's:18647       \n                                                   \n                                                   \n                                                   \n                                                   \n                AGEGRP               EDUCATION_COMP  HH_CHILD_R  \n 10 - 17 Years     : 6833   < 12 Years      : 4995   0   :39356  \n 18 - 34 Years     :11037   12 Years        :12158   1   :12383  \n 35 - 44 Years     : 8243   College Graduate:21376   2   :11333  \n 45 - 54 Years     :11071   Some College    :14872   3   : 6969  \n 55 - 64 Years     :11685   NA's            :17139   NA's:  499  \n 6 Months - 9 Years: 7332                                        \n 65+ Years         :14339                                        \n               INC_CAT1            MARITAL     \n $75,001 - $100,000:19781   Married    :28539  \n $50,001 - $75,000 : 9985   Not Married:24818  \n $35,001 - $50,000 : 7976   NA's       :17183  \n $15,001 - $25,000 : 5805                      \n $25,001 - $35,000 : 5134                      \n (Other)           : 6820                      \n NA's              :15039                      \n                                 RACEETH4_I    N_ADULT_R   \n Hispanic                             : 5469   1   :18654  \n Non-Hispanic, Black Only             : 5776   2   :40293  \n Non-Hispanic, Other or Multiple Races: 4626   3   : 7996  \n Non-Hispanic, White Only             :54669   4   : 3098  \n                                               NA's:  499  \n                                                           \n                                                           \n    SEX_I                        STATE       state_recoded     \n Female:40314   TEXAS               : 1720   Length:70540      \n Male  :30226   NEW MEXICO          : 1678   Class :character  \n                CALIFORNIA          : 1637   Mode  :character  \n                GEORGIA             : 1605                     \n                MARYLAND            : 1584                     \n                DISTRICT OF COLUMBIA: 1581                     \n                (Other)             :60735                     \n    Region         \n Length:70540      \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\nThe predictors are plotted against the target variable to check for complete or quasi-complete separation.\n\n\n\n\n\nPlots I\n\n\n\n\n\nPlots II\n\n\n\n\nPlots III\n\n\n\n\n\nThe new dataframe h1n1model is created. 3 variables with complete/quasi-complete separation were removed.\n\n\nh1n1model <- h1n1data #new dataframe for predictive modeling\n              \n\nh1n1model <-select(h1n1model,-c(INT_H1N1,B_H1N1_ANTIV,INT_SEAS, state_recoded, Region)) #Remove variable with complete separation from dataset.\n\n\nh1n1model <- h1n1model %>% #Omitting na in order as some models unable to process with missing values. \n             na.omit\n\nsummary(h1n1model) #To check the data again.\n\n\n VACC_H1N1_F VACC_SEAS_F B_H1N1_AVOID B_H1N1_FMASK B_H1N1_HANDS\n No :30432   No :20780   No :10338    No :36863    No : 6618   \n Yes: 9075   Yes:18727   Yes:29169    Yes: 2644    Yes:32889   \n                                                               \n                                                               \n                                                               \n                                                               \n                                                               \n B_H1N1_LARGE B_H1N1_RCONT B_H1N1_TOUCH CONCERN_LEVEL KNOW_H1N1\n No :25744    No :26430    No :12467    0: 4486       0:21859  \n Yes:13763    Yes:13077    Yes:27040    1:12541       1: 2903  \n                                        2:16183       2:14745  \n                                        3: 6297                \n                                                               \n                                                               \n                                                               \n DOCREC    CHRONIC_MED_F CLOSE_UNDER6MO_F HEALTH_WORKER_F\n 0:  917   No :28467     No :36077        No :34785      \n 1:24438   Yes:11040     Yes: 3430        Yes: 4722      \n 2: 5363                                                 \n 3: 1271                                                 \n 4: 7518                                                 \n                                                         \n                                                         \n PATIENT_CONTACT_F                AGEGRP              EDUCATION_COMP \n No :35658         10 - 17 Years     :   0   < 12 Years      : 3300  \n Yes: 3849         18 - 34 Years     :8122   12 Years        : 8593  \n                   35 - 44 Years     :6220   College Graduate:16515  \n                   45 - 54 Years     :8283   Some College    :11099  \n                   55 - 64 Years     :8367                           \n                   6 Months - 9 Years:   0                           \n                   65+ Years         :8515                           \n HH_CHILD_R               INC_CAT1            MARITAL     \n 0:27196    $10,001 - $15,000 : 1979   Married    :21477  \n 1: 4939    $15,001 - $25,000 : 4335   Not Married:18030  \n 2: 4570    $25,001 - $35,000 : 3826                      \n 3: 2802    $35,001 - $50,000 : 5879                      \n            $50,001 - $75,000 : 7082                      \n            $75,001 - $100,000:13303                      \n            <= $10,000        : 3103                      \n                                 RACEETH4_I    N_ADULT_R\n Hispanic                             : 2581   1:11389  \n Non-Hispanic, Black Only             : 3083   2:22005  \n Non-Hispanic, Other or Multiple Races: 2274   3: 4399  \n Non-Hispanic, White Only             :31569   4: 1714  \n                                                        \n                                                        \n                                                        \n    SEX_I                        STATE      \n Female:23154   NEW MEXICO          :  964  \n Male  :16353   DISTRICT OF COLUMBIA:  926  \n                TEXAS               :  926  \n                CALIFORNIA          :  896  \n                ARIZONA             :  878  \n                VIRGINIA            :  863  \n                (Other)             :34054  \n\n3 Modeling\n3.1 Choosing the right Modeling Package\nThe R caret package is a set of functions that streamlines the process for predictive model building. It’s current release consist 238 models.As different modeling functions has different syntax for modeling training and prediction, it will be difficult to keep track of which algorithms are in which package. For example, a random forest model will be using randomforest() syntax to run the model and a neural network model requires the neuralnet() syntax. Moreover, each of the algorithm will have their own arguments, making it difficult and time-consuming if different models are required to be used in the same code.\nThere is no need to call for the library for the different modeling packages using caret. caret will assist to load the required packages when used and if the package is missing, there will be a prompt for installation.\nThe train() function in caret has multiple functions:\nBuilding a model using a specific algorithm\nCross validating the model\nTune the parameters for optimal model performance\nChoose the optimal model based on a given evaluation metric\nPreprocessing\nThe caret package made it easier by combining the data pre-processing, model hyperparameter tuning within the same package. It allows quick change of model with minor syntax change, allowing it the most suitable model to be found.\n3.2 Data Splitting\nAs the H1N1 vaccination (VACC_H1N1_F) is the target variable is important for analysis, a balance of the target variable across the training/test sets, the function createDataPartition was used to create training/testing sets using stratified random sampling.\nData is split with 80% as training data and 20% are testing data.In place of partitioning a validation dataset, the traincontrol function is used for the cross-validation of the training data set.\nThe below code shows the spliting of the dataset.\n\n\nset.seed(123)\n\n# define an 80%/20% train/test split of the h1n1model data set\nsplit=0.80 \ntrainIndex <- createDataPartition(h1n1model$VACC_H1N1_F, p=split, list=FALSE)\ndata_train <- h1n1model[ trainIndex,]\ndata_test <- h1n1model[-trainIndex,]\n\n\n\n3.3 Model Tuning\nThe function trainControl generates parameters that further control how models are created, with different resampling methods like bootstrap re-sampling, k-fold cross validation. In the code below, the k-fold cross validation method with number = referring to the number of folds being used. The repeated k-fold cross validation method involves splitting the dataset into k-subsets and repeating in a number of time. For each subset is held out while the model is trained on all other subsets. This process is completed until accuracy is determine for each instance in the dataset, and an overall accuracy estimate is provided.\n\n\nfitControl <- trainControl(\n  method = \"cv\",\n  number = 5,\n  classProbs = TRUE,\n  summaryFunction = twoClassSummary, #twoClassSummary computes the sensitivity, specificity and aread under the ROC curve. \n  savePredictions = TRUE)\n\n\n\nThere are two main ways of tuning the model within the caret package, using tuneLength or tuneGrid.\nThe tuneLength parameter allows the user to enter a value which will determine the number of default values being used as the main parameter for a specific model. The number used can be applicable throughout all the models. The tuneGrid function create a dataframe to store the tuning parameter grid specified by the user. It allows the user to determine which are the values a model will take as it’s main parameter. The parameters in the tuneGrid is model specific. Using tuneGrid will be more applicable as it provides the user more model customizability and fine tuning.\nFor random forest using the ranger method in caret, three options are available for tuning the model. Firstly, mtry which refers to the number of variables randomly sampled as candidates at each split. Split rule defines which splitting method is used. The default used is Gini where the split minimizes the the Gini impurtity for classification. The minimum node size refers to the minimum number of observations in a terminal node.\nAccording the research (Probst et al.,2019), mtry has the most influence over the model performance and the best value of mtry depends on the number of variables that are related to the outcome.\n\n\n# Random Forest:\nset.seed(123)\n\nm=4\nns=10\n\nrf_grid <- expand.grid(\n                mtry = 2:m,\n                splitrule =\"gini\",\n                min.node.size = 10\n                      )\n\nmodel_rf <- train(VACC_H1N1_F~., \n                  data=data_train, \n                  trControl = fitControl, \n                  method = \"ranger\",\n                  metric = \"ROC\",\n                  importance = \"impurity\",\n                  tuneGrid = rf_grid)\n\nmodel_rf\n\n\nRandom Forest \n\n31606 samples\n   23 predictor\n    2 classes: 'No', 'Yes' \n\nNo pre-processing\nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 25285, 25285, 25284, 25285, 25285 \nResampling results across tuning parameters:\n\n  mtry  ROC        Sens       Spec     \n  2     0.8335559  0.9952764  0.0738292\n  3     0.8390148  0.9692352  0.2856749\n  4     0.8417187  0.9558860  0.3809917\n\nTuning parameter 'splitrule' was held constant at a value of\n gini\nTuning parameter 'min.node.size' was held constant at a\n value of 10\nROC was used to select the optimal model using the largest value.\nThe final values used for the model were mtry = 4, splitrule =\n gini and min.node.size = 10.\n\nThe rpart2 method within the caret package allows for the tuning for the maximum depth of the tree. This tuning variable can help to limit the decsion tree model from growing too deep which might cause over-fitting.\n\n\n#Decision Tree\nset.seed(123)\n\ndepth = 5 #User-defined maximum depth of decision tree\n\ndt_grid<- expand.grid(maxdepth = depth)\n\nmodel_dt <- train(VACC_H1N1_F~., \n                  data=data_train, \n                  trControl = fitControl, \n                  method = \"rpart2\",\n                  metric = \"ROC\",\n                  tuneGrid = dt_grid\n                  )\n\nmodel_dt\n\n\nCART \n\n31606 samples\n   23 predictor\n    2 classes: 'No', 'Yes' \n\nNo pre-processing\nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 25285, 25285, 25284, 25285, 25285 \nResampling results:\n\n  ROC        Sens       Spec     \n  0.7841742  0.9484104  0.4137741\n\nTuning parameter 'maxdepth' was held constant at a value of 5\n\nThe principle behind K-Nearest Neighbor(KNN) algorithm is to find K predefined number of training samples that are closest in the distance to a new point & predict a label for our new point using these samples. For classification the KNN method starts by identifying the k most similar training observations (i.e. neighbors) to the new observation, and then assigns the observation to the class containing the majority of its neighbors.\nThe choice of k considerably impacts the output of KNN model. k = 1 corresponds to a highly flexible method resulting to a training error rate of 0 (over-fitting), but the test error rate may be quite high. The value of optimal k is usually the square root of N, where N is the total number of samples.\n\n\n#K-Nearest Neighbors\nset.seed(123)\n\nkv=10  #User-defined k value\n\nknn_grid <- expand.grid(k= kv)\n\nmodel_knn <- train(VACC_H1N1_F~., \n                  data=data_train, \n                  trControl = fitControl, \n                  method = \"knn\",\n                  metric = \"ROC\",\n                  tuneGrid = knn_grid\n                  )\n\nmodel_knn\n\n\nk-Nearest Neighbors \n\n31606 samples\n   23 predictor\n    2 classes: 'No', 'Yes' \n\nNo pre-processing\nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 25285, 25285, 25284, 25285, 25285 \nResampling results:\n\n  ROC        Sens       Spec     \n  0.8048322  0.9500945  0.3513774\n\nTuning parameter 'k' was held constant at a value of 10\n\nFor the neural network(nnet) model,there are two tuning parameters, which need to be set. First is the number of nodes in the hidden layer and second, it is the value of the “weight decay” parameter.\nThe hidden layer of the neural network is the intermediate layer between the input and output layer of a neuron network (Panchal & Panchal, 2014, p. 460). The hidden nodes might cause overfitting when too many neurons(hidden nodes) are present in the network. The purpose of the weight decay factor is to prevent overfitting.\n\n\n#Neural Network  \nset.seed(123)\n\nsz = 1 #User-defined number of hidden nodes\ndc = 0 #USer-defined decay rate\n\nnnet_grid <- expand.grid( size = sz,\n                          decay = dc)\n\n\nmodel_nnet <- train(VACC_H1N1_F~., \n                  data=data_train, \n                  trControl = fitControl, \n                  method = \"nnet\",\n                  metric = \"ROC\",\n                  tuneGrid = nnet_grid\n                  )\n\n\n# weights:  99\ninitial  value 26589.627274 \niter  10 value 13626.461983\niter  20 value 13376.340522\niter  30 value 12915.052594\niter  40 value 12606.753114\niter  50 value 12331.349382\niter  60 value 11946.723445\niter  70 value 11776.270369\niter  80 value 11732.724596\niter  90 value 11718.627201\niter 100 value 11717.572046\nfinal  value 11717.572046 \nstopped after 100 iterations\n# weights:  99\ninitial  value 17171.750195 \niter  10 value 11380.634022\niter  20 value 11309.563841\niter  30 value 11278.590198\niter  40 value 11264.527582\niter  50 value 11259.782750\niter  60 value 11256.844758\niter  70 value 11253.710980\niter  80 value 11241.607724\niter  90 value 11232.658714\niter 100 value 11232.389316\nfinal  value 11232.389316 \nstopped after 100 iterations\n# weights:  99\ninitial  value 19684.645375 \niter  10 value 10712.335323\niter  20 value 10503.529519\niter  30 value 10471.490428\niter  40 value 10447.308989\niter  50 value 10426.685950\niter  60 value 10414.830002\niter  70 value 10410.289543\niter  80 value 10409.708839\nfinal  value 10409.698890 \nconverged\n# weights:  99\ninitial  value 17241.041006 \niter  10 value 13626.329956\niter  20 value 12536.157114\niter  30 value 11488.105019\niter  40 value 11293.383176\niter  50 value 11148.360692\niter  60 value 11045.260594\niter  70 value 10976.829467\niter  80 value 10943.918263\niter  90 value 10928.649520\niter 100 value 10914.121349\nfinal  value 10914.121349 \nstopped after 100 iterations\n# weights:  99\ninitial  value 16605.060349 \niter  10 value 12063.508758\niter  20 value 11550.729798\niter  30 value 11528.194364\niter  40 value 11510.989549\niter  50 value 11503.611516\niter  60 value 11493.210692\niter  70 value 11487.004214\niter  80 value 11481.522394\niter  90 value 11473.852666\niter 100 value 11468.934232\nfinal  value 11468.934232 \nstopped after 100 iterations\n# weights:  99\ninitial  value 18646.728694 \niter  10 value 14221.978222\niter  20 value 14022.646547\niter  30 value 13911.598167\niter  40 value 13319.594765\niter  50 value 12953.457998\niter  60 value 12841.826303\niter  70 value 12639.090264\niter  80 value 12554.912863\niter  90 value 12535.639135\niter 100 value 12531.439084\nfinal  value 12531.439084 \nstopped after 100 iterations\n\nmodel_nnet\n\n\nNeural Network \n\n31606 samples\n   23 predictor\n    2 classes: 'No', 'Yes' \n\nNo pre-processing\nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 25285, 25285, 25284, 25285, 25285 \nResampling results:\n\n  ROC        Sens       Spec     \n  0.7411793  0.9238097  0.3256198\n\nTuning parameter 'size' was held constant at a value of 1\n\nTuning parameter 'decay' was held constant at a value of 0\n\n4. Plotting Variable Importance\nVariable importance helps to identify most important variables that contribute most significantly to the target variable.Being able to select the most important predictor variables that explains the major part of variance of a target variable can help to identify and build high performing models.\nThe variable importance of each trained model is plotted.(Note:kNN does not have variable importance)\n\n\nVariable Importance of Random Forest\n\n\nrfImp <- varImp(model_rf)\ndtImp <- varImp(model_dt)\nnnetImp <- varImp(model_nnet)\n\nNo_Var=5 #No.of variable importance to be shown can be user-defined.\n\ng1 <- rfImp$importance %>% \n  as.data.frame() %>%\n  rownames_to_column() %>%\n  arrange(Overall) %>%\n  mutate(rowname = forcats::fct_inorder(rowname )) %>%\n  top_n(No_Var,Overall) %>%  #top 5 Importance\n  ggplot(aes(x = rowname, y = Overall))+\n    geom_col(color=\"black\",fill = \"light blue\")+\n    coord_flip()+\n    xlab(\"Variable\")+\n    ggtitle(\"Variable Importance of Random Forest Model\") + \n    theme_minimal() +\n    theme(panel.background = element_rect(fill = \"gray80\", color = \"gray80\", size =0.5, linetype = \"solid\"),\n       panel.grid.major = element_line(size =0.5, linetype = \"solid\", color = \"white\"), #major refers to grid line at values\n       panel.grid.minor = element_line(size =0.25, linetype = \"solid\", color = \"white\")) # minor refers line in between grid values\n\nggplotly(g1, tooltip = c(\"rowname\", \"Overall\"))\n\n\n\n{\"x\":{\"data\":[{\"orientation\":\"h\",\"width\":[0.9,0.9,0.9,0.9,0.9],\"base\":[0,0,0,0,0],\"x\":[18.2359585268045,24.8869169214332,30.709481313405,69.2805079158989,100],\"y\":[1,2,3,4,5],\"text\":[\"rowname: HEALTH_WORKER_FYes<br />Overall:  18.23596\",\"rowname: DOCREC2<br />Overall:  24.88692\",\"rowname: DOCREC1<br />Overall:  30.70948\",\"rowname: DOCREC4<br />Overall:  69.28051\",\"rowname: VACC_SEAS_FYes<br />Overall: 100.00000\"],\"type\":\"bar\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(173,216,230,1)\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(0,0,0,1)\"}},\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":45.4063926940639,\"r\":7.30593607305936,\"b\":41.8264840182648,\"l\":130.776255707763},\"plot_bgcolor\":\"rgba(204,204,204,1)\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187},\"title\":{\"text\":\"Variable Importance of Random Forest Model\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":17.5342465753425},\"x\":0,\"xref\":\"paper\"},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[-5,105],\"tickmode\":\"array\",\"ticktext\":[\"0\",\"25\",\"50\",\"75\",\"100\"],\"tickvals\":[0,25,50,75,100],\"categoryorder\":\"array\",\"categoryarray\":[\"0\",\"25\",\"50\",\"75\",\"100\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(255,255,255,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"Overall\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[0.4,5.6],\"tickmode\":\"array\",\"ticktext\":[\"HEALTH_WORKER_FYes\",\"DOCREC2\",\"DOCREC1\",\"DOCREC4\",\"VACC_SEAS_FYes\"],\"tickvals\":[1,2,3,4,5],\"categoryorder\":\"array\",\"categoryarray\":[\"HEALTH_WORKER_FYes\",\"DOCREC2\",\"DOCREC1\",\"DOCREC4\",\"VACC_SEAS_FYes\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(255,255,255,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\"Variable\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":null,\"line\":{\"color\":null,\"width\":0,\"linetype\":[]},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false,\"legend\":{\"bgcolor\":null,\"bordercolor\":null,\"borderwidth\":0,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.689497716895}},\"hovermode\":\"closest\",\"barmode\":\"relative\"},\"config\":{\"doubleClick\":\"reset\",\"showSendToCloud\":false},\"source\":\"A\",\"attrs\":{\"1890658726e\":{\"x\":{},\"y\":{},\"type\":\"bar\"}},\"cur_data\":\"1890658726e\",\"visdat\":{\"1890658726e\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\n\n\nVariable Importance of Decision Tree\n\n\ng2 <- dtImp$importance %>% \n  as.data.frame() %>%\n  rownames_to_column() %>%\n  arrange(Overall) %>%\n  mutate(rowname = forcats::fct_inorder(rowname )) %>%\n  top_n(No_Var,Overall) %>%  #top 5 Importance\n  ggplot(aes(x = rowname, y = Overall))+\n    geom_col(color=\"black\",fill = \"light blue\")+\n    coord_flip()+\n    xlab(\"Variable\")+\n    ggtitle(\"Variable Importance of Decision Tree Model\") + \n    theme_minimal() +\n    theme(panel.background = element_rect(fill = \"gray80\", color = \"gray80\", size =0.5, linetype = \"solid\"),\n       panel.grid.major = element_line(size =0.5, linetype = \"solid\", color = \"white\"), #major refers to grid line at values\n       panel.grid.minor = element_line(size =0.25, linetype = \"solid\", color = \"white\")) # minor refers line in between grid values\n\nggplotly(g2, tooltip = c(\"rowname\", \"Overall\"))\n\n\n\n{\"x\":{\"data\":[{\"orientation\":\"h\",\"width\":[0.9,0.9,0.9,0.9,0.9],\"base\":[0,0,0,0,0],\"x\":[24.9272016160619,25.258635091715,27.4749244977431,65.8105301166099,100],\"y\":[1,2,3,4,5],\"text\":[\"rowname: HEALTH_WORKER_FYes<br />Overall:  24.92720\",\"rowname: DOCREC1<br />Overall:  25.25864\",\"rowname: DOCREC2<br />Overall:  27.47492\",\"rowname: VACC_SEAS_FYes<br />Overall:  65.81053\",\"rowname: DOCREC4<br />Overall: 100.00000\"],\"type\":\"bar\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(173,216,230,1)\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(0,0,0,1)\"}},\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":45.4063926940639,\"r\":7.30593607305936,\"b\":41.8264840182648,\"l\":130.776255707763},\"plot_bgcolor\":\"rgba(204,204,204,1)\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187},\"title\":{\"text\":\"Variable Importance of Decision Tree Model\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":17.5342465753425},\"x\":0,\"xref\":\"paper\"},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[-5,105],\"tickmode\":\"array\",\"ticktext\":[\"0\",\"25\",\"50\",\"75\",\"100\"],\"tickvals\":[0,25,50,75,100],\"categoryorder\":\"array\",\"categoryarray\":[\"0\",\"25\",\"50\",\"75\",\"100\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(255,255,255,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"Overall\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[0.4,5.6],\"tickmode\":\"array\",\"ticktext\":[\"HEALTH_WORKER_FYes\",\"DOCREC1\",\"DOCREC2\",\"VACC_SEAS_FYes\",\"DOCREC4\"],\"tickvals\":[1,2,3,4,5],\"categoryorder\":\"array\",\"categoryarray\":[\"HEALTH_WORKER_FYes\",\"DOCREC1\",\"DOCREC2\",\"VACC_SEAS_FYes\",\"DOCREC4\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(255,255,255,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\"Variable\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":null,\"line\":{\"color\":null,\"width\":0,\"linetype\":[]},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false,\"legend\":{\"bgcolor\":null,\"bordercolor\":null,\"borderwidth\":0,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.689497716895}},\"hovermode\":\"closest\",\"barmode\":\"relative\"},\"config\":{\"doubleClick\":\"reset\",\"showSendToCloud\":false},\"source\":\"A\",\"attrs\":{\"1890767f7bc1\":{\"x\":{},\"y\":{},\"type\":\"bar\"}},\"cur_data\":\"1890767f7bc1\",\"visdat\":{\"1890767f7bc1\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\n\n\nVariable Importance of Neural Network\n\n\ng3 <- nnetImp$importance %>% \n  as.data.frame() %>%\n  rownames_to_column() %>%\n  arrange(Overall) %>%\n  mutate(rowname = forcats::fct_inorder(rowname )) %>%\n  top_n(No_Var,Overall) %>%  #top 5 Importance\n  ggplot(aes(x = rowname, y = Overall))+\n    geom_col(color=\"black\",fill = \"light blue\")+\n    coord_flip()+\n    xlab(\"Variable\")+\n    ggtitle(\"Variable Importance of Neural Network Model\") + \n    theme_minimal() +\n    theme(panel.background = element_rect(fill = \"gray80\", color = \"gray80\", size =0.5, linetype = \"solid\"),\n       panel.grid.major = element_line(size =0.5, linetype = \"solid\", color = \"white\"), #major refers to grid line at values\n       panel.grid.minor = element_line(size =0.25, linetype = \"solid\", color = \"white\")) # minor refers line in between grid values\n\nggplotly(g3, tooltip = c(\"rowname\", \"Overall\"))\n\n\n\n{\"x\":{\"data\":[{\"orientation\":\"h\",\"width\":[0.9,0.9,0.9,0.9,0.9],\"base\":[0,0,0,0,0],\"x\":[31.8277313713564,32.7172301979378,50.6010822123337,99.5454136385648,100],\"y\":[1,2,3,4,5],\"text\":[\"rowname: DOCREC4<br />Overall:  31.82773\",\"rowname: PATIENT_CONTACT_FYes<br />Overall:  32.71723\",\"rowname: DOCREC2<br />Overall:  50.60108\",\"rowname: VACC_SEAS_FYes<br />Overall:  99.54541\",\"rowname: DOCREC3<br />Overall: 100.00000\"],\"type\":\"bar\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(173,216,230,1)\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(0,0,0,1)\"}},\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":45.4063926940639,\"r\":7.30593607305936,\"b\":41.8264840182648,\"l\":142.465753424658},\"plot_bgcolor\":\"rgba(204,204,204,1)\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187},\"title\":{\"text\":\"Variable Importance of Neural Network Model\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":17.5342465753425},\"x\":0,\"xref\":\"paper\"},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[-5,105],\"tickmode\":\"array\",\"ticktext\":[\"0\",\"25\",\"50\",\"75\",\"100\"],\"tickvals\":[0,25,50,75,100],\"categoryorder\":\"array\",\"categoryarray\":[\"0\",\"25\",\"50\",\"75\",\"100\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(255,255,255,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"Overall\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[0.4,5.6],\"tickmode\":\"array\",\"ticktext\":[\"DOCREC4\",\"PATIENT_CONTACT_FYes\",\"DOCREC2\",\"VACC_SEAS_FYes\",\"DOCREC3\"],\"tickvals\":[1,2,3,4,5],\"categoryorder\":\"array\",\"categoryarray\":[\"DOCREC4\",\"PATIENT_CONTACT_FYes\",\"DOCREC2\",\"VACC_SEAS_FYes\",\"DOCREC3\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(255,255,255,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\"Variable\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":null,\"line\":{\"color\":null,\"width\":0,\"linetype\":[]},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false,\"legend\":{\"bgcolor\":null,\"bordercolor\":null,\"borderwidth\":0,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.689497716895}},\"hovermode\":\"closest\",\"barmode\":\"relative\"},\"config\":{\"doubleClick\":\"reset\",\"showSendToCloud\":false},\"source\":\"A\",\"attrs\":{\"18906fab19f4\":{\"x\":{},\"y\":{},\"type\":\"bar\"}},\"cur_data\":\"18906fab19f4\",\"visdat\":{\"18906fab19f4\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\n\n\n5. Model Comparision by ROC/AUC and Visualisations\nNote: Compare the model, note the predicted results.\nThe ROC (Receiver Operating Characteristic) curve is used to evaluate the strength of a classification model and also to compare between classification models.The ROC curve shows the trade-off between the true positive rate and the false positive rate. To compare between models, the AUC (area under the curve) is used. AUC provides an aggregate measure of performance of a model across the classification thresholds. It is a representation of the model’s capability to distinguish between the classes.\n5.1 Comparing ROC Packages\nThe following R packages ROCR, pROC and plotROC are used to plot the ROC curves of the predictive models. The packages are later compared on usability, comprehensiveness and visualization of ROC curves.\n5.1.1 Using ROCR Package\n\n\n#using ROCR package \n\n#ROC Curve for Random Forest\nrf_pred <- prediction(model_rf$pred$Yes,model_rf$pred$obs)\nrf_perf <- performance(rf_pred,\"tpr\",\"fpr\")\nplot(rf_perf, main = \"ROC Curves of Models\")\n\n\n#ROC Curve for Decision Tree\ndt_pred <-prediction(model_dt$pred$Yes,model_dt$pred$obs)\ndt_perf <- performance(dt_pred,\"tpr\",\"fpr\")\nplot(dt_perf, add = TRUE, col = \"blue\")\n\n#ROC Curve for KNN\nknn_pred <-prediction(model_knn$pred$Yes,model_knn$pred$obs)\nknn_perf <- performance(knn_pred,\"tpr\",\"fpr\")\nplot(knn_perf, add = TRUE, col = \"red\")\n\n#ROC Curve for Neural Network\nnnet_pred <-prediction(model_nnet$pred$Yes,model_nnet$pred$obs)\nnnet_perf <- performance(nnet_pred,\"tpr\",\"fpr\")\nplot(nnet_perf, add = TRUE, col = \"green\")\n\nlegend(\"right\", legend = c(\"Random Forest\",\"Decision Tree\",\"KNN\",\"Neural Network\"),bty= 'n',cex = 1, lty =1, \n       col= c(\"black\",\"blue\",\"red\",\"green\"))\n\n\n\n\n5.1.2 Using pROC Package\n\n\n#using pROC package\n\n#ROC Curve for Random Forest\nrf_pROC <- roc(model_rf$pred$obs,model_rf$pred$Yes )\nplot(rf_pROC, print.auc = TRUE, grid = TRUE, col = \"red\")\n\n#ROC Curve for Decision Tree\ndt_pROC <- roc(model_dt$pred$obs,model_dt$pred$Yes )\nplot(dt_pROC, print.auc = TRUE, col = \"blue\", add = TRUE, print.auc.y = .4)\n\n#ROC Curve for KNN\nknn_pROC <- roc(model_knn$pred$obs,model_knn$pred$Yes )\nplot(knn_pROC, print.auc = TRUE, col = \"green\", add = TRUE, print.auc.y = .3)\n\n#ROC Curve for Neural Network\nnnet_pROC <- roc(model_nnet$pred$obs,model_nnet$pred$Yes )\nplot(nnet_pROC, print.auc = TRUE, col = \"black\", add = TRUE, print.auc.y = .2)\n\n\n\n\n5.1.3 Using plotROC Package\n\n\n#USing plotROC package\n              ggplot() + \n              geom_roc(aes(d = obs, m = Yes, color=\"Random Forest\"), model_rf$pred,n.cuts = 0) + #ROC Curve for Random Forest\n              geom_roc(aes(d = obs, m = Yes, color=\"Decision Tree\"), model_dt$pred,n.cuts = 0) + #ROC Curve for Decision Tree\n              geom_roc(aes(d = obs, m = Yes, color=\"KNN\"), model_knn$pred,n.cuts = 0) + #ROC Curve for KNN \n              geom_roc(aes(d = obs, m = Yes, color=\"Neural Network\"), model_nnet$pred,n.cuts = 0) +  #ROC Curve for Neural Network\n              scale_color_manual(values=c(\"Random Forest\"=\"red\", \"Decision Tree\"=\"blue\",\"KNN\"=\"green\",\"Neural Network\"=\"black\"), \n              name=\"Models\", guide=\"legend\") + \n              coord_equal()+\n              style_roc(theme = theme_grey,xlab = \"1-Specificity\", ylab =\"Sensitivity\")+\n              theme(legend.position = \"bottom\")+\n              labs(title=\"ROC Plots Comparison\")\n\n\n\n\n5.1.4 ROC Package Comparison\nBased on report (Robin et al., 2011, p. 12), the pROC is a report dedicated to ROC analysis compared to ROCR. Both pROC and ROCR use simple commands to for plotting the ROC curve. ROCR requiring only 3 commands and pROC* requiring 2 commands for a basic plot. One key difference between the plotROC package and the other two, plotROC allows the use of ggplot’s geoms to plot the ROC curve, enabling usage of the extensive ggplot package. where the other two packages use the base plot function in R.\nThus, for the purpose of a ROC visualisation for shiny,plotROC is deemed to be the more appropriate package for it’s usability for plotting via ggplot.\n5.2 Obtaining the AUC Table\n\n\nCombineAUC <- calc_auc(ggplot() + \n              geom_roc(aes(d = obs, m = Yes,), model_rf$pred))\n\nAUCdt <- calc_auc(ggplot() + \n              geom_roc(aes(d = obs, m = Yes), model_dt$pred)) \n\nAUCknn <- calc_auc(ggplot() + \n              geom_roc(aes(d = obs, m = Yes), model_knn$pred)) \n\nAUCnnet <- calc_auc(ggplot() + \n              geom_roc(aes(d = obs, m = Yes), model_nnet$pred)) \n           \n\nCombineAUC <- bind_rows(CombineAUC,AUCdt,AUCknn,AUCnnet) #Combining AUC values of each model into one dataframe\n\nModel <-c(\"Random Forest\", \"Decision Tree\",\"kNN\",\"Neural Network\")\nAUC <- CombineAUC$AUC\nFinalAUC <- data.frame(Model,AUC)\n\nggplot(FinalAUC, aes( x=Model, y= AUC))+\n                  geom_bar(stat = \"Identity\", fill= \"#E7B800\", color =\"black\")+\n                  geom_text(aes(y=AUC, ymax= AUC, label = round(AUC, 3)))+\n                  coord_flip()+\n                  geom_hline(yintercept = AUC[AUC == max(AUC)],color = \"red\",linetype =2)+\n                  theme_grey()\n\n\n\n\nAs seen from both the AUC table and the ROC curve, it is shown the Random Forest model has performed the best with the highest AUC at 0.837 and highest ROC curve.\n5.3 Comparing Model Performance via Resampling\nThe caret’s resamples() function assist to resampling performance on the final model produced during the model training.It creates summary statistics (mean, min, max, etc.) for each performance metric for the list of models.\n\n\nrvalues <-resamples(list('Random Forest'=model_rf,'Decision Tree'=model_dt,kNN=model_knn, 'Neural Network'=model_nnet))\nsummary(rvalues)\n\n\n\nCall:\nsummary.resamples(object = rvalues)\n\nModels: Random Forest, Decision Tree, kNN, Neural Network \nNumber of resamples: 5 \n\nROC \n                    Min.   1st Qu.    Median      Mean   3rd Qu.\nRandom Forest  0.8325592 0.8366193 0.8424705 0.8417187 0.8480867\nDecision Tree  0.7774597 0.7819551 0.7825665 0.7841742 0.7869916\nkNN            0.7918626 0.7983920 0.8044332 0.8048322 0.8136617\nNeural Network 0.6875573 0.7225108 0.7347946 0.7411793 0.7355749\n                    Max. NA's\nRandom Forest  0.8488579    0\nDecision Tree  0.7918983    0\nkNN            0.8158115    0\nNeural Network 0.8254590    0\n\nSens \n                    Min.   1st Qu.    Median      Mean   3rd Qu.\nRandom Forest  0.9515301 0.9533785 0.9548255 0.9558860 0.9574861\nDecision Tree  0.9439310 0.9463956 0.9486548 0.9484104 0.9492813\nkNN            0.9474225 0.9480386 0.9498870 0.9500945 0.9501027\nNeural Network 0.8264531 0.8540041 0.9385911 0.9238097 1.0000000\n                    Max. NA's\nRandom Forest  0.9622099    0\nDecision Tree  0.9537893    0\nkNN            0.9550216    0\nNeural Network 1.0000000    0\n\nSpec \n                    Min.   1st Qu.    Median      Mean   3rd Qu.\nRandom Forest  0.3719008 0.3739669 0.3760331 0.3809917 0.3856749\nDecision Tree  0.4001377 0.4008264 0.4166667 0.4137741 0.4228650\nkNN            0.3312672 0.3326446 0.3615702 0.3513774 0.3629477\nNeural Network 0.0000000 0.0000000 0.4366391 0.3256198 0.5488981\n                    Max. NA's\nRandom Forest  0.3973829    0\nDecision Tree  0.4283747    0\nkNN            0.3684573    0\nNeural Network 0.6425620    0\n\nA box-whiskers plot is used to visualized the re-sampling distributions of the models.The best performing model on resamples based on mean ROC score was Random Forest model.Neural network model has the highest sensitivity.\n\n\ntrellis.par.set()\nbwplot(rvalues,layout= c(3,1))\n\n\n\n\n6. Proposed Visualisation from Shiny Module\n\n7. Conclusion/Reflections\nThe purpose of this post was to review the packages available for predictive modeling, how to compare the results of those modes and how to incorporate into a Shiny App. As highlighted in section 3, the caret package was found to be a “wholesome” package when it comes to model building, providing most of the functions required to predictive modeling.\nUser of the shiny app would be able to tune and explore the four different models made available. Various visualizations to assess the models were provided for users to assess the parameters and models used.\nReferences\nProbst, P., Wright, M., & Boulesteix, A.-L. (2019). Hyperparameters and Tuning Strategies for Random Forest. https://arxiv.org/pdf/1804.03515.pdf\nBand, A. (2020b, May 23). How to find the optimal value of K in KNN? - Towards Data Science. Medium. https://towardsdatascience.com/how-to-find-the-optimal-value-of-k-in-knn-35d936e554eb#:%7E:text=The%20optimal%20K%20value%20usually,be%20aware%20of%20the%20outliers.\nRobin, X., Turck, N., Hainard, A., Tiberti, N., Lisacek, F., Sanchez, J. C., & Müller, M. (2011). pROC: an open-source package for R and S+ to analyze and compare ROC curves. BMC Bioinformatics, 12(1), 12. https://doi.org/10.1186/1471-2105-12-77\nPanchal, F. S., & Panchal, M. (2014). Review on Methods of Selecting Number of Hidden Nodes in Artificial Neural Network. International Journal of Computer Science and Mobile Computing, 3(11), 455–464. https://www.ijcsmc.com/docs/papers/November2014/V3I11201499a19.pdf\nFridkin, V. (n.d.). Shrooming - Interactive mushroom edibility predictions with XGBoost. Https://Shiny.Rstudio.Com/. https://vfridkin.shinyapps.io/mushroom_app/\nMerlino, A. (2018). Machine Learning for Insurance Claims. Https://Www.Tychobra.Com/Posts/Claims-Ml/. https://tychobra.shinyapps.io/wc-pm-dashboard/\n\n\n\n",
    "preview": "posts/2021-03-23-decision-tree/decision-tree_files/figure-html5/unnamed-chunk-13-1.png",
    "last_modified": "2021-04-11T21:48:11+08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-03-23-eda/",
    "title": "Exploratory Data Analysis",
    "description": "Exploratory data analysis forms the first component of the Shiny application on the prediction of whether an indiviudal would take the H1N1 vaccine. Its role is to give users of the application introductory insights into the relationship between input variables and the target variable, before the user proceeds to the other components of the Shiny application on explanatory and predictive models.",
    "author": [
      {
        "name": "TAY Kai lin",
        "url": "https://www.linkedin.com/in/kai-lin-tay/"
      }
    ],
    "date": "2021-03-23",
    "categories": [],
    "contents": "\n1 Literature Review\n1.1 Approach to Literature Review\nLiterature review was conducted to analyze how Exploratory Data Analysis (EDA) has been performed before, and whether those techniques are applicable to the project on the explanatory and predictive modeling of whether an individual is likely to undergo H1N1 vaccination. In view of the scope of the project that covers explanatory and predictive modeling, the objective of the EDA is to visualize the relationships between input variables and the target variable so as to identify any trends which may suggest the usefulness of an input variable in predicting the target variable.\nA key consideration in deciding the type of visualization is the data type of the input variables. For this dataset, most of the input variables are categorical. Therefore, visualizations that are suitable for categorical variables will be explored, as opposed to visualization that are suitable for continuous variables such as correlation plots and histograms.\n1.2 Reviewing Past Visualizations on H1N1 vaccination or related topics\nMany descriptive visualizations have been made to visualize survey responses on attitudes towards H1N1 vaccination before, or related public health topics on other pandemics. Some examples have been highlighted below:\nDistribution of survey responses\nAn example of a visualization is responses of survey respondents on a scale of Strongly Disagree to Strongly Agree with respect to various statements, and how these proportions have changed over time. The visualization is available at this link and a screenshot is provided below:\n\nFigure 1: Visualization of how the distribution of survey responses to several statements related to Covid-19 and/or the vaccine have changed over time\nGeospatial distribution of Survey Responses\nAnother example of a visualization is a global map visualizing how the proportions of survey respondents who Strongly Agree or Agree with the statement that ‘Vaccines are imporant for children to have’. The visualization is available at this link and a screenshot is provided below:\n\nFigure 2: Geospatial visualization on survey responses of the percentage that ‘Agree’ and ‘Strongly Agree’ that vaccines are important for children\nHowever, these visualizations are not the most relevant for this project. While this dataset also involves survey responses, the objective of the visualization is not to gain insights on the survey responses alone but to gain insights on how the survey responses influence whether an individual takes the H1N1 vaccination. Therefore, I will not be following what these visualization have done, but look at other methods that can be used to explore the relationship between an input and target variable.\n1.3 Mosaic Plot\nThe mosaic plot data visualization technique is suitable for visualizing multivariate categorical data. A mosaic plot is a graphical display of cell frequencies in a contingency table, which is useful in this project where we are looking at how each input variable affects the target variable.\nWhile there are many packages that can be used for mosaic plots including ggmosaic and dlookr which contains plot.relate(), I will be using the vcd package. vcd stands for visualizing categorical data. ggmosaic, dlookr and vcd are all able to plot the basic requirements of a mosaic chart - which is to plot 2 categorical variables against each other and modify the aesthetics of the graph (e.g. color scheme) as required. However, the vcd package stands out for its shade function, where it is able to shade the mosaic plot based on chi-square test results. This color scale would be a useful indicator for this project in helping the user observe which input variables have a relationship with the target variable, and provides early insights into which input variables might be included or excluded in the explanatory and predictive models.\nHowever, a disadvantage of the mosaic plot is that rectangles can vary considerably in aspect ratio. As it is difficult to compare rectangles of different length and width, a user may not be able to compare the frequencies of the rectangles. To overcome this difficulty, a bar plot can be used in conjunction with the mosaic plot.\n1.4 Stacked Bar Chart\nBar plots are also a suitable data visualization technique for visualizing multivariate categorical data by helping us to identify the relationship between the input and target variables. For this project, we will be using a stacked bar chart which will clearly illustrate the different bars for those who have taken the vaccine and those who have not. With the bar charts, labels will be added to show the count and proportions of those who have and have not taken vaccine within each group (see below for more details). In addition, it can also help us to observe the distribution of the input variables with respect to the target variable, and whether there are any plots with complete or quasi-complete separation. Variables with complete or quasi-complete separation need to be removed from the logistic regression.\nWhile there are also many packages that can be used for bar charts, the package that I will be using is ggplot. The ggplot package is easy to manipulate and there are many different elements that we can add to the graph according to what is required. Aside from ggplot, other ways to plot barplots in R include R’s barplot() and barplot3d package. Barplot3d package is intended for 3d barplot, which I would not be exploring in this visualization. R’s barplot() offers similar functions to ggplot and can be used to do up simple barplots, but as a whole ggplot is a package with many more functions. Thus, ggplot is chosen.\n1.5 Other techniques for multivariate categorical data\nThere are other exploratory visualizations that we can explore for multivariate categorical data namely balloon plots, which can be plotted using ‘ggballoonplot()’ under ggpubr and correspondance analysis, which can be plotted using ’ca()’under the package FactoMineR. However, both of these plots will not be explored in this visualization. Most of the categorical variables in this visualization are binary and do not require balloon plots nor correspondance analysis which may be more suitable for categorical variables that have many categories.\nApart from visualizations, the contingency table is another commonly used technique for multivariate categorical data. There are many packages that are available for displaying tables including KableExtra, flextable, huxtable and reactable among many others. However, I will not need a contingency table as I will be including information on count in the bar chart.\n2 Storyboard\nCombining both elements of a mosaic plot and bar chart together, a storyboard has been sketched out as follows:\n\nFigure 3: Sketch of storyboard\nAs the objective of this visualization is to visualize the relationship between input variables and the target variable, the top section of the storyboard aims to achieve this objective through the mosaic plot and bar chart. By selecting a variable in the left panel, the variable will be plotted against the target variable in the main panel. In addition, it may be interested to investigate if there are relationships between input variables, which the bottom section aims to achieve. Upon selecting both variables in the left panel, both variables would appear in the main panel.\n3 Data Extraction and Preparation\n3.1 Installing packages\nThe first step would be to install the required packages. The packages that I will be using are as follows:\nPackage\nPurpose\ntidyverse\nData manipulation and plotting bar chart\nvcd and vcdExtra\nPlotting mosaic plot\nscales\nDisplaying the proportions in the bar chart\nstringr\nRecoding the values in the column ‘State’ into letters where the first letter is capitalized\nThe code for installing the packages is as follows:\n\n\npackages = c('tidyverse', 'vcd', 'vcdExtra', 'scales', 'stringr')\nfor (p in packages){\n  if(!require(p, character.only = T)){\n    install.packages(p)\n  }\n  library(p, character.only = T)\n}\n\n\n\n3.2 Importing dataset\nThe following line of code can be used to import the dataset.\n\n\nH1N1 <- read_csv(\"data/H1N1_Final_dan_edit.csv\")\n\n\n\n3.3 Data preparation\nThere are a few steps that we can take to prepare the data.\nThe first step is to rename the column for ‘Concern Level’. This is a problem that is specific to our dataset. As Concern Level has a whitespace character, there may be difficulties in calling this variable in subsequent codes. Thus, we rename it as ‘Concern_Level’.\n\n\nnames(H1N1)[names(H1N1) == 'CONCERN LEVEL'] <- \"CONCERN_LEVEL\"\n\n\n\nThe second step is to handle NA values. We handle NA values differently for the target variable and input variables. For the target variable, we would remove NA values as these rows are not useful to our analysis. The code is as follows:\n\n\n#exclude the NA column in the target variable\nH1N1 <- H1N1 %>%\n  filter(!is.na(VACC_H1N1_F))\n\n\n\nHowever, for input variables, it is acceptable to have NA values as long as these values are not above a certain threshold, which we have set as 50%. To select the input variables that have less than 50% of NA values, there are a few steps involved. The first step is to recode the NA values into NA as recognized by R. This is because the NA values in the dataset are coded as #N/A which is not recognized as an NA value to R. The following code can be run for this recoding process:\n\n\nH1N1[H1N1 == '#N/A'] <- NA\n\n\n\nNext, we can view a summary of the proportion of NA values in every column, the following code can be run:\n\n\ncolMeans(is.na(H1N1))\n\n\n\nFinally, we can select out the variables that have a missing value threshold of less than 50%. The following code can be run:\n\n\nh1n1data <-H1N1 %>%\n  select(VACC_H1N1_F, VACC_SEAS_F, B_H1N1_ANTIV, B_H1N1_AVOID, B_H1N1_FMASK,\n         B_H1N1_HANDS, B_H1N1_LARGE, B_H1N1_RCONT, B_H1N1_TOUCH, CONCERN_LEVEL,\n         INT_H1N1, KNOW_H1N1, INT_SEAS, DOCREC, CHRONIC_MED_F, CLOSE_UNDER6MO_F,\n         HEALTH_WORKER_F, PATIENT_CONTACT_F, AGEGRP, EDUCATION_COMP, HH_CHILD_R,\n         INC_CAT1, MARITAL, RACEETH4_I, N_ADULT_R, SEX_I, STATE)\n\n\n\nThe third step is to code the variables as categorical.\n\n\nh1n1data <- transform(h1n1data,\n                      VACC_H1N1_F= as.factor(VACC_H1N1_F),\n                      VACC_SEAS_F= as.factor(VACC_SEAS_F),\n                      B_H1N1_ANTIV= as.factor(B_H1N1_ANTIV),\n                      B_H1N1_AVOID= as.factor(B_H1N1_AVOID),\n                      B_H1N1_FMASK= as.factor(B_H1N1_FMASK),\n                      B_H1N1_HANDS= as.factor(B_H1N1_HANDS),\n                      B_H1N1_LARGE= as.factor(B_H1N1_LARGE),\n                      B_H1N1_RCONT= as.factor(B_H1N1_RCONT),\n                      B_H1N1_TOUCH= as.factor(B_H1N1_TOUCH),\n                      CONCERN_LEVEL= as.factor(CONCERN_LEVEL),\n                      INT_H1N1= as.factor(INT_H1N1),\n                      KNOW_H1N1= as.factor(KNOW_H1N1),\n                      DOCREC= as.factor(DOCREC),\n                      CHRONIC_MED_F= as.factor(CHRONIC_MED_F),\n                      CLOSE_UNDER6MO_F= as.factor(CLOSE_UNDER6MO_F),\n                      HEALTH_WORKER_F= as.factor(HEALTH_WORKER_F),\n                      AGEGRP= as.factor(AGEGRP),\n                      EDUCATION_COMP= as.factor(EDUCATION_COMP),\n                      HH_CHILD_R= as.factor(HH_CHILD_R),\n                      INC_CAT1= as.factor(INC_CAT1),\n                      MARITAL= as.factor(MARITAL),\n                      RACEETH4_I= as.factor(RACEETH4_I),\n                      N_ADULT_R= as.factor(N_ADULT_R),\n                      SEX_I= as.factor(SEX_I),\n                      STATE= as.factor(STATE),\n                      PATIENT_CONTACT_F = as.factor(PATIENT_CONTACT_F),\n                      INT_SEAS = as.factor(INT_SEAS)\n                   )\n\n\n\nThe fourth step is to create a new column for region based on the column in the dataset for state. To do so, we have another dataset that has columns for both region and state. We will start by importing this dataset with the following code:\n\n\nregion <- read_csv(\"data/state_region.csv\")\n\n\n\nThen, we will have to recode the values in the state column. This is because the values are currently all in uppercase letters. We will have to recode the letters into lowercase letters apart from the first letter. Finally, we can merge both tables using a left join.\n\n\nh1n1data$state_recoded <- str_to_title(h1n1data$STATE)\nh1n1data <- left_join(h1n1data, region,\n                      by=c(\"state_recoded\" = \"State\"))\n\n\n\n3.4 Overview of Variables\nAfter data preparation, the variables that I will be using are as follows:\nCategory\nVariable Name\nAllowable Values\nTarget Variable\nTaken H1N1 flu vaccine\nYes, No\nDemographic\nGender\nMale, Female\nDemographic\nAge Group\n6 months-9 years, 10-17 years, 18-34 years, 35-44 years, 45-54 years, 55-64 years, 65+ years\nDemographic\nEducation Level\n<12 years, 12 years, some college, college graduate\nDemographic\nIncome Level\n<=$10000, $10001-$15000, $15001-$25000, $25001-$35000, $35001-$50000, $50001-$75000, $75001-$100000\nDemographic\nMarital Status\nMarried, Not Married\nDemographic\nRace\nHispanic, Non-Hispanic Black Only, Non-Hispanic White Only, Non-Hispanic Other or Multiple Races\nDemographic\nNumber of children in household\n0, 1, 2, 3\nDemographic\nNumber of adults in household\n1, 2, 3, 4\nDemographic\nRegion\nNortheast Region, Midwest Region, South Region, West Region\nBehavioural\nTaken seasonal flu vaccine\nYes, No\nBehavioural\nTaken antiviral medications\nYes, No\nBehavioural\nAvoid close contact with others with flu-like symptoms\nYes, No\nBehavioural\nBought a face mask\nYes, No\nBehavioural\nWashing hands\nYes, No\nBehavioural\nReduced time at large gatherings\nYes, No\nBehavioural\nReduced contact outside home\nYes, No\nBehavioural\nAvoid touching eyes, nose or mouth\nYes, No\nAttitude\nConcern level about H1N1 flu\nNot at all concerned, not very concerned, somewhat concerned, very concerned\nAttitude\nIntent to get H1N1 flu vaccine\nDefinitely no intent, improbably intent, probable intent, definite intent\nAttitude\nKnowledge about H1N1 flu\nNo knowledge, a little knowledge, a lot of knowledge\nAttitude\nIntent to get seasonal flue vaccine\nDefinitely no intent, improbably intent, probable intent, definite intent\nAttitude\nDoctor recommendation on vaccines\nNever recommend vaccines, recommend seasonal flu vaccine only, recommend H1N1 vaccine only, recommend both seasonal flu and H1N1 flu vaccines\nRisk Factor\nChronic medical condition flag\nYes, No\nRisk Factor\nClose contact with child under 6 months flag\nYes, No\nRisk Factor\nWorks in healthcare field flag\nYes, No\nRisk Factor\nDirect patient contact flag\nYes, No\n4 Testing and Prototyping\nAs the storyboard contains mosaic plots and bar charts, this section will to test the codes for the plots and which kind of plots would work better for this project. While there are two sections in the storyboard, this prototype will focus on plotting a randomly chosen input variable against the target variable. The randomly chosen input variable is behavioural variable of whether the individual has bought a face mask. These codes can easily be replicated for other variables, and for the other section in the final Shiny application.\n4.1 Mosaic Plot\n4.1.1 Using Chi-Square Test for Shading\nStarting off on the mosaic plot, the first option is to use shading for the chi-square test plot. The color legend indicates which cells contribute to the significance of the chi-squared test results, and means the following:\nColor\nStatistical Significance\nRed\nThere are fewer observations than would have been expected under the null model\nBlue\nThere are more observations that would have been expected under the null mode\nThe colors imply that there is a relationship between the input variable and target variable. In this case, survey respondents who bought a face mask are more likely to have taken the H1N1 vaccine. The code and resultant plot are as follows:\n\n\nmosaic(~VACC_H1N1_F + B_H1N1_FMASK, data = h1n1data, shade = TRUE,\n       labeling_args = list(set_varnames = \n                              c(B_H1N1_ANTIV = \"Bought a Face Mask\", \n                                VACC_H1N1_F = \"Taken H1N1 vaccine\")))\n\n\n\n\nAs a contrast, the plot for gender is below, and is greyscale. This implies that gender is not a significant indicator of whether an individual takes the vaccine.\n\n\n\n4.1.2 Drawing attention to the desired outcome\nThe alternative option for shading is to draw attention to the desired outcome. However, in comparison with the mosaic plot in 4.1.1, this mosaic plot provides less useful information to the user as it does not display the chi-square test results. Therefore, we have decided to opt for the first mosaic plot. Nonetheless, the code and the resultant plot are as follows:\n\n\nmosaic(~VACC_H1N1_F + B_H1N1_FMASK, data = h1n1data, \n       labeling_args = list(set_varnames = \n                              c(VACC_H1N1_F = \"Taken H1N1 vaccine\", \n                                B_H1N1_FMASK = \"Bought a face mask\")),\n       shade = TRUE,\n       gp = gpar(fill=c('light grey', 'pink')))\n\n\n\n\n4.2 Bar Chart\nThe next plot that I will require is a stacked bar chart, which would require the code geom_bar() from the package ggplot2. There are several steps that we ned to take to produce the graph.\n4.2.1 Data Preparation\nThe first step is to drop the NA values in the columns using drop_NA(). Without dropping the NA values, these values would show up in the bar chart but do not offer much meaningful information to the user. Thus, I have decided to remove the NA values.\n4.2.2 Plotting the Graph\nThe basic function ggplot and geom_bar() can be used to plot the bar chart. As I am looking at creating a stacked bar chart for respondents who have taken the vaccine vs those who have not, the target variable can be used as the ‘fill’. While there are many themes that can be used, I have chosen to use the theme theme_classic().\n4.2.2.1 Plotting Data Labels of Frequency and Proportion\nTo provide comprehensive information to the user, I have decided to provide labels for both frequency and proportion.\nFor effective comparison on how the input variable affects the target variable, the proportion needs to be the count out of the sub-category within the target variable. To illustrate with the example of the input variable ‘Bought a Face Mask’, it will be more effective for users to compare that 32% of those who bought a face mask took the H1N1 vaccine vs a lower proportion of 21% of those who did not buy a face mask took the vaccine. This would highlight that there is a difference in proportion. Comparatively, it would be less insightful if the labels were a proportion of the total population i.e. 19% of the population were those who did not buy a face mask and took the vaccine vs 2% of the population were those who bought a face mask and took the vaccine. As differences in the proportions of the height of the stacked bar chart may not be obvious to the eye, the user would not be able to tell without further computations whether buying a face mask had an impact on whether an individual takes the vaccine.\nThe R code for the latter is much simpler and requires applying the geom_text() function to ..count.. / sum(..count..). However, the former requires a more complex formula to first compute the percentages using the package scales, and then plotting these values into geom_text(). Frequency and count were called in separate geom_text() functions.\n4.2.2.2 Colors\nTo draw attention to the respondents who have taken the vaccine as this is the desired outcome, I have colored those who have taken the vaccine in bright blue vs those who have not taken the vaccine which is in gray. To draw further attention to the desired outcome, I have included a black border.\nAs the values in the column for whether an individual took the H1N1 vaccine are coded as ‘Yes’ and ‘No’, I have also re-labelled the legened as ‘Took H1N1 vaccine’ and ‘Did not take H1N1 vaccine’ respectively. I have further titled the legend as ‘H1N1 vaccination’.\n4.2.2.3 Axis labels\nI have labelled the axes accordingly using xlab() and ylab(). To prevent the x-axis labels from overlapping each other when there are several categories in a variable, I have placed the labels diagonally as opposed to horizontally.\n4.2.3 Code and Final Plot\nThe resultant code and plot are as follows:\n\n\nVACC_H1N1_F.labs <- c(\"Did not take H1N1 vaccine\", \"Took H1N1 vaccine\")\nnames(VACC_H1N1_F.labs) <- c(\"No\", \"Yes\")\n\npercentData <- h1n1data %>% \n  drop_na(B_H1N1_FMASK) %>%\n  group_by(B_H1N1_FMASK) %>% \n  count(VACC_H1N1_F) %>%\n  mutate(ratio=scales::percent(n/sum(n)))\n\nh1n1data %>%\n  drop_na(B_H1N1_FMASK) %>%\n  ggplot(aes(x = B_H1N1_FMASK, fill = VACC_H1N1_F)) +\n  geom_bar(aes(color = VACC_H1N1_F == \"Yes\")) + \n  geom_text(data = percentData,\n            aes(y=n, label=paste(\"(\",ratio,\")\")),\n            size = 3,\n            position = position_stack(vjust = 0.5), hjust=-0.1) +\n  geom_text(stat = \"count\",\n            aes(label = ..count..),\n            size = 3,\n            position = position_stack(vjust = 0.5), hjust = 0.95) +\n  scale_fill_manual(values = c(\"#ECECEC\", \"#2a9df4\"),\n                    breaks = c(\"No\", \"Yes\"),\n                    labels = VACC_H1N1_F.labs,\n                    name = \"H1N1 Vaccination\",) + \n  scale_x_discrete(guide = guide_axis(angle = 45)) + \n  scale_color_manual(values = c(NA, 'black'), guide=F) +\n  xlab(\"Bought a face mask\") + \n  ylab(\"Frequency\") +\n  theme_classic()\n\n\n\n\n\n\n\n",
    "preview": "posts/2021-03-23-eda/eda_files/figure-html5/unnamed-chunk-10-1.png",
    "last_modified": "2021-04-11T16:11:13+08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-03-23-logistic-regression/",
    "title": "Logistic Regression",
    "description": "Blow blog is my individual assignment and I am plan to build the explanatory model.",
    "author": [
      {
        "name": "HAI Dan",
        "url": {}
      }
    ],
    "date": "2021-03-23",
    "categories": [],
    "contents": "\n\nContents\n1. Overview1.1 Core Purpose of Dataviz Exercise\n1.2 Literature review\n\n2.0 Interactivity\n3.0 Step-by-step Data Visualisation Preparation3.1 Installing and launching R packages\n3.2 Data Preparation3.2.1 Share Code in the group project\n3.2.2 Building Explainatory Model\n\n3.3 Model Selection3.3.1 Add three transfrom variables\n3.3.2 Select Behavior Variable to Continue Build Explanatory Model\n\n3.4 ‘blorr’ and ‘sjPlot’ Package Exploration\n\n4 Sketch of proposed visualisation\n5.References\n\n1. Overview\n1.1 Core Purpose of Dataviz Exercise\nThis makeover aims to visualise the insight of National 2009 H1N1 Flu Survey (NHFS) after the analysis with the explanatory model method. This extensive dataset would not just allow us to perform descriptive analytics on how H1N1 vaccination rates vary in USA, but also allows me to derive medical insights about how a person’s individual attributes relate to the willingness of taken H1N1 vaccination. I try to explain this insight by using predictor variables, which are directly or indirectly related to the effect of US citizen taken vaccine. More importantly, I want to visualize the results by using the knowledge obtained from Visual Analytics and Application class.\nAnd at the same time, increasing the interaction with users through shiny applications. With the help of posters and shiny applications, I want to let users know the insight contain and hide in NHFS dataset.The purpose of an explanatory model is to explain rather than predict the outcome of taken vaccination, where the objective of explanation is the application of statistical inference in order to:\nidentify predictor variables with statistically significant impact to the decision of taking H1N1 Flu Vaccination\nestimate the magnitude of impact of the significant predictors toward the vanccine decision\nvisualize the insight by using shinny application\n\n1.2 Literature review\nBefore doing this project, Prof. Kam recommended many very useful packages, so I will use a large number of blorr packages in the following paragraphs.Blorr Tools designed to make it easier for users, particularly beginner/intermediate R users to build logistic regression models. At the same time, I find the package ‘jtools’ and ‘huxtable’ by using the function ‘summs’, which have the similar function with blorr’s ‘blr_regress’, but after the comparison, I decide to focus on using blorr. And in the end, I using the ‘sjPlot’ package to plot the insight graph on model’s odd ratio. ‘sjPlot’ is the collection of plotting and table output functions for data visualization\nAt the same time, a key consideration in the literature review is how to perform a good explanatory model. I review several article about building the explanatory model. Among those, I review a lot from the Dimitrios Tziotis article. I also read many other articles and after the second consultation with Prof Kam, and I finally decided to interpret the result with the explanatory model and my teammate will building the predictive model.\n2.0 Interactivity\nAs for the interactivity of explaining model, I want to enable users to directly browse all statistics insight and odd ratio insight through shiny application. Interaction can be created by allowing the user to select the information they want in shiny app to click in the slider bar, such as the model’s odd ratio, which will appear on the right side of the diagram and text explanation, that is, all the functions in the ‘blorr’ package, I can reach the maximum interactivity through shiny applications with synchronized plot and sidebar selection to users.\n3.0 Step-by-step Data Visualisation Preparation\n3.1 Installing and launching R packages\nA list of packages are required for this makeover exercise. This code chunk installs the required packages and loads them onto RStudio environment.\n\n\npackages = c('tidyverse','readr','ISLR','VIM', 'gridExtra','blorr','jtools','huxtable','boot','sjPlot')\nfor (p in packages){\n  if(!require(p, character.only = T)){\n  install.packages(p)\n  }\n  library(p,character.only= T ) \n} \n\n\n\n3.2 Data Preparation\n3.2.1 Share Code in the group project\nwe share the same basic modification code to raw data with our teammate to make sure the consistent on each of our own.\n\n\nH1N1 <- read_csv('data/H1N1_Final_dan_edit.csv')\n\n\n\n\n\n#exclude the NA column in the target variable\nH1N1 <- H1N1 %>%\n  filter(!is.na(VACC_H1N1_F))\n\n\n\n\n\nnames(H1N1)[names(H1N1) == 'CONCERN LEVEL'] <- \"CONCERN_LEVEL\"\n\n\n\n\n\nH1N1[H1N1 == '#N/A'] <- NA\n\n\n\n\n\ncolMeans(is.na(H1N1))\n\n\n       VACC_H1N1_F        VACC_SEAS_F       B_H1N1_ANTIV \n       0.000000000        0.003997732        0.203132974 \n      B_H1N1_AVOID       B_H1N1_FMASK       B_H1N1_HANDS \n       0.207201588        0.201360930        0.202098100 \n      B_H1N1_LARGE       B_H1N1_RCONT       B_H1N1_TOUCH \n       0.203189680        0.203274738        0.204678197 \n     CONCERN_LEVEL               HQ23               HQ24 \n       0.203473207        0.854834137        0.963198185 \n            HQ24_B           INT_H1N1           INT_NEXT \n       0.994740573        0.255146016        0.692755883 \n          INT_SEAS          KNOW_H1N1                Q23 \n       0.459625744        0.204479728        0.960518855 \n               Q24              Q24_B             DOCREC \n       0.977417068        0.996597675        0.044031755 \n   ILI_DIAG_H1N1_F    ILI_DIAG_SEAS_F              ILI_F \n       0.961993195        0.961993195        0.020484831 \n       ILI_OTHER_F        ILI_TREAT_F              PSL_1 \n       0.016869861        0.922497874        1.000000000 \n             PSL_2                 Q9             Q9_NUM \n       1.000000000        1.000000000        1.000000000 \n     CHRONIC_MED_F   CLOSE_UNDER6MO_F    HEALTH_WORKER_F \n       0.031216331        0.225333144        0.224766090 \n PATIENT_CONTACT_F             AGEGRP     EDUCATION_COMP \n       0.264346470        0.000000000        0.242968528 \n        HH_CHILD_R             HISP_I           INC_CAT1 \n       0.007074001        0.000000000        0.213198185 \n            INSURE            MARITAL          N_ADULT_R \n       1.000000000        0.243592288        0.007074001 \n        N_PEOPLE_R                Q95         Q95_INDSTR \n       0.003118798        0.994527927        0.594074284 \n         Q95_OCCPN         RACEETH4_I         RENT_OWN_R \n       0.594074284        0.000000000        0.983612135 \n             SEX_I              STATE REAS_NOH1N1_AHAD_F \n       0.000000000        0.000000000        0.401020697 \nREAS_NOH1N1_ALLG_F REAS_NOH1N1_CANT_F REAS_NOH1N1_COST_F \n       0.401020697        0.401020697        0.401020697 \nREAS_NOH1N1_DKNW_F REAS_NOH1N1_DWRK_F REAS_NOH1N1_GOTO_F \n       0.401020697        0.401020697        0.401020697 \nREAS_NOH1N1_NDOC_F REAS_NOH1N1_NEVR_F REAS_NOH1N1_NNDD_F \n       0.401020697        0.401020697        0.401020697 \nREAS_NOH1N1_NOTA_F REAS_NOH1N1_OTHR_F REAS_NOH1N1_REFD_F \n       0.401020697        0.401020697        0.401020697 \nREAS_NOH1N1_SAVE_F REAS_NOH1N1_SEFF_F REAS_NOH1N1_TIME_F \n       0.401020697        0.401020697        0.401020697 \n\n\n\nh1n1data <-H1N1 %>%\n  select(VACC_H1N1_F,\n                   VACC_SEAS_F,\n                   B_H1N1_ANTIV,\n                   B_H1N1_AVOID,\n                   B_H1N1_FMASK,\n                   B_H1N1_HANDS,\n                   B_H1N1_LARGE,\n                   B_H1N1_RCONT,\n                   B_H1N1_TOUCH,\n                   CONCERN_LEVEL,\n                   INT_H1N1,\n                   KNOW_H1N1,\n                   INT_SEAS,  \n                   DOCREC,\n                   CHRONIC_MED_F,\n                   CLOSE_UNDER6MO_F,         \n                   HEALTH_WORKER_F,\n                   PATIENT_CONTACT_F,\n                   AGEGRP,\n                   EDUCATION_COMP,\n                   HH_CHILD_R,\n                   INC_CAT1,\n                   MARITAL,\n                   RACEETH4_I,\n                   N_ADULT_R,\n                   SEX_I,\n                   STATE)\n\n\n\n\n\nh1n1data <- transform(h1n1data,\n                   VACC_H1N1_F= as.factor(VACC_H1N1_F),\n                   VACC_SEAS_F= as.factor(VACC_SEAS_F),\n                   B_H1N1_ANTIV= as.factor(B_H1N1_ANTIV),\n                   B_H1N1_AVOID= as.factor(B_H1N1_AVOID),\n                   B_H1N1_FMASK= as.factor(B_H1N1_FMASK),\n                   B_H1N1_HANDS= as.factor(B_H1N1_HANDS),\n                   B_H1N1_LARGE= as.factor(B_H1N1_LARGE),\n                   B_H1N1_RCONT= as.factor(B_H1N1_RCONT),\n                   B_H1N1_TOUCH= as.factor(B_H1N1_TOUCH),\n                   CONCERN_LEVEL= as.factor(CONCERN_LEVEL),\n                   INT_H1N1= as.factor(INT_H1N1),\n                   KNOW_H1N1= as.factor(KNOW_H1N1),\n                   DOCREC= as.factor(DOCREC),\n                   CHRONIC_MED_F= as.factor(CHRONIC_MED_F),\n                   CLOSE_UNDER6MO_F= as.factor(CLOSE_UNDER6MO_F),\n                   HEALTH_WORKER_F= as.factor(HEALTH_WORKER_F),\n                   AGEGRP= as.factor(AGEGRP),\n                   EDUCATION_COMP= as.factor(EDUCATION_COMP),\n                   HH_CHILD_R= as.factor(HH_CHILD_R),\n                   INC_CAT1= as.factor(INC_CAT1),\n                   MARITAL= as.factor(MARITAL),\n                   RACEETH4_I= as.factor(RACEETH4_I),\n                   N_ADULT_R= as.factor(N_ADULT_R),\n                   SEX_I= as.factor(SEX_I),\n                   STATE= as.factor(STATE),\n                   PATIENT_CONTACT_F = as.factor(PATIENT_CONTACT_F),\n                   INT_SEAS = as.factor(INT_SEAS)\n                   )\n\n\n\n\n\nregion <- read_csv(\"data/state_region.csv\")\nh1n1data$state_recoded <- str_to_title(h1n1data$STATE)\nh1n1data <- left_join(h1n1data, region,\n                      by=c(\"state_recoded\" = \"State\"))\n\n\n\n\n\nglimpse(h1n1data)\n\n\nRows: 70,540\nColumns: 29\n$ VACC_H1N1_F       <fct> No, No, No, No, No, Yes, No, No, No, No, …\n$ VACC_SEAS_F       <fct> No, Yes, Yes, Yes, No, Yes, Yes, No, Yes,…\n$ B_H1N1_ANTIV      <fct> No, No, NA, No, No, No, No, No, NA, No, N…\n$ B_H1N1_AVOID      <fct> Yes, Yes, NA, Yes, Yes, No, Yes, Yes, NA,…\n$ B_H1N1_FMASK      <fct> No, No, NA, Yes, No, No, No, No, NA, No, …\n$ B_H1N1_HANDS      <fct> Yes, Yes, NA, Yes, Yes, Yes, Yes, Yes, NA…\n$ B_H1N1_LARGE      <fct> Yes, Yes, NA, Yes, Yes, No, No, Yes, NA, …\n$ B_H1N1_RCONT      <fct> Yes, No, NA, Yes, Yes, No, No, No, NA, No…\n$ B_H1N1_TOUCH      <fct> Yes, Yes, NA, Yes, Yes, Yes, No, No, NA, …\n$ CONCERN_LEVEL     <fct> 2, 2, NA, 2, 1, 2, 1, 3, NA, 2, 2, NA, 0,…\n$ INT_H1N1          <fct> 1, 2, 2, 2, 2, NA, 0, 2, 3, 1, 2, NA, 0, …\n$ KNOW_H1N1         <fct> 0, 2, NA, 2, 2, 2, 2, 0, NA, 0, 0, NA, 0,…\n$ INT_SEAS          <fct> 1, NA, NA, NA, 2, NA, NA, 2, NA, NA, NA, …\n$ DOCREC            <fct> 1, NA, 2, 1, NA, 4, 2, 1, 1, 4, 1, 4, 1, …\n$ CHRONIC_MED_F     <fct> No, Yes, Yes, Yes, No, No, No, No, No, No…\n$ CLOSE_UNDER6MO_F  <fct> No, No, NA, No, No, No, No, No, NA, Yes, …\n$ HEALTH_WORKER_F   <fct> No, No, NA, No, Yes, Yes, No, No, NA, No,…\n$ PATIENT_CONTACT_F <fct> No, NA, NA, No, No, Yes, No, No, NA, No, …\n$ AGEGRP            <fct> 65+ Years, 35 - 44 Years, 10 - 17 Years, …\n$ EDUCATION_COMP    <fct> Some College, Some College, NA, 12 Years,…\n$ HH_CHILD_R        <fct> 0, 3, 3, 0, 0, 0, 0, 2, 2, 0, 3, 3, 0, 2,…\n$ INC_CAT1          <fct> \"<= $10,000\", \"$15,001 - $25,000\", \"$15,0…\n$ MARITAL           <fct> Not Married, Not Married, NA, Married, No…\n$ RACEETH4_I        <fct> \"Non-Hispanic, White Only\", \"Non-Hispanic…\n$ N_ADULT_R         <fct> 1, 1, 1, 2, 2, 4, 2, 2, 2, 1, 2, 2, 2, 2,…\n$ SEX_I             <fct> Female, Female, Female, Female, Female, M…\n$ STATE             <fct> NEW MEXICO, OHIO, OHIO, IDAHO, OREGON, NE…\n$ state_recoded     <chr> \"New Mexico\", \"Ohio\", \"Ohio\", \"Idaho\", \"O…\n$ Region            <chr> \"West Region\", \"Midwest Region\", \"Midwest…\n\n3.2.2 Building Explainatory Model\nIn order to explain causal effects, we must rely on domain knowledge to isolate the variables that we consider impactful. Variables such as ‘State’ seem relevant but are simply too sparse to be of any use. Below code I remove it.\n\n\ndat1 <- h1n1data[,-27]\n\n\n\nRecode the target variable citizen who did take vaccine as value 1 and did not take vaccine as value 0.\n\n\ndat1$VACC_H1N1_F <- ifelse(dat1$VACC_H1N1_F==\"Yes\",1,0)\ndat1$HH_CHILD_R <- ifelse(dat1$HH_CHILD_R==\"0\",0,1)\n\n\n\nPlot missing values:\n\n\naggr(dat1[,1:10], col = c('green','red'), numbers = TRUE, sortVars = TRUE, \n     labels = names(dat1), cex.axis = .5, gap = 2, \n     ylab = c(\"Proportion in variable\",\"Proportion in dataset\"))\n\n\n\n\n Variables sorted by number of missings: \n      Variable       Count\n  B_H1N1_AVOID 0.207201588\n  B_H1N1_TOUCH 0.204678197\n CONCERN_LEVEL 0.203473207\n  B_H1N1_RCONT 0.203274738\n  B_H1N1_LARGE 0.203189680\n  B_H1N1_ANTIV 0.203132974\n  B_H1N1_HANDS 0.202098100\n  B_H1N1_FMASK 0.201360930\n   VACC_SEAS_F 0.003997732\n   VACC_H1N1_F 0.000000000\n\nBase model\nThe following is a list of all the important explanations variable for vaccinations and we did a logistic regression.\n\n\nmodel0 <- glm(VACC_H1N1_F ~ B_H1N1_ANTIV + B_H1N1_AVOID + B_H1N1_FMASK+ B_H1N1_HANDS+ B_H1N1_LARGE+ \n                B_H1N1_RCONT+ B_H1N1_TOUCH+ CONCERN_LEVEL + KNOW_H1N1 + DOCREC + CHRONIC_MED_F + HEALTH_WORKER_F + \n                MARITAL+ SEX_I + HH_CHILD_R+ N_ADULT_R, data= dat1, family = binomial(link = 'logit'))\nblr_regress(model0)\n\n\n                               Model Overview                                \n----------------------------------------------------------------------------\nData Set       Resp Var     Obs.    Df. Model    Df. Residual    Convergence \n----------------------------------------------------------------------------\n  data      VACC_H1N1_F    48950      48949         48925           TRUE     \n----------------------------------------------------------------------------\n\n                    Response Summary                     \n--------------------------------------------------------\nOutcome        Frequency        Outcome        Frequency \n--------------------------------------------------------\n   0             37926             1             11024   \n--------------------------------------------------------\n\n                      Maximum Likelihood Estimates                        \n-------------------------------------------------------------------------\n    Parameter         DF    Estimate    Std. Error    z value     Pr(>|z|) \n-------------------------------------------------------------------------\n   (Intercept)        1     -2.0238        0.0958    -21.1286      0.0000 \n B_H1N1_ANTIVYes      1      0.2249        0.0531      4.2353      0.0000 \n B_H1N1_AVOIDYes      1     -0.0066        0.0309     -0.2126      0.8317 \n B_H1N1_FMASKYes      1      0.2376        0.0454      5.2330      0.0000 \n B_H1N1_HANDSYes      1      0.1874        0.0389      4.8127      0.0000 \n B_H1N1_LARGEYes      1     -0.0767        0.0317     -2.4198      0.0155 \n B_H1N1_RCONTYes      1     -0.1177        0.0323     -3.6497       3e-04 \n B_H1N1_TOUCHYes      1      0.0837        0.0301      2.7769      0.0055 \n  CONCERN_LEVEL1      1      0.1653        0.0466      3.5515       4e-04 \n  CONCERN_LEVEL2      1      0.4280        0.0457      9.3574      0.0000 \n  CONCERN_LEVEL3      1      0.6492        0.0510     12.7190      0.0000 \n    KNOW_H1N11        1     -0.2401        0.0516     -4.6550      0.0000 \n    KNOW_H1N12        1      0.3009        0.0255     11.7908      0.0000 \n     DOCREC1          1     -0.3930        0.0751     -5.2338      0.0000 \n     DOCREC2          1     -1.0211        0.0847    -12.0508      0.0000 \n     DOCREC3          1      1.2236        0.0902     13.5617      0.0000 \n     DOCREC4          1      1.2981        0.0767     16.9266      0.0000 \n CHRONIC_MED_FYes     1      0.3219        0.0266     12.1048      0.0000 \nHEALTH_WORKER_FYes    1      0.9243        0.0341     27.0934      0.0000 \nMARITALNot Married    1     -0.1835        0.0322     -5.6921      0.0000 \n    SEX_IMale         1      0.1459        0.0255      5.7112      0.0000 \n    HH_CHILD_R        1     -0.1410        0.0278     -5.0794      0.0000 \n    N_ADULT_R2        1     -0.0429        0.0367     -1.1695      0.2422 \n    N_ADULT_R3        1     -0.1603        0.0473     -3.3912       7e-04 \n    N_ADULT_R4        1     -0.1914        0.0662     -2.8905      0.0038 \n-------------------------------------------------------------------------\n\n Association of Predicted Probabilities and Observed Responses  \n---------------------------------------------------------------\n% Concordant          0.7664          Somers' D        0.5332   \n% Discordant          0.2333          Gamma            0.5331   \n% Tied                3e-04           Tau-a            0.1860   \nPairs               418096224         c                0.7665   \n---------------------------------------------------------------\n\nblr_model_fit_stats(model0)\n\n\n                               Model Fit Statistics                                 \n-----------------------------------------------------------------------------------\nLog-Lik Intercept Only:     -39033.108    Log-Lik Full Model:            -21883.399 \nDeviance(48925):             43766.798    LR(24):                         34299.418 \n                                          Prob > LR:                          0.000 \nMCFadden's R2                    0.439    McFadden's Adj R2:                  0.439 \nML (Cox-Snell) R2:               0.385    Cragg-Uhler(Nagelkerke) R2:         0.575 \nMcKelvey & Zavoina's R2:         0.231    Efron's R2:                         0.186 \nCount R2:                        0.798    Adj Count R2:                       0.103 \nBIC:                         44036.762    AIC:                            43816.798 \n-----------------------------------------------------------------------------------\n\nIt can be seen that the current AIC is 43816.19. Next, we will try to select variable to fit the model by using Stepwise method. But before that, let us check the collinearity issue in our predictor.\ncollinearity diagnostics VIF that exceed 10 are often regarded as indicating multicollinearity, but in weaker models values above 2.5 may be a cause for concern. In our model, it seem all the explanatory varialbe is fine\n\n\nblr_coll_diag(model0)\n\n\n\n** We also see reports on goodness-of-fit statistics and criteria such as AIC, BIC, Deviance, which can be used for model selection under certain conditions. **\nBut the first thing we did was to use Stepwise in the Blorr package to select the predictor most fit the model.Build regression model from a set of candidate predictor variables by removing predictors based on akaike information criterion, in a stepwise manner until there is no variable left to remove any more.\n\n\nblr_step_aic_backward(model0, details = TRUE)\n\n\nBackward Elimination Method \n---------------------------\n\nCandidate Terms: \n\n1 . B_H1N1_ANTIV \n2 . B_H1N1_AVOID \n3 . B_H1N1_FMASK \n4 . B_H1N1_HANDS \n5 . B_H1N1_LARGE \n6 . B_H1N1_RCONT \n7 . B_H1N1_TOUCH \n8 . CONCERN_LEVEL \n9 . KNOW_H1N1 \n10 . DOCREC \n11 . CHRONIC_MED_F \n12 . HEALTH_WORKER_F \n13 . MARITAL \n14 . SEX_I \n15 . HH_CHILD_R \n16 . N_ADULT_R \n\n Step 0: AIC = 43816.8 \n VACC_H1N1_F ~ B_H1N1_ANTIV + B_H1N1_AVOID + B_H1N1_FMASK + B_H1N1_HANDS + B_H1N1_LARGE + B_H1N1_RCONT + B_H1N1_TOUCH + CONCERN_LEVEL + KNOW_H1N1 + DOCREC + CHRONIC_MED_F + HEALTH_WORKER_F + MARITAL + SEX_I + HH_CHILD_R + N_ADULT_R \n\n------------------------------------------------------------\nVariable           DF       AIC          BIC       Deviance  \n------------------------------------------------------------\nB_H1N1_AVOID       1     43814.843    44026.008    43766.843 \nB_H1N1_LARGE       1     43820.665    44031.830    43772.665 \nB_H1N1_TOUCH       1     43822.536    44033.701    43774.536 \nB_H1N1_RCONT       1     43828.154    44039.320    43780.154 \nN_ADULT_R          1     43828.996    44022.564    43784.996 \nB_H1N1_ANTIV       1     43832.422    44043.587    43784.422 \nB_H1N1_HANDS       1     43838.299    44049.464    43790.299 \nHH_CHILD_R         1     43840.786    44051.952    43792.786 \nB_H1N1_FMASK       1     43841.779    44052.945    43793.779 \nSEX_I              1     43847.365    44058.531    43799.365 \nMARITAL            1     43847.476    44058.641    43799.476 \nCHRONIC_MED_F      1     43959.296    44170.462    43911.296 \nKNOW_H1N1          1     44003.376    44205.743    43957.376 \nCONCERN_LEVEL      1     44050.436    44244.004    44006.436 \nHEALTH_WORKER_F    1     44524.798    44735.963    44476.798 \nDOCREC             1     48946.258    49131.028    48904.258 \n------------------------------------------------------------\n\n\nx B_H1N1_AVOID \n\n\n  Step 1 : AIC = 43814.84 \n VACC_H1N1_F ~ B_H1N1_ANTIV + B_H1N1_FMASK + B_H1N1_HANDS + B_H1N1_LARGE + B_H1N1_RCONT + B_H1N1_TOUCH + CONCERN_LEVEL + KNOW_H1N1 + DOCREC + CHRONIC_MED_F + HEALTH_WORKER_F + MARITAL + SEX_I + HH_CHILD_R + N_ADULT_R \n\n------------------------------------------------------------\nVariable           DF       AIC          BIC       Deviance  \n------------------------------------------------------------\nB_H1N1_LARGE       1     43818.814    44021.180    43772.814 \nB_H1N1_TOUCH       1     43820.612    44022.979    43774.612 \nB_H1N1_RCONT       1     43826.384    44028.751    43780.384 \nN_ADULT_R          1     43827.040    44011.810    43785.040 \nB_H1N1_ANTIV       1     43830.459    44032.826    43784.459 \nB_H1N1_HANDS       1     43836.790    44039.157    43790.790 \nHH_CHILD_R         1     43838.895    44041.262    43792.895 \nB_H1N1_FMASK       1     43839.831    44042.198    43793.831 \nMARITAL            1     43845.483    44047.850    43799.483 \nSEX_I              1     43845.571    44047.938    43799.571 \nCHRONIC_MED_F      1     43957.307    44159.674    43911.307 \nKNOW_H1N1          1     44001.499    44195.067    43957.499 \nCONCERN_LEVEL      1     44049.061    44233.831    44007.061 \nHEALTH_WORKER_F    1     44525.056    44727.423    44479.056 \nDOCREC             1     48945.038    49121.009    48905.038 \n------------------------------------------------------------\n\nNo more variables to be removed.\n\nVariables Removed: \n\n- B_H1N1_AVOID \n\n\nFinal Model Output \n------------------\n\n                               Model Overview                                \n----------------------------------------------------------------------------\nData Set       Resp Var     Obs.    Df. Model    Df. Residual    Convergence \n----------------------------------------------------------------------------\n  data      VACC_H1N1_F    48950      48949         48926           TRUE     \n----------------------------------------------------------------------------\n\n                    Response Summary                     \n--------------------------------------------------------\nOutcome        Frequency        Outcome        Frequency \n--------------------------------------------------------\n   0             37926             1             11024   \n--------------------------------------------------------\n\n                      Maximum Likelihood Estimates                        \n-------------------------------------------------------------------------\n    Parameter         DF    Estimate    Std. Error    z value     Pr(>|z|) \n-------------------------------------------------------------------------\n   (Intercept)        1     -2.0257        0.0954    -21.2417      0.0000 \n B_H1N1_ANTIVYes      1      0.2248        0.0531      4.2344      0.0000 \n B_H1N1_FMASKYes      1      0.2376        0.0454      5.2337      0.0000 \n B_H1N1_HANDSYes      1      0.1858        0.0383      4.8566      0.0000 \n B_H1N1_LARGEYes      1     -0.0772        0.0316     -2.4410      0.0146 \n B_H1N1_RCONTYes      1     -0.1182        0.0322     -3.6746       2e-04 \n B_H1N1_TOUCHYes      1      0.0825        0.0297      2.7825      0.0054 \n  CONCERN_LEVEL1      1      0.1647        0.0465      3.5451       4e-04 \n  CONCERN_LEVEL2      1      0.4272        0.0456      9.3760      0.0000 \n  CONCERN_LEVEL3      1      0.6484        0.0509     12.7334      0.0000 \n    KNOW_H1N11        1     -0.2396        0.0515     -4.6501      0.0000 \n    KNOW_H1N12        1      0.3008        0.0255     11.7891      0.0000 \n     DOCREC1          1     -0.3930        0.0751     -5.2335      0.0000 \n     DOCREC2          1     -1.0211        0.0847    -12.0510      0.0000 \n     DOCREC3          1      1.2235        0.0902     13.5603      0.0000 \n     DOCREC4          1      1.2980        0.0767     16.9255      0.0000 \n CHRONIC_MED_FYes     1      0.3218        0.0266     12.1033      0.0000 \nHEALTH_WORKER_FYes    1      0.9246        0.0341     27.1359      0.0000 \nMARITALNot Married    1     -0.1833        0.0322     -5.6887      0.0000 \n    SEX_IMale         1      0.1461        0.0255      5.7253      0.0000 \n    HH_CHILD_R        1     -0.1411        0.0277     -5.0856      0.0000 \n    N_ADULT_R2        1     -0.0430        0.0367     -1.1712      0.2415 \n    N_ADULT_R3        1     -0.1604        0.0473     -3.3927       7e-04 \n    N_ADULT_R4        1     -0.1914        0.0662     -2.8895      0.0039 \n-------------------------------------------------------------------------\n\n Association of Predicted Probabilities and Observed Responses  \n---------------------------------------------------------------\n% Concordant          0.7663          Somers' D        0.5333   \n% Discordant          0.2333          Gamma            0.5331   \n% Tied                4e-04           Tau-a            0.1860   \nPairs               418096224         c                0.7665   \n---------------------------------------------------------------\n\n            Backward Elimination Summary             \n---------------------------------------------------\nVariable           AIC          BIC       Deviance  \n---------------------------------------------------\nFull Model      43816.798    44036.762    43766.798 \nB_H1N1_AVOID    43814.843    44026.008    43766.843 \n---------------------------------------------------\n\n\n\nblr_step_aic_forward(model2)\n\n\n\n\n\nblr_step_p_backward(model2)\n\n\n\n3.3 Model Selection\nHowever, we found that AIC had no change after step wise, which proved that this method was not applicable to our case. So the next part I will do is to select model begin with our domain knowledge in considering H1N1 vaccination.\nThe model selection process will involve fitting several candidate models until we run into the one that’s closest to the “true” model. At every comparison, candidate models will be evaluated with respect to specific asymptotic criteria (to be explained). We’ll start off with a very simple model。\nWe also see reports on goodness-of-fit statistics and criteria such as AIC, BIC, Deviance, which can be used for model selection under certain conditions. The obvious next steps are to add more predictors into the model and see whether the fit improves.\n3.3.1 Add three transfrom variables\nThere are three variables that we combine and concatenate from original raw data set. Below is the definition.\nVariable\nDefinition\nCONCERN LEVEL 0-3\n0 is not at all, 1 is not very, 2 is somewhat concerned, 3 is very concern\nKNOW_H1N1 0-2\n0 no knowledge, 1 a little knowledge, 2 a lot\nDOCREC 0-4\n0 is unknown and refused, 1 neither vaccine is recommend, 2 seasonal,3 H1N1, 4 both\n\n\nmodel <- glm(VACC_H1N1_F ~ CONCERN_LEVEL , data= dat1, family = binomial(link = 'logit'))\n\n\n\n\n\nmodel2 <- glm(VACC_H1N1_F ~ CONCERN_LEVEL + KNOW_H1N1 + DOCREC, data= dat1, family = binomial(link = 'logit'))\n\nblr_multi_model_fit_stats(model,model2)\n\n\n                               Measures    Model 1    Model 2\nloglik_null      Log-Lik Intercept Only -39033.108 -39033.108\nloglik_model         Log-Lik Full Model -28720.426 -24173.572\nm_deviance                     Deviance  57440.852  48347.144\nlr_ratio                             LR  20625.364  29719.071\nlr_pval                       Prob > LR      0.000      0.000\nmcfadden                  MCFadden's R2      0.264      0.381\nadj_mcfadden          McFadden's Adj R2      0.264      0.380\nm_aic                 ML (Cox-Snell) R2  57448.852  48367.144\ncox_snell    Cragg-Uhler(Nagelkerke) R2      0.254      0.344\nm_bic           McKelvey & Zavoina's R2  57484.598  48455.908\nmckelvey                     Efron's R2      0.026      0.198\neffron                         Count R2      0.015      0.163\nnagelkerke                 Adj Count R2      0.379      0.514\ncount_r2                            AIC      0.787      0.793\ncount_adj                           BIC      0.000      0.075\n\n3.3.2 Select Behavior Variable to Continue Build Explanatory Model\n\n\ngfit1a = glm(VACC_H1N1_F ~ CONCERN_LEVEL + KNOW_H1N1 + \n               DOCREC + B_H1N1_ANTIV, data= dat1, family = binomial(link = 'logit'))\ngfit1b = glm(VACC_H1N1_F ~ CONCERN_LEVEL + KNOW_H1N1 + \n               DOCREC + B_H1N1_ANTIV+B_H1N1_AVOID, data= dat1, family = binomial(link = 'logit'))\ngfit1c = glm(VACC_H1N1_F ~ CONCERN_LEVEL + KNOW_H1N1 + \n               DOCREC + B_H1N1_ANTIV +B_H1N1_AVOID +B_H1N1_FMASK, data= dat1, family = binomial(link = 'logit'))\ngfit1d = glm(VACC_H1N1_F ~ CONCERN_LEVEL + KNOW_H1N1 + DOCREC \n             + B_H1N1_ANTIV +B_H1N1_AVOID +B_H1N1_FMASK+ B_H1N1_HANDS, data= dat1, family = binomial(link = 'logit'))\n\nblr_multi_model_fit_stats(model2, gfit1a, gfit1b,gfit1c,gfit1d)\n\n\n                               Measures    Model 1    Model 2\nloglik_null      Log-Lik Intercept Only -39033.108 -39033.108\nloglik_model         Log-Lik Full Model -24173.572 -24077.127\nm_deviance                     Deviance  48347.144  48154.254\nlr_ratio                             LR  29719.071  29911.962\nlr_pval                       Prob > LR      0.000      0.000\nmcfadden                  MCFadden's R2      0.381      0.383\nadj_mcfadden          McFadden's Adj R2      0.380      0.383\nm_aic                 ML (Cox-Snell) R2  48367.144  48176.254\ncox_snell    Cragg-Uhler(Nagelkerke) R2      0.344      0.346\nm_bic           McKelvey & Zavoina's R2  48455.908  48273.864\nmckelvey                     Efron's R2      0.198      0.199\neffron                         Count R2      0.163      0.163\nnagelkerke                 Adj Count R2      0.514      0.516\ncount_r2                            AIC      0.793      0.793\ncount_adj                           BIC      0.075      0.076\n                Model 3    Model 4    Model 5\nloglik_null  -39033.108 -39033.108 -39033.108\nloglik_model -23902.787 -23866.864 -23827.075\nm_deviance    47805.573  47733.729  47654.151\nlr_ratio      30260.643  30332.487  30412.065\nlr_pval           0.000      0.000      0.000\nmcfadden          0.388      0.389      0.390\nadj_mcfadden      0.387      0.388      0.389\nm_aic         47829.573  47759.729  47682.151\ncox_snell         0.349      0.349      0.350\nm_bic         47935.968  47874.984  47806.256\nmckelvey          0.199      0.200      0.201\neffron            0.163      0.164      0.164\nnagelkerke        0.521      0.522      0.523\ncount_r2          0.794      0.794      0.795\ncount_adj         0.079      0.077      0.081\n\nWe found that the Behavior Varible had no significant effect on AIC after insert the first variable ‘B_H1N1_ANTIV’, which define as indicator of taking anti-viral medications. After consideration, I only kept ‘B_H1N1_ANTIV’ variable.\ncontinue adding predictor\n\n\ngfit1f <- glm(VACC_H1N1_F ~ CONCERN_LEVEL + KNOW_H1N1 + \n                DOCREC + B_H1N1_ANTIV+CHRONIC_MED_F, data= dat1, family = binomial(link = 'logit'))\ngfit1g <- glm(VACC_H1N1_F ~ CONCERN_LEVEL + KNOW_H1N1 + \n                DOCREC + B_H1N1_ANTIV+CHRONIC_MED_F +HEALTH_WORKER_F, data= dat1, family = binomial(link = 'logit'))\nblr_multi_model_fit_stats(gfit1a, gfit1f,gfit1g )\n\n\n                               Measures    Model 1    Model 2\nloglik_null      Log-Lik Intercept Only -39033.108 -39033.108\nloglik_model         Log-Lik Full Model -24077.127 -23323.858\nm_deviance                     Deviance  48154.254  46647.716\nlr_ratio                             LR  29911.962  31418.499\nlr_pval                       Prob > LR      0.000      0.000\nmcfadden                  MCFadden's R2      0.383      0.402\nadj_mcfadden          McFadden's Adj R2      0.383      0.402\nm_aic                 ML (Cox-Snell) R2  48176.254  46671.716\ncox_snell    Cragg-Uhler(Nagelkerke) R2      0.346      0.359\nm_bic           McKelvey & Zavoina's R2  48273.864  46777.826\nmckelvey                     Efron's R2      0.199      0.203\neffron                         Count R2      0.163      0.166\nnagelkerke                 Adj Count R2      0.516      0.537\ncount_r2                            AIC      0.793      0.795\ncount_adj                           BIC      0.076      0.086\n                Model 3\nloglik_null  -39033.108\nloglik_model -22884.809\nm_deviance    45769.618\nlr_ratio      32296.598\nlr_pval           0.000\nmcfadden          0.414\nadj_mcfadden      0.413\nm_aic         45795.618\ncox_snell         0.367\nm_bic         45910.528\nmckelvey          0.222\neffron            0.180\nnagelkerke        0.549\ncount_r2          0.796\ncount_adj         0.089\n\nFrom above table, we can see that variable ‘CHRONIC_MED_F’ and variable ‘HEALTH_WORKER_F’ are fit to the explanatory table by the large decrease of AIC.\n\n\ngfit1h <- glm(VACC_H1N1_F ~ CONCERN_LEVEL + KNOW_H1N1 + DOCREC + \n                B_H1N1_ANTIV+CHRONIC_MED_F +HEALTH_WORKER_F + MARITAL, data= dat1, family = binomial(link = 'logit'))\nblr_multi_model_fit_stats(gfit1g, gfit1h)\n\n\n                               Measures    Model 1    Model 2\nloglik_null      Log-Lik Intercept Only -39033.108 -39033.108\nloglik_model         Log-Lik Full Model -22884.809 -22322.996\nm_deviance                     Deviance  45769.618  44645.991\nlr_ratio                             LR  32296.598  33420.224\nlr_pval                       Prob > LR      0.000      0.000\nmcfadden                  MCFadden's R2      0.414      0.428\nadj_mcfadden          McFadden's Adj R2      0.413      0.428\nm_aic                 ML (Cox-Snell) R2  45795.618  44673.991\ncox_snell    Cragg-Uhler(Nagelkerke) R2      0.367      0.377\nm_bic           McKelvey & Zavoina's R2  45910.528  44797.405\nmckelvey                     Efron's R2      0.222      0.225\neffron                         Count R2      0.180      0.182\nnagelkerke                 Adj Count R2      0.549      0.564\ncount_r2                            AIC      0.796      0.796\ncount_adj                           BIC      0.089      0.091\n\nFrom above table, we can see that variable ‘Marital’ is fit to the explanatory table by a large decrease of AIC.\n\n\ngfit1i <- glm(VACC_H1N1_F ~ CONCERN_LEVEL + KNOW_H1N1 + DOCREC + B_H1N1_ANTIV+\n                CHRONIC_MED_F +HEALTH_WORKER_F + MARITAL+ HH_CHILD_R, data= dat1, family = binomial(link = 'logit'))\nblr_multi_model_fit_stats(gfit1h, gfit1i)\n\n\n                               Measures    Model 1    Model 2\nloglik_null      Log-Lik Intercept Only -39033.108 -39033.108\nloglik_model         Log-Lik Full Model -22322.996 -22299.160\nm_deviance                     Deviance  44645.991  44598.320\nlr_ratio                             LR  33420.224  33467.896\nlr_pval                       Prob > LR      0.000      0.000\nmcfadden                  MCFadden's R2      0.428      0.429\nadj_mcfadden          McFadden's Adj R2      0.428      0.428\nm_aic                 ML (Cox-Snell) R2  44673.991  44628.320\ncox_snell    Cragg-Uhler(Nagelkerke) R2      0.377      0.378\nm_bic           McKelvey & Zavoina's R2  44797.405  44760.544\nmckelvey                     Efron's R2      0.225      0.226\neffron                         Count R2      0.182      0.183\nnagelkerke                 Adj Count R2      0.564      0.564\ncount_r2                            AIC      0.796      0.796\ncount_adj                           BIC      0.091      0.095\n\nAfter adding variable ‘HH_CHILE_R’, AIC did not show any significant decrease, so ‘HH_CHILE_R’ are determined not to fit this model\nN_ADULT_R\n\n\ngfit1j <- glm(VACC_H1N1_F ~ CONCERN_LEVEL + KNOW_H1N1 + DOCREC + B_H1N1_ANTIV+\n                CHRONIC_MED_F +HEALTH_WORKER_F + MARITAL+ N_ADULT_R, data= dat1, family = binomial(link = 'logit'))\nblr_multi_model_fit_stats(gfit1h, gfit1j)\n\n\n                               Measures    Model 1    Model 2\nloglik_null      Log-Lik Intercept Only -39033.108 -39033.108\nloglik_model         Log-Lik Full Model -22322.996 -22305.967\nm_deviance                     Deviance  44645.991  44611.934\nlr_ratio                             LR  33420.224  33454.282\nlr_pval                       Prob > LR      0.000      0.000\nmcfadden                  MCFadden's R2      0.428      0.429\nadj_mcfadden          McFadden's Adj R2      0.428      0.428\nm_aic                 ML (Cox-Snell) R2  44673.991  44645.934\ncox_snell    Cragg-Uhler(Nagelkerke) R2      0.377      0.378\nm_bic           McKelvey & Zavoina's R2  44797.405  44795.788\nmckelvey                     Efron's R2      0.225      0.226\neffron                         Count R2      0.182      0.183\nnagelkerke                 Adj Count R2      0.564      0.564\ncount_r2                            AIC      0.796      0.796\ncount_adj                           BIC      0.091      0.092\n\nAfter adding variable ‘N_ADULT_R’, AIC did not show any significant decrease, so ‘N_ADULT_R’ are determined not to fit this model\nSEX_I\n\n\ngfit1k <- glm(VACC_H1N1_F ~ CONCERN_LEVEL + KNOW_H1N1 + DOCREC + B_H1N1_ANTIV+CHRONIC_MED_F +\n                HEALTH_WORKER_F + MARITAL+ SEX_I, data= dat1, family = binomial(link = 'logit'))\nblr_multi_model_fit_stats(gfit1h, gfit1k)\n\n\n                               Measures    Model 1    Model 2\nloglik_null      Log-Lik Intercept Only -39033.108 -39033.108\nloglik_model         Log-Lik Full Model -22322.996 -22310.047\nm_deviance                     Deviance  44645.991  44620.093\nlr_ratio                             LR  33420.224  33446.123\nlr_pval                       Prob > LR      0.000      0.000\nmcfadden                  MCFadden's R2      0.428      0.428\nadj_mcfadden          McFadden's Adj R2      0.428      0.428\nm_aic                 ML (Cox-Snell) R2  44673.991  44650.093\ncox_snell    Cragg-Uhler(Nagelkerke) R2      0.377      0.378\nm_bic           McKelvey & Zavoina's R2  44797.405  44782.322\nmckelvey                     Efron's R2      0.225      0.226\neffron                         Count R2      0.182      0.183\nnagelkerke                 Adj Count R2      0.564      0.564\ncount_r2                            AIC      0.796      0.796\ncount_adj                           BIC      0.091      0.092\n\nAfter adding variable ‘SEX_I’, AIC did not show any significant decrease, so ‘SEX_I’ are determined not to fit this model\nAlthough this AIC is still lower than original ‘model0’ that we initially chose, we have evidence to prove that the variable we chose can better explain this model. The reason why AIC of Model0 is lower than AIC of the current model is most likely missing value in behavior variable. When R runs logistic regression, these rows containing missing value are automatically ignored, thus reducing AIC. But current models are more convincing. So our best fit model so fat is gfit1h <- glm(VACC_H1N1_F ~ CONCERN_LEVEL + KNOW_H1N1 + DOCREC + B_H1N1_ANTIV+CHRONIC_MED_F +HEALTH_WORKER_F + MARITAL, data= dat1, family = binomial(link = ‘logit’))\n3.4 ‘blorr’ and ‘sjPlot’ Package Exploration\n\n\nblr_regress(gfit1h)\n\n\n                               Model Overview                                \n----------------------------------------------------------------------------\nData Set       Resp Var     Obs.    Df. Model    Df. Residual    Convergence \n----------------------------------------------------------------------------\n  data      VACC_H1N1_F    49775      49774         49761           TRUE     \n----------------------------------------------------------------------------\n\n                    Response Summary                     \n--------------------------------------------------------\nOutcome        Frequency        Outcome        Frequency \n--------------------------------------------------------\n   0             38580             1             11195   \n--------------------------------------------------------\n\n                      Maximum Likelihood Estimates                        \n-------------------------------------------------------------------------\n    Parameter         DF    Estimate    Std. Error    z value     Pr(>|z|) \n-------------------------------------------------------------------------\n   (Intercept)        1     -1.9045        0.0819    -23.2461      0.0000 \n  CONCERN_LEVEL1      1      0.1770        0.0454      3.8969       1e-04 \n  CONCERN_LEVEL2      1      0.4399        0.0434     10.1253      0.0000 \n  CONCERN_LEVEL3      1      0.6585        0.0477     13.7952      0.0000 \n    KNOW_H1N11        1     -0.2424        0.0504     -4.8054      0.0000 \n    KNOW_H1N12        1      0.3155        0.0252     12.5380      0.0000 \n     DOCREC1          1     -0.4120        0.0726     -5.6722      0.0000 \n     DOCREC2          1     -1.0343        0.0824    -12.5586      0.0000 \n     DOCREC3          1      1.1940        0.0878     13.5957      0.0000 \n     DOCREC4          1      1.2756        0.0742     17.1960      0.0000 \n B_H1N1_ANTIVYes      1      0.2087        0.0517      4.0396       1e-04 \n CHRONIC_MED_FYes     1      0.3328        0.0260     12.7949      0.0000 \nHEALTH_WORKER_FYes    1      0.9189        0.0333     27.5567      0.0000 \nMARITALNot Married    1     -0.1523        0.0243     -6.2675      0.0000 \n-------------------------------------------------------------------------\n\n Association of Predicted Probabilities and Observed Responses  \n---------------------------------------------------------------\n% Concordant          0.7581          Somers' D        0.5317   \n% Discordant          0.2318          Gamma            0.5263   \n% Tied                0.0101          Tau-a            0.1835   \nPairs               431903100         c                0.7632   \n---------------------------------------------------------------\n\nblr_model_fit_stats(gfit1h)\n\n\n                               Model Fit Statistics                                 \n-----------------------------------------------------------------------------------\nLog-Lik Intercept Only:     -39033.108    Log-Lik Full Model:            -22322.996 \nDeviance(49761):             44645.991    LR(13):                         33420.224 \n                                          Prob > LR:                          0.000 \nMCFadden's R2                    0.428    McFadden's Adj R2:                  0.428 \nML (Cox-Snell) R2:               0.377    Cragg-Uhler(Nagelkerke) R2:         0.564 \nMcKelvey & Zavoina's R2:         0.225    Efron's R2:                         0.182 \nCount R2:                        0.796    Adj Count R2:                       0.091 \nBIC:                         44797.405    AIC:                            44673.991 \n-----------------------------------------------------------------------------------\n\ncollinearity diagnostics on current model VIF that exceed 10 are often regarded as indicating multicollinearity, but in weaker models values above 2.5 may be a cause for concern. In our model, it seem all the explanatory varialbe is fine.\n\n\nblr_coll_diag(gfit1h)\n\n\nTolerance and Variance Inflation Factor\n---------------------------------------\n             Variable Tolerance      VIF\n1      CONCERN_LEVEL1 0.3956554 2.527452\n2      CONCERN_LEVEL2 0.3727496 2.682766\n3      CONCERN_LEVEL3 0.4896430 2.042304\n4          KNOW_H1N11 0.9160660 1.091624\n5          KNOW_H1N12 0.9083588 1.100887\n6             DOCREC1 0.1047972 9.542244\n7             DOCREC2 0.1805549 5.538481\n8             DOCREC3 0.4635360 2.157330\n9             DOCREC4 0.1482760 6.744178\n10    B_H1N1_ANTIVYes 0.9857712 1.014434\n11   CHRONIC_MED_FYes 0.9438335 1.059509\n12 HEALTH_WORKER_FYes 0.9576852 1.044184\n13 MARITALNot Married 0.9725132 1.028264\n\n\nEigenvalue and Condition Index\n------------------------------\n   Eigenvalue Condition Index    intercept CONCERN_LEVEL1\n1  4.47595334        1.000000 4.103814e-05   4.498075e-05\n2  1.23668868        1.902447 5.166615e-06   4.387617e-04\n3  1.16556108        1.959635 7.281643e-07   5.958998e-05\n4  1.03000147        2.084605 2.005268e-08   7.686205e-05\n5  0.99793605        2.117832 2.431683e-07   1.651098e-04\n6  0.95699984        2.162653 4.731020e-08   8.808643e-04\n7  0.90884376        2.219209 1.418821e-07   2.330486e-05\n8  0.82382391        2.330910 3.177016e-07   5.130630e-04\n9  0.79995392        2.365431 4.955707e-06   8.192435e-07\n10 0.58797883        2.759065 1.252409e-05   1.522190e-05\n11 0.53513525        2.892085 1.913908e-06   2.921654e-06\n12 0.38847374        3.394392 1.752155e-04   3.576528e-04\n13 0.08052532        7.455496 1.386463e-03   8.537141e-03\n14 0.01212481       19.213450 4.103343e-02   6.287625e-04\n   CONCERN_LEVEL2 CONCERN_LEVEL3   KNOW_H1N11   KNOW_H1N12\n1    6.620711e-05   3.670524e-05 2.054797e-05 9.189276e-05\n2    1.750621e-05   3.167875e-04 2.533815e-04 9.763749e-05\n3    1.396407e-04   6.035886e-04 8.854450e-04 3.350935e-04\n4    3.443186e-04   2.408446e-04 1.492012e-05 5.011296e-08\n5    5.357656e-04   2.450998e-04 4.708721e-05 1.715065e-06\n6    8.182862e-04   3.330363e-05 4.149938e-04 6.388152e-05\n7    9.105413e-06   4.754821e-07 4.194479e-04 4.908061e-05\n8    4.959919e-06   1.559202e-03 1.291786e-04 1.745905e-04\n9    5.763945e-06   9.807733e-05 1.111088e-03 6.712639e-05\n10   1.356530e-05   2.143261e-05 3.638067e-04 1.324741e-03\n11   1.160403e-05   2.775875e-05 7.581818e-04 1.747545e-03\n12   6.213359e-04   5.874716e-04 1.230971e-04 3.011419e-03\n13   1.177621e-02   5.241067e-03 1.389484e-04 1.185941e-04\n14   8.265211e-04   3.415267e-04 3.586146e-05 2.599130e-05\n        DOCREC1      DOCREC2      DOCREC3      DOCREC4\n1  1.157297e-04 3.374155e-05 8.063685e-06 7.240256e-05\n2  5.660723e-04 5.561475e-06 3.962221e-05 1.558130e-03\n3  1.290438e-04 3.625470e-04 1.297413e-04 2.586889e-05\n4  2.270512e-04 2.211815e-03 6.957570e-04 3.036297e-07\n5  6.058565e-06 5.145264e-05 2.970165e-03 6.091922e-04\n6  2.687834e-04 6.498775e-04 6.096598e-04 4.237834e-06\n7  2.094081e-05 3.934063e-04 2.830208e-04 5.960346e-04\n8  3.274310e-04 6.793432e-05 3.626091e-05 1.823658e-03\n9  1.008630e-04 1.913592e-04 2.013493e-06 4.735430e-05\n10 9.304103e-05 2.028304e-04 2.274589e-05 7.628030e-04\n11 4.422238e-05 3.058448e-05 6.568671e-08 3.244664e-04\n12 4.707379e-04 1.731532e-04 3.803928e-05 4.940525e-04\n13 8.148647e-03 2.422029e-03 5.664855e-04 4.711567e-03\n14 9.792987e-02 2.402457e-02 5.580811e-03 4.447707e-02\n   B_H1N1_ANTIVYes CHRONIC_MED_FYes HEALTH_WORKER_FYes\n1     2.950855e-05     1.987093e-04       4.302490e-04\n2     2.407958e-04     1.484126e-04       2.456596e-03\n3     3.562514e-04     3.306972e-04       5.256532e-03\n4     5.529198e-04     3.877998e-04       4.626853e-04\n5     4.036926e-05     1.336634e-05       1.574600e-04\n6     3.694631e-04     7.757257e-05       7.643660e-04\n7     5.144970e-03     3.510143e-04       1.458814e-06\n8     9.643727e-04     3.136235e-04       1.878534e-03\n9     4.168956e-05     8.455634e-04       3.705783e-02\n10    6.345420e-05     8.979167e-03       8.790117e-03\n11    1.248638e-05     2.577916e-03       2.979031e-04\n12    3.668923e-05     7.529849e-04       7.025951e-06\n13    6.488497e-07     2.727236e-05       1.885855e-05\n14    2.944345e-07     1.510983e-05       1.197428e-05\n   MARITALNot Married\n1        8.977128e-03\n2        6.549090e-03\n3        3.376096e-03\n4        6.937633e-05\n5        1.876332e-06\n6        7.682279e-04\n7        1.981414e-03\n8        4.552646e-06\n9        1.070521e-03\n10       1.338774e-03\n11       2.968223e-01\n12       2.794646e-01\n13       1.686756e-02\n14       5.708095e-03\n\nconfusion_matrix\n\n\nblr_confusion_matrix(gfit1h)\n\n\nConfusion Matrix and Statistics \n\n          Reference\nPrediction     0     1\n         0 36127  7718\n         1  2453  3477\n\n                Accuracy : 0.7957 \n     No Information Rate : 0.7751 \n\n                   Kappa : 0.2965 \n\nMcNemars's Test P-Value  : 0.0000 \n\n             Sensitivity : 0.3106 \n             Specificity : 0.9364 \n          Pos Pred Value : 0.5863 \n          Neg Pred Value : 0.8240 \n              Prevalence : 0.2249 \n          Detection Rate : 0.0699 \n    Detection Prevalence : 0.1191 \n       Balanced Accuracy : 0.6235 \n               Precision : 0.5863 \n                  Recall : 0.3106 \n\n        'Positive' Class : 1\n\nHosmer lemeshow goodness of fit test\n\n\nblr_test_hosmer_lemeshow(gfit1h)\n\n\n           Partition for the Hosmer & Lemeshow Test            \n--------------------------------------------------------------\n                        def = 1                 def = 0        \nGroup    Total    Observed    Expected    Observed    Expected \n--------------------------------------------------------------\n  1      5001       356        335.68       4645      4665.32  \n  2      5043       411        455.13       4632      4587.87  \n  3      4913       468        519.45       4445      4393.55  \n  4      4980       556        596.27       4424      4383.73  \n  5      5291       710        718.25       4581      4572.75  \n  6      6115       942        979.04       5173      5135.96  \n  7      3539       667        680.75       2872      2858.25  \n  8      5048       1672      1495.66       3376      3552.34  \n  9      5083       2533      2368.37       2550      2714.63  \n 10      4762       2880      3046.41       1882      1715.59  \n--------------------------------------------------------------\n\n     Goodness of Fit Test      \n------------------------------\nChi-Square    DF    Pr > ChiSq \n------------------------------\n 93.1307      8       0.0000   \n------------------------------\n\nDiagnostics for detecting ill fitted observations\n\n\nblr_plot_diag_difdev(gfit1h)\n\n\n\n\n\n\nblr_plot_diag_difchisq(gfit1h)\n\n\n\n\nModel interpretation\n\n\nexp(coef(gfit1h))\n\n\n       (Intercept)     CONCERN_LEVEL1     CONCERN_LEVEL2 \n         0.1488963          1.1936463          1.5525988 \n    CONCERN_LEVEL3         KNOW_H1N11         KNOW_H1N12 \n         1.9318415          0.7847801          1.3709536 \n           DOCREC1            DOCREC2            DOCREC3 \n         0.6622965          0.3554634          3.3002736 \n           DOCREC4    B_H1N1_ANTIVYes   CHRONIC_MED_FYes \n         3.5810001          1.2321034          1.3948007 \nHEALTH_WORKER_FYes MARITALNot Married \n         2.5064326          0.8587532 \n\nConcern_level :\nH1N1 vaccination probability is 119% higher in concern_level1(not very concerned about H1N1), compared to concern_level0(Not at all concerned about H1N1).\nH1N1 vaccination probability is 155% higher in concern_level2(somewhat concerned about H1N1), compared to concern_level0(Not at all concerned about H1N1).\nH1N1 vaccination probability is 193% higher in concern_level3(very concerned about H1N1), compared to concern_level0(Not at all concerned about H1N1).\nKNOW_H1N1:\nH1N1 vaccination probability is 78.47% lower in KNOW_H1N11(little knowledge about H1N1), compared to KNOW_H1N10(No knowledge about H1N1).\nH1N1 vaccination probability is 137% higher in KNOW_H1N12(a lot knowledge about H1N1), compared to KNOW_H1N10(No knowledge about H1N1).\nDOCREC:\nH1N1 vaccination probability is 66.23% lower in DOCREC1(DOCTORS RECOMMENDATION FOR NEITHER H1N1 NOR SEASONAL VACCINE), compared to DOCREC0(Doctors opinions don’t know)\nH1N1 vaccination probability is 35.54% lower in DOCREC2(Doctors recommendation for seasonal), compared to DOCREC0(Doctors opinions don’t know)\nH1N1 vaccination probability is 330% higher in DOCREC3(Doctors recommendation for H1N1), compared to DOCREC0(Doctors opinions don’t know)\nH1N1 vaccination probability is 358% higher in DOCREC4(Doctors recommendation for both), compared to DOCREC0(Doctors opinions don’t know)\nB_H1N1_ANTIV:\nH1N1 vaccination probability is 123% higher in B_H1N1_ANTIVYes(TAKING ANTIVIRAL MEDICATIONS), compared to B_H1N1_ANTIVNo\nCHRONIC_MED_F:\nH1N1 vaccination probability is 139% higher in CHRONIC_MED_FYes(having chronic medical condition), compared to CHRONIC_MED_FNo\nHEALTH_WORKER_F:\nH1N1 vaccination probability is 250% higher in HEALTH_WORKER_FYes(the person is a health worker), compared to HEALTH_WORKER_FNo\nMARITALNot Married:\nH1N1 vaccination probability is 86% lower in MARITAL-Not Married, compared to MARITAL-Married.\nPlot\n\n\nplot_model(gfit1h, \n           show.values = TRUE, value.offset = .3)\n\n\n\n\n4 Sketch of proposed visualisation\n\n\n\nThe upper left corner provides the option that the user chooses to see, such as odd ratio, test_hosmer_lemeshow,plot_diag_difdev, then the corresponding graph and the information appears on the right side to showcase\nThe bottom left hand corner gives the user the option of selecting variable to see how that variable interprets/explain the model and then on the right hand side the message will show up.\n5.References\nhttps://towardsdatascience.com/explanatory-modeling-f1f890d11ac2\nhttps://cran.r-project.org/web/packages/blorr/blorr.pdf\nhttps://www.r-statistics.com/2010/07/visualization-of-regression-coefficients-in-r/\nhttps://cran.r-project.org/web/packages/sjPlot/index.html\nhttps://easystats.github.io/performance/reference/performance_roc.html\n\n\n\n",
    "preview": "posts/2021-03-23-logistic-regression/logistic-regression_files/figure-html5/unnamed-chunk-13-1.png",
    "last_modified": "2021-04-23T23:17:26+08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-02-23-proposal/",
    "title": "Group 5 Proposal",
    "description": "Below is our project proposal detail.",
    "author": [
      {
        "name": "Desmond LIM Pek Loong, HAI Dan, TAY Kai lin",
        "url": "https://example.com/norajones"
      }
    ],
    "date": "2021-02-23",
    "categories": [],
    "contents": "\nMotivation of the project\nWith the outbreak of Covid-19 and recent advancements in vaccination, an important task that public health authorities are looking into is increasing vaccination rates. This would entail looking into the factors that result in an individual undergoing vaccination and how to predict whether an individual would go for the vaccine.\nOur team is interested in drawing a parallel to another 21st century pandemic, the H1N1 virus, which is also known as the swine flu, that broke out in 2009. An extensive study had been conducted by the USA known as the National 2009 H1N1 Flu Survey (NHFS) into the demographics, attitudes towards H1N1 virus or the vaccine, and whether an individual had taken the H1N1 vaccine. This extensive dataset would not just allow us to perform descriptive analytics on how H1N1 vaccination rates vary in USA, but also allows us to do predictions on whether an individual would go for the vaccine.\nData Source\nThe source for our data is provided at the following link: https://www.cdc.gov/nchs/nis/data_files_h1n1.htm\nProblems or issues that the project will address\nThis project will address the following problems:\nDescriptive Analytics: How do vaccination rates vary across states in the USA?\nPredictive Analytics: How do we predict whether an individual would go for the H1N1 vaccine?\nProject Objectives\nThe project aims to use NFHS data to:\nVisualize vaccination receptivity in across states in US\nVisualize the relationships between vaccination and other variables.\nCreate predictive model of vaccination through Logistic regression, Decision tree and random forest\nProposed Scope and Methodology\nData Preparation\nData cleaning will be done using Excel and R. Excel is used as the first preliminary data cleaning to remove columns that will not be used and to combine binary columns into a single column. As for R, we will be using it to remove rows that have blanks for our target variables and to remove columns that have a proportion of blanks above a certain percentage.\nVisualization\nThe first page of the visualization would be our Map. In the Map, we would show how the survey responses and vaccination rates differ across various states in the USA.\nThe second page of the visualization would be our Exploratory Data Analysis (EDA). In our EDA, we will explore the factors that affect H1N1 vaccination. We will have visualizations for both a density plot and a multiplot. The density plot will help users visualize how every factor affects whether an individual would go for vaccination. Users can select the factors to be displayed on the correlation plot. The multiplot will help us to visualize the distribution of our target binary variable according to the factors in the survey. Users can select the factor that they wish to display on the visualization.\nThe third page of the visualization is our logistic regression. The fourth page will showcase the decision tree and random forest model.\nThe last page of the visualization is our Model Comparison.\nEarly prototypes or storyboards\nPage 1: Map\n\n\n\nPage 2: Exploratory Data Analysis (EDA) - Density Plot & Multiplot\n\n\n\nPage 3: Predictive Analytics\n\n\n\nPage 4: Decision Tree/Random Forest\nPage 5: Model Comparison\nR Packages to be used\nPackage Name\nDescription\nShiny and shinydashboard\nFor building interactive web applications with R\ndplyr\nFor effective data manipulation\nreadr\nFor reading excel files in R\nggplot2\nFor plotting various visualizations and EDA\ndlookr\nFor plotting various visualizations and EDA\nrpart\nTo perform recursive partitioning I.e. Decision Tree modelling\nrandomForest\nTo perform random forest modelling\nProject Timeline\n\n\n\nReferences\nComparison of the Logistic Regression, Decision Tree, and Random Forest Models to Predict Red Wine Quality in R: https://towardsdatascience.com/comparison-of-the-logistic-regression-decision-tree-and-random-forest-models-to-predict-red-wine-313d012d6953\nA COMPLETE GUIDE TO RANDOM FOREST IN R: https://www.listendata.com/2014/11/random-forest-with-r.html\nIntroduction to Random Forest in R: https://www.simplilearn.com/tutorials/data-science-tutorial/random-forest-in-r\nLogistic Regression in R: A Classification Technique to Predict Credit Card Default: https://blog.datasciencedojo.com/logistic-regression-in-r-tutorial/\n\n\n\n",
    "preview": "posts/2021-02-23-proposal/picture/1.JPG",
    "last_modified": "2021-03-30T15:04:43+08:00",
    "input_file": {}
  },
  {
    "path": "posts/welcome/",
    "title": "Welcome to G5Project_ISSS602",
    "description": "Welcome to our new blog, G5Project_ISSS602. We hope you enjoy \nreading what we have to say!",
    "author": [
      {
        "name": "Nora Jones",
        "url": "https://example.com/norajones"
      }
    ],
    "date": "2021-02-23",
    "categories": [],
    "contents": "\n\n\n\n",
    "preview": {},
    "last_modified": "2021-02-23T09:26:31+08:00",
    "input_file": {}
  }
]
